--- ./kos//arch/arm/include/asm/signal.h	2012-06-09 00:42:38.000000000 -0400
+++ ./kern//arch/arm/include/asm/signal.h	2012-06-13 16:30:48.000000000 -0400
@@ -14,7 +14,7 @@
 #define _NSIG_BPW	32
 #define _NSIG_WORDS	(_NSIG / _NSIG_BPW)
 
-typedef unsigned long old_sigset_t;		/* at least 32 bits */
+typedef uint32_t old_sigset_t;		/* at least 32 bits */
 
 typedef struct {
 	unsigned long sig[_NSIG_WORDS];
@@ -28,43 +28,47 @@
 
 #endif /* __KERNEL__ */
 
-#define SIGHUP		 1
-#define SIGINT		 2
-#define SIGQUIT		 3
-#define SIGILL		 4
-#define SIGTRAP		 5
-#define SIGABRT		 6
-#define SIGIOT		 6
-#define SIGBUS		 7
-#define SIGFPE		 8
-#define SIGKILL		 9
-#define SIGUSR1		10
-#define SIGSEGV		11
-#define SIGUSR2		12
-#define SIGPIPE		13
-#define SIGALRM		14
-#define SIGTERM		15
-#define SIGSTKFLT	16
-#define SIGCHLD		17
-#define SIGCONT		18
-#define SIGSTOP		19
-#define SIGTSTP		20
-#define SIGTTIN		21
-#define SIGTTOU		22
-#define SIGURG		23
-#define SIGXCPU		24
-#define SIGXFSZ		25
-#define SIGVTALRM	26
-#define SIGPROF		27
-#define SIGWINCH	28
-#define SIGIO		29
-#define SIGPOLL		SIGIO
+
+#define	SIGHUP	1	/* hangup */
+#define	SIGINT	2	/* interrupt */
+#define	SIGQUIT	3	/* quit */
+#define	SIGILL	4	/* illegal instruction (not reset when caught) */
+#define	SIGTRAP	5	/* trace trap (not reset when caught) */
+#define	SIGABRT	6	/* abort() */
+#define	SIGPOLL	7	/* pollable event ([XSR] generated, not supported) */
+#define	SIGIOT	SIGABRT	/* compatibility */
+#define	SIGEMT	7	/* EMT instruction */
+#define	SIGFPE	8	/* floating point exception */
+#define	SIGKILL	9	/* kill (cannot be caught or ignored) */
+#define	SIGBUS	10	/* bus error */
+#define	SIGSEGV	11	/* segmentation violation */
+#define	SIGSYS	12	/* bad argument to system call */
+#define	SIGPIPE	13	/* write on a pipe with no one to read it */
+#define	SIGALRM	14	/* alarm clock */
+#define	SIGTERM	15	/* software termination signal from kill */
+#define	SIGURG	16	/* urgent condition on IO channel */
+#define	SIGSTOP	17	/* sendable stop signal not from tty */
+#define	SIGTSTP	18	/* stop signal from tty */
+#define	SIGCONT	19	/* continue a stopped process */
+#define	SIGCHLD	20	/* to parent on child stop or exit */
+#define	SIGTTIN	21	/* to readers pgrp upon background tty read */
+#define	SIGTTOU	22	/* like TTIN for output if (tp->t_local&LTOSTOP) */
+#define	SIGIO	23	/* input/output possible signal */
+#define	SIGXCPU	24	/* exceeded CPU time limit */
+#define	SIGXFSZ	25	/* exceeded file size limit */
+#define	SIGVTALRM 26	/* virtual time alarm */
+#define	SIGPROF	27	/* profiling time alarm */
+#define SIGWINCH 28	/* window size changes */
+#define SIGINFO	29	/* information request */
+#define SIGUSR1 30	/* user defined signal 1 */
+#define SIGUSR2 31	/* user defined signal 2 */
+
 /*
 #define SIGLOST		29
 */
-#define SIGPWR		30
-#define SIGSYS		31
-#define	SIGUNUSED	31
+#define SIGPWR		32
+#define	SIGUNUSED	32
+#define SIGSTKFLT	32
 
 /* These should not be considered constants from userland.  */
 #define SIGRTMIN	32
@@ -114,11 +118,14 @@
 #include <asm-generic/signal-defs.h>
 
 #ifdef __KERNEL__
+
+#include <DarwinTypes.h>
+
 struct old_sigaction {
 	__sighandler_t sa_handler;
 	old_sigset_t sa_mask;
-	unsigned long sa_flags;
-	__sigrestore_t sa_restorer;
+	int sa_flags;
+	//__sigrestore_t sa_restorer;
 };
 
 struct sigaction {
@@ -141,8 +148,8 @@
 	  void (*_sa_sigaction)(int, struct siginfo *, void *);
 	} _u;
 	sigset_t sa_mask;
-	unsigned long sa_flags;
-	void (*sa_restorer)(void);
+	int sa_flags;
+	//void (*sa_restorer)(void);
 };
 
 #define sa_handler	_u._sa_handler
diff -Naur ./kos//arch/arm/include/asm/socket.h ./kern//arch/arm/include/asm/socket.h
--- ./kos//arch/arm/include/asm/socket.h	2012-06-09 00:42:38.000000000 -0400
+++ ./kern//arch/arm/include/asm/socket.h	2012-06-13 09:11:44.000000000 -0400
@@ -4,31 +4,50 @@
 #include <asm/sockios.h>
 
 /* For setsockopt(2) */
+
+#define	SO_DEBUG	0x0001		/* turn on debugging info recording */
+#define	SO_ACCEPTCONN	0x0002		/* socket has had listen() */
+#define	SO_REUSEADDR	0x0004		/* allow local address reuse */
+#define	SO_KEEPALIVE	0x0008		/* keep connections alive */
+#define	SO_DONTROUTE	0x0010		/* just use interface addresses */
+#define	SO_BROADCAST	0x0020		/* permit sending of broadcast msgs */
+#define SO_SNDBUF	0x1001		/* send buffer size */
+#define SO_RCVBUF	0x1002		/* receive buffer size */
+#define SO_SNDLOWAT	0x1003		/* send low-water mark */
+#define SO_RCVLOWAT	0x1004		/* receive low-water mark */
+#define SO_SNDTIMEO	0x1005		/* send timeout */
+#define SO_RCVTIMEO	0x1006		/* receive timeout */
+#define	SO_ERROR	0x1007		/* get error status and clear */
+#define	SO_TYPE		0x1008		/* get socket type */
+
+#define SO_LINGER	0x1080          /* linger on close if data present (in seconds) */
+#define	SO_OOBINLINE	0x0100	
+
 #define SOL_SOCKET	1
 
-#define SO_DEBUG	1
-#define SO_REUSEADDR	2
-#define SO_TYPE		3
-#define SO_ERROR	4
-#define SO_DONTROUTE	5
-#define SO_BROADCAST	6
-#define SO_SNDBUF	7
-#define SO_RCVBUF	8
-#define SO_SNDBUFFORCE	32
-#define SO_RCVBUFFORCE	33
-#define SO_KEEPALIVE	9
-#define SO_OOBINLINE	10
+//[bsd]//#define SO_DEBUG	1
+//[bsd]//#define SO_REUSEADDR	2
+//[bsd]//#define SO_TYPE		3
+//[bsd]//#define SO_ERROR	4
+//[bsd]//#define SO_DONTROUTE	5
+//[bsd]//#define SO_BROADCAST	6
+//[bsd]//#define SO_SNDBUF	7
+//[bsd]//#define SO_RCVBUF	8
+#define SO_SNDBUFFORCE	52 /* used to be 32 */
+#define SO_RCVBUFFORCE	53
+//[bsd]//#define SO_KEEPALIVE	9
+//[bsd]//#define SO_OOBINLINE	10
 #define SO_NO_CHECK	11
 #define SO_PRIORITY	12
-#define SO_LINGER	13
+//[bsd]//#define SO_LINGER	13
 #define SO_BSDCOMPAT	14
 /* To add :#define SO_REUSEPORT 15 */
-#define SO_PASSCRED	16
+#define SO_PASSCRED	56
 #define SO_PEERCRED	17
-#define SO_RCVLOWAT	18
-#define SO_SNDLOWAT	19
-#define SO_RCVTIMEO	20
-#define SO_SNDTIMEO	21
+//[bsd]//#define SO_RCVLOWAT	18
+//[bsd]//#define SO_SNDLOWAT	19
+//[bsd]//#define SO_RCVTIMEO	20
+//[bsd]//#define SO_SNDTIMEO	21
 
 /* Security levels - as per NRL IPv6 - don't actually do anything */
 #define SO_SECURITY_AUTHENTICATION		22
@@ -45,7 +64,7 @@
 #define SO_TIMESTAMP		29
 #define SCM_TIMESTAMP		SO_TIMESTAMP
 
-#define SO_ACCEPTCONN		30
+//[bsd]//#define SO_ACCEPTCONN		30
 
 #define SO_PEERSEC		31
 #define SO_PASSSEC		34
diff -Naur ./kos//arch/arm/kernel/entry-armv.S ./kern//arch/arm/kernel/entry-armv.S
--- ./kos//arch/arm/kernel/entry-armv.S	2012-06-09 00:42:40.000000000 -0400
+++ ./kern//arch/arm/kernel/entry-armv.S	2012-08-03 20:49:56.000000000 -0400
@@ -230,6 +230,10 @@
 #endif
 
 	irq_handler
+
+	/* irqs are lol */
+	get_thread_info tsk
+
 #ifdef CONFIG_PREEMPT
 	str	r8, [tsk, #TI_PREEMPT]		@ restore preempt count
 	ldr	r0, [tsk, #TI_FLAGS]		@ get flags
@@ -459,6 +463,10 @@
 #endif
 
 	irq_handler
+
+	/* irqs are lol */
+	get_thread_info tsk
+
 #ifdef CONFIG_PREEMPT
 	ldr	r0, [tsk, #TI_PREEMPT]
 	str	r8, [tsk, #TI_PREEMPT]
diff -Naur ./kos//arch/arm/kernel/entry-common.S ./kern//arch/arm/kernel/entry-common.S
--- ./kos//arch/arm/kernel/entry-common.S	2012-06-09 00:42:39.000000000 -0400
+++ ./kern//arch/arm/kernel/entry-common.S	2012-08-06 11:12:29.000000000 -0400
@@ -8,6 +8,15 @@
  * published by the Free Software Foundation.
  */
 
+
+ /*
+  * Copyright (c) 2012 Christina Brooks
+  *
+  * Darwin ABI support and preservation of the r9 register in
+  * order to support running swi handlers that use this ABI
+  * as it can sometimes trash r9.
+  */
+
 #include <asm/unistd.h>
 #include <asm/ftrace.h>
 #include <mach/entry-macro.S>
@@ -15,30 +24,73 @@
 
 #include "entry-header.S"
 
+#define __apple_darwin_abi__
+
+#if defined(CONFIG_OABI_COMPAT)
+#error config_oabi_compat is not supported by this kernel
+#endif
 
 	.align	5
+
+/*
+ * Common.
+ */
+Restore_user_high:
+	arch_ret_to_user r1, lr
+	restore_user_regs fast = 1, offset = S_OFF
+
+/*
+ * Return to the userspace from *any point* in the system call.
+ */
+.globl Return_to_user_from_swi
+Return_to_user_from_swi:
+	disable_irq /* disable irq */
+
+	/* restore r9 */
+ 	get_thread_info tsk
+
+ 	/*
+ 	 * Recover the stack frame.
+ 	 * (oh god wtf)
+ 	 */
+ 	add sp, tsk, #8192
+ 	sub sp, #S_FRAME_SIZE+S_OFF+8
+
+	/* force work pending */
+	b fast_work_pending
+
+	/* switch back to userspace */
+	mov r1, #0
+	b Restore_user_high
+
+
 /*
  * This is the fast syscall return path.  We do as little as
  * possible here, and this includes saving r0 back into the SVC
  * stack.
  */
-ret_fast_syscall:
+.globl Return_to_user_from_swi_fast
+Return_to_user_from_swi_fast:
  UNWIND(.fnstart	)
  UNWIND(.cantunwind	)
-	disable_irq				@ disable interrupts
+
+ 	/* restore r9 */
+ 	get_thread_info tsk
+ 	
+	disable_irq	/* disable irq */
 	ldr	r1, [tsk, #TI_FLAGS]
 	tst	r1, #_TIF_WORK_MASK
 	bne	fast_work_pending
+
 #if defined(CONFIG_IRQSOFF_TRACER)
 	asm_trace_hardirqs_on
 #endif
 
 	/* perform architecture specific actions before user return */
-	arch_ret_to_user r1, lr
-
-	restore_user_regs fast = 1, offset = S_OFF
+	b Restore_user_high
  UNWIND(.fnend		)
 
+
 /*
  * Ok, we need to do extra processing, enter the slow path.
  */
@@ -73,7 +125,6 @@
 #endif
 	/* perform architecture specific actions before user return */
 	arch_ret_to_user r1, lr
-
 	restore_user_regs fast = 0, offset = 0
 ENDPROC(ret_to_user)
 
@@ -214,7 +265,7 @@
 #ifdef CONFIG_OLD_MCOUNT
 /*
  * This is under an ifdef in order to force link-time errors for people trying
- * to build with !FRAME_POINTER with a GCC which doesn't use the new-style
+ * to build with !FRAME_POINTER with a GCC which does not use the new-style
  * mcount.
  */
 ENTRY(mcount)
@@ -247,18 +298,17 @@
 
 #endif /* CONFIG_FUNCTION_TRACER */
 
-/*=============================================================================
- * SWI handler
- *-----------------------------------------------------------------------------
- */
+/* Handle a Darwin system call (0x80) */
+ENTRY(Fleh_swi_darwin)
+	adr	lr, BSYM(Return_to_user_from_swi_fast)
+	b Sleh_swi_darwin
+ENDPROC(Fleh_swi_darwin)
+
 
-	/* If we're optimising for StrongARM the resulting code won't 
-	   run on an ARM7 and we can save a couple of instructions.  
-								--pb */
 #ifdef CONFIG_CPU_ARM710
 #define A710(code...) code
 .Larm710bug:
-	ldmia	sp, {r0 - lr}^			@ Get calling r0 - lr
+	ldmia	sp, {r0 - lr}^			// Get calling r0 - lr
 	mov	r0, r0
 	add	sp, sp, #S_FRAME_SIZE
 	subs	pc, lr, #4
@@ -267,121 +317,120 @@
 #endif
 
 	.align	5
+
+/* Software interrupt vector */
 ENTRY(vector_swi)
 	sub	sp, sp, #S_FRAME_SIZE
-	stmia	sp, {r0 - r12}			@ Calling r0 - r12
- ARM(	add	r8, sp, #S_PC		)
- ARM(	stmdb	r8, {sp, lr}^		)	@ Calling sp, lr
- THUMB(	mov	r8, sp			)
- THUMB(	store_user_sp_lr r8, r10, S_SP	)	@ calling sp, lr
-	mrs	r8, spsr			@ called from non-FIQ mode, so ok.
-	str	lr, [sp, #S_PC]			@ Save calling PC
-	str	r8, [sp, #S_PSR]		@ Save CPSR
-	str	r0, [sp, #S_OLD_R0]		@ Save OLD_R0
+	stmia	sp, {r0 - r12}			// Calling r0 - r12
+
+ ARM(	add	r11, sp, #S_PC		)
+ ARM(	stmdb	r11, {sp, lr}^		)	// Calling sp, lr
+ THUMB(	mov	r11, sp			)
+ THUMB(	store_user_sp_lr r11, r10, S_SP	)	// calling sp, lr
+
+	mrs	r11, spsr			// called from non-FIQ mode, so ok.
+	str	lr, [sp, #S_PC]			// Save calling PC
+	str	r11, [sp, #S_PSR]		// Save CPSR
+	str	r0, [sp, #S_OLD_R0]		// Save OLD_R0
 	zero_fp
 
-	/*
-	 * Get the system call number.
-	 */
+	/* args to the syscall */
+	sub sp, #8
+	stmdb	sp!, {r4, r5, r6, r8}
 
-#if defined(CONFIG_OABI_COMPAT)
+	/* ghey */
+	mov r8, r11
 
 	/*
-	 * If we have CONFIG_OABI_COMPAT then we need to look at the swi
-	 * value to determine if it is an EABI or an old ABI call.
+	 * If this is a darwin system call, move r12 to scno.
 	 */
-#ifdef CONFIG_ARM_THUMB
-	tst	r8, #PSR_T_BIT
-	movne	r10, #0				@ no thumb OABI emulation
-	ldreq	r10, [lr, #-4]			@ get SWI instruction
-#else
-	ldr	r10, [lr, #-4]			@ get SWI instruction
-  A710(	and	ip, r10, #0x0f000000		@ check for SWI		)
-  A710(	teq	ip, #0x0f000000						)
-  A710(	bne	.Larm710bug						)
-#endif
-#ifdef CONFIG_CPU_ENDIAN_BE8
-	rev	r10, r10			@ little endian instruction
-#endif
+	ldr	r11, [lr, #-4]	/* svc instr */
+	bics r11, r11, #0xff000000 /* strip the instr opcode */
+	cmp r11, #0x80 /* svc 0x80 means darwin */
+
+	/* move r12 to scno and skip all the linux crap */
+	moveq scno, r12
+	beq darwin_2
+
+	/* stripped oabi code */
 
-#elif defined(CONFIG_AEABI)
+#if defined(CONFIG_AEABI)
 
 	/*
 	 * Pure EABI user space always put syscall number into scno (r7).
 	 */
-  A710(	ldr	ip, [lr, #-4]			@ get SWI instruction	)
-  A710(	and	ip, ip, #0x0f000000		@ check for SWI		)
-  A710(	teq	ip, #0x0f000000						)
-  A710(	bne	.Larm710bug						)
+  A710(	ldr	ip, [lr, #-4] ) // get SWI instruction	
+  A710(	and	ip, ip, #0x0f000000	) // check for SWI		
+  A710(	teq	ip, #0x0f000000	)
+  A710(	bne	.Larm710bug	)
 
 #elif defined(CONFIG_ARM_THUMB)
 
 	/* Legacy ABI only, possibly thumb mode. */
-	tst	r8, #PSR_T_BIT			@ this is SPSR from save_user_regs
-	addne	scno, r7, #__NR_SYSCALL_BASE	@ put OS number in
+	tst	r8, #PSR_T_BIT //this is SPSR from save_user_regs
+	addne	scno, r7, #__NR_SYSCALL_BASE // put OS number in
 	ldreq	scno, [lr, #-4]
 
 #else
 
 	/* Legacy ABI only. */
-	ldr	scno, [lr, #-4]			@ get SWI instruction
-  A710(	and	ip, scno, #0x0f000000		@ check for SWI		)
-  A710(	teq	ip, #0x0f000000						)
-  A710(	bne	.Larm710bug						)
+	ldr	scno, [lr, #-4]	// get SWI instruction
+  A710(	and	ip, scno, #0x0f000000 )
+  A710(	teq	ip, #0x0f000000 )
+  A710(	bne	.Larm710bug	) // check for SWI	
 
 #endif
 
 #ifdef CONFIG_ALIGNMENT_TRAP
 	ldr	ip, __cr_alignment
 	ldr	ip, [ip]
-	mcr	p15, 0, ip, c1, c0		@ update control register
+	mcr	p15, 0, ip, c1, c0	// update control register
 #endif
-	enable_irq
 
-	get_thread_info tsk
-	adr	tbl, sys_call_table		@ load syscall table pointer
+	adr	tbl, sys_call_table	// load syscall table pointer
 
-#if defined(CONFIG_OABI_COMPAT)
-	/*
-	 * If the swi argument is zero, this is an EABI call and we do nothing.
-	 *
-	 * If this is an old ABI call, get the syscall number into scno and
-	 * get the old ABI syscall table address.
-	 */
-	bics	r10, r10, #0xff000000
-	eorne	scno, r10, #__NR_OABI_SYSCALL_BASE
-	ldrne	tbl, =sys_oabi_call_table
-#elif !defined(CONFIG_AEABI)
-	bic	scno, scno, #0xff000000		@ mask off SWI op-code
-	eor	scno, scno, #__NR_SYSCALL_BASE	@ check OS number
+#if !defined(CONFIG_AEABI)
+	bic	scno, scno, #0xff000000	// mask off SWI op-code
+	eor	scno, scno, #__NR_SYSCALL_BASE // check OS number
 #endif
 
-	ldr	r10, [tsk, #TI_FLAGS]		@ check for syscall tracing
-	stmdb	sp!, {r4, r5}			@ push fifth and sixth args
+	
+darwin_2:
+	/***** darwin syscalls start here *****/
+	enable_irq
+
+	get_thread_info tsk
+	ldr	r10, [tsk, #TI_FLAGS] // check for syscall tracing	
 
 #ifdef CONFIG_SECCOMP
 	tst	r10, #_TIF_SECCOMP
 	beq	1f
 	mov	r0, scno
 	bl	__secure_computing	
-	add	r0, sp, #S_R0 + S_OFF		@ pointer to regs
-	ldmia	r0, {r0 - r3}			@ have to reload r0 - r3
+	add	r0, sp, #S_R0 + S_OFF // pointer to regs
+	ldmia	r0, {r0 - r3} // have to reload r0 - r3
 1:
 #endif
 
-	tst	r10, #_TIF_SYSCALL_TRACE		@ are we tracing syscalls?
+	/* is this a darwin call? */
+	cmp r11, #0x80 
+	beq Fleh_swi_darwin 
+
+	tst	r10, #_TIF_SYSCALL_TRACE // are we tracing syscalls?
 	bne	__sys_trace
 
-	cmp	scno, #NR_syscalls		@ check upper syscall limit
-	adr	lr, BSYM(ret_fast_syscall)	@ return address
-	ldrcc	pc, [tbl, scno, lsl #2]		@ call sys_* routine
+Llinux_syscall:
+	adr	lr, BSYM(Return_to_user_from_swi_fast)	// return address
+	cmp	scno, #NR_syscalls		// check upper syscall limit
+	
+	ldrcc	pc, [tbl, scno, lsl #2]		// call sys_* routine
 
 	add	r1, sp, #S_OFF
 2:	mov	why, #0				@ no longer a real syscall
 	cmp	scno, #(__ARM_NR_BASE - __NR_SYSCALL_BASE)
-	eor	r0, scno, #__NR_SYSCALL_BASE	@ put OS number back
+	eor	r0, scno, #__NR_SYSCALL_BASE	// put OS number back
 	bcs	arm_syscall	
-	b	sys_ni_syscall			@ not private func
+	b	sys_ni_syscall			// not private func
 ENDPROC(vector_swi)
 
 	/*
@@ -438,13 +487,13 @@
 /*============================================================================
  * Special system call wrappers
  */
-@ r0 = syscall number
-@ r8 = syscall table
+// r0 = syscall number
+// r8 = syscall table
 sys_syscall:
 		bic	scno, r0, #__NR_OABI_SYSCALL_BASE
 		cmp	scno, #__NR_syscall - __NR_SYSCALL_BASE
-		cmpne	scno, #NR_syscalls	@ check range
-		stmloia	sp, {r5, r6}		@ shuffle args
+		cmpne	scno, #NR_syscalls	// check range
+		stmloia	sp, {r5, r6}		// shuffle args
 		movlo	r0, r1
 		movlo	r1, r2
 		movlo	r2, r3
@@ -476,13 +525,13 @@
 
 sys_sigreturn_wrapper:
 		add	r0, sp, #S_OFF
-		mov	why, #0		@ prevent syscall restart handling
+		mov	why, #0		// prevent syscall restart handling
 		b	sys_sigreturn
 ENDPROC(sys_sigreturn_wrapper)
 
 sys_rt_sigreturn_wrapper:
 		add	r0, sp, #S_OFF
-		mov	why, #0		@ prevent syscall restart handling
+		mov	why, #0		// prevent syscall restart handling
 		b	sys_rt_sigreturn
 ENDPROC(sys_rt_sigreturn_wrapper)
 
diff -Naur ./kos//arch/arm/kernel/entry-header.S ./kern//arch/arm/kernel/entry-header.S
--- ./kos//arch/arm/kernel/entry-header.S	2012-06-09 00:42:40.000000000 -0400
+++ ./kern//arch/arm/kernel/entry-header.S	2012-08-05 10:00:45.000000000 -0400
@@ -20,7 +20,7 @@
 @ the addition of 8 bytes for storing syscall args 5 and 6.
 @ This _must_ remain a multiple of 8 for EABI.
 @
-#define S_OFF		8
+#define S_OFF		24
 
 /* 
  * The SWI code relies on the fact that R0 is at the bottom of the stack
diff -Naur ./kos//arch/arm/kernel/signal.c ./kern//arch/arm/kernel/signal.c
--- ./kos//arch/arm/kernel/signal.c	2012-06-09 00:42:40.000000000 -0400
+++ ./kern//arch/arm/kernel/signal.c	2012-06-13 16:34:58.000000000 -0400
@@ -90,8 +90,7 @@
 	if (act) {
 		old_sigset_t mask;
 		if (!access_ok(VERIFY_READ, act, sizeof(*act)) ||
-		    __get_user(new_ka.sa.sa_handler, &act->sa_handler) ||
-		    __get_user(new_ka.sa.sa_restorer, &act->sa_restorer))
+		    __get_user(new_ka.sa.sa_handler, &act->sa_handler))
 			return -EFAULT;
 		__get_user(new_ka.sa.sa_flags, &act->sa_flags);
 		__get_user(mask, &act->sa_mask);
@@ -102,8 +101,7 @@
 
 	if (!ret && oact) {
 		if (!access_ok(VERIFY_WRITE, oact, sizeof(*oact)) ||
-		    __put_user(old_ka.sa.sa_handler, &oact->sa_handler) ||
-		    __put_user(old_ka.sa.sa_restorer, &oact->sa_restorer))
+		    __put_user(old_ka.sa.sa_handler, &oact->sa_handler))
 			return -EFAULT;
 		__put_user(old_ka.sa.sa_flags, &oact->sa_flags);
 		__put_user(old_ka.sa.sa_mask.sig[0], &oact->sa_mask);
@@ -502,7 +500,8 @@
 #endif
 
 	if (ka->sa.sa_flags & SA_RESTORER) {
-		retcode = (unsigned long)ka->sa.sa_restorer;
+		panic("signal.c: (ka->sa.sa_flags & SA_RESTORER)");
+		retcode = (unsigned long)0;
 	} else {
 		unsigned int idx = thumb << 1;
 
diff -Naur ./kos//arch/arm/mm/mmap.c ./kern//arch/arm/mm/mmap.c
--- ./kos//arch/arm/mm/mmap.c	2012-06-09 00:42:35.000000000 -0400
+++ ./kern//arch/arm/mm/mmap.c	2012-08-04 10:33:47.000000000 -0400
@@ -25,10 +25,9 @@
  * in the VIVT case, we optimise out the alignment rules.
  */
 unsigned long
-arch_get_unmapped_area(struct file *filp, unsigned long addr,
+ARM_get_unmapped_area(struct mm_struct *mm, struct file *filp, unsigned long addr,
 		unsigned long len, unsigned long pgoff, unsigned long flags)
 {
-	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
 	unsigned long start_addr;
 #ifdef CONFIG_CPU_V6
@@ -120,6 +119,13 @@
 	}
 }
 
+unsigned long
+arch_get_unmapped_area(struct file *filp, unsigned long addr,
+		unsigned long len, unsigned long pgoff, unsigned long flags)
+{
+	/* classic */
+	return ARM_get_unmapped_area(current->mm, filp, addr, len, pgoff, flags);
+}
 
 /*
  * You really shouldn't be using read() or write() on /dev/mem.  This
diff -Naur ./kos//drivers/tty/vt/vt.c ./kern//drivers/tty/vt/vt.c
--- ./kos//drivers/tty/vt/vt.c	2012-06-09 00:39:23.000000000 -0400
+++ ./kern//drivers/tty/vt/vt.c	2012-06-24 07:51:24.000000000 -0400
@@ -2480,6 +2480,8 @@
  * The console must be locked when we get here.
  */
 
+static unsigned int printk_color = 0x17;
+
 static void vt_console_print(struct console *co, const char *b, unsigned count)
 {
 	struct vc_data *vc = vc_cons[fg_console].d;
@@ -2518,12 +2520,19 @@
 		hide_cursor(vc);
 
 	start = (ushort *)vc->vc_pos;
+	
+	vc->vc_color = printk_color;
+	update_attr(vc);
 
 	/* Contrived structure to try to emulate original need_wrap behaviour
 	 * Problems caused when we have need_wrap set on '\n' character */
 	while (count--) {
 		c = *b++;
 		if (c == 10 || c == 13 || c == 8 || vc->vc_need_wrap) {
+
+			vc->vc_color = vc->vc_def_color;
+			update_attr(vc);
+
 			if (cnt > 0) {
 				if (CON_IS_VISIBLE(vc))
 					vc->vc_sw->con_putcs(vc, start, cnt, vc->vc_y, vc->vc_x);
@@ -2536,6 +2545,10 @@
 				bs(vc);
 				start = (ushort *)vc->vc_pos;
 				myx = vc->vc_x;
+
+				vc->vc_color = printk_color;
+				update_attr(vc);
+
 				continue;
 			}
 			if (c != 13)
@@ -2543,6 +2556,10 @@
 			cr(vc);
 			start = (ushort *)vc->vc_pos;
 			myx = vc->vc_x;
+
+			vc->vc_color = printk_color;
+			update_attr(vc);
+
 			if (c == 10 || c == 13)
 				continue;
 		}
@@ -2565,6 +2582,10 @@
 			vc->vc_need_wrap = 1;
 		}
 	}
+
+	vc->vc_color = vc->vc_def_color;
+	update_attr(vc);
+
 	set_cursor(vc);
 	notify_update(vc);
 
diff -Naur ./kos//fs/exec.c ./kern//fs/exec.c
--- ./kos//fs/exec.c	2012-06-09 00:43:55.000000000 -0400
+++ ./kern//fs/exec.c	2012-06-30 19:21:01.000000000 -0400
@@ -1680,6 +1680,8 @@
 	unsigned long flags;
 	int nr = -EAGAIN;
 
+	printk("zap_threads!\n");
+
 	spin_lock_irq(&tsk->sighand->siglock);
 	if (!signal_group_exit(tsk->signal)) {
 		mm->core_state = core_state;
diff -Naur ./kos//fs/stat.c ./kern//fs/stat.c
--- ./kos//fs/stat.c	2012-06-09 00:43:56.000000000 -0400
+++ ./kern//fs/stat.c	2012-07-10 14:31:56.000000000 -0400
@@ -115,7 +115,7 @@
 {
 	static int warncount = 5;
 	struct __old_kernel_stat tmp;
-	
+	printk("OLDSTATTTTT!!!!!!!!!\n");
 	if (warncount > 0) {
 		warncount--;
 		printk(KERN_WARNING "VFS: Warning: %s using old stat() call. Recompile your binary.\n",
@@ -191,7 +191,7 @@
 static int cp_new_stat(struct kstat *stat, struct stat __user *statbuf)
 {
 	struct stat tmp;
-
+	
 #if BITS_PER_LONG == 32
 	if (!old_valid_dev(stat->dev) || !old_valid_dev(stat->rdev))
 		return -EOVERFLOW;
@@ -332,6 +332,8 @@
 {
 	struct stat64 tmp;
 
+	//printk("cp_new_stat64(): size of stat64 is %d \n", sizeof(struct stat64));
+
 	memset(&tmp, 0, sizeof(struct stat64));
 #ifdef CONFIG_MIPS
 	/* mips has weird padding, so we don't get 64 bits there */
diff -Naur ./kos//include/asm-generic/signal-defs.h ./kern//include/asm-generic/signal-defs.h
--- ./kos//include/asm-generic/signal-defs.h	2012-06-09 00:43:44.000000000 -0400
+++ ./kern//include/asm-generic/signal-defs.h	2012-06-13 16:44:57.000000000 -0400
@@ -4,13 +4,13 @@
 #include <linux/compiler.h>
 
 #ifndef SIG_BLOCK
-#define SIG_BLOCK          0	/* for blocking signals */
+#define SIG_BLOCK          1	/* for blocking signals */
 #endif
 #ifndef SIG_UNBLOCK
-#define SIG_UNBLOCK        1	/* for unblocking signals */
+#define SIG_UNBLOCK        2	/* for unblocking signals */
 #endif
 #ifndef SIG_SETMASK
-#define SIG_SETMASK        2	/* for setting the signal mask */
+#define SIG_SETMASK        3	/* for setting the signal mask */
 #endif
 
 #ifndef __ASSEMBLY__
diff -Naur ./kos//include/linux/in.h ./kern//include/linux/in.h
--- ./kos//include/linux/in.h	2012-06-09 00:43:32.000000000 -0400
+++ ./kern//include/linux/in.h	2012-06-13 08:57:51.000000000 -0400
@@ -21,6 +21,8 @@
 #include <linux/types.h>
 #include <linux/socket.h>
 
+#include <DarwinTypes.h>
+
 /* Standard well-defined IP protocols.  */
 enum {
   IPPROTO_IP = 0,		/* Dummy protocol for TCP		*/
@@ -54,7 +56,7 @@
 
 /* Internet address. */
 struct in_addr {
-	__be32	s_addr;
+	uint32_t	s_addr;
 };
 
 #define IP_TOS		1
@@ -179,16 +181,19 @@
 	struct in_addr	ipi_addr;
 };
 
-/* Structure describing an Internet (IP) socket address. */
+/*
+ * Structure describing an Internet (IP) socket address.
+ * [BSD]
+ */
 #define __SOCK_SIZE__	16		/* sizeof(struct sockaddr)	*/
 struct sockaddr_in {
+  uint8_t sin_len; /* [BSD] */
   sa_family_t		sin_family;	/* Address family		*/
-  __be16		sin_port;	/* Port number			*/
+  uint16_t		sin_port;	/* Port number			*/
   struct in_addr	sin_addr;	/* Internet address		*/
 
   /* Pad to size of `struct sockaddr'. */
-  unsigned char		__pad[__SOCK_SIZE__ - sizeof(short int) -
-			sizeof(unsigned short int) - sizeof(struct in_addr)];
+  unsigned char		__pad[8]; /* [BSD] */
 };
 #define sin_zero	__pad		/* for BSD UNIX comp. -FvK	*/
 
diff -Naur ./kos//include/linux/sched.h ./kern//include/linux/sched.h
--- ./kos//include/linux/sched.h	2012-06-09 00:43:33.000000000 -0400
+++ ./kern//include/linux/sched.h	2012-07-18 18:00:59.000000000 -0400
@@ -1516,8 +1516,18 @@
 	/*
 	 * Mach stuff
 	 */
-	void* task_port;
-	void* port_rights;
+	void* task_port; /* this task's task_port_t/ipc_space */
+	void* port_rights; /* not used */
+	void* thread_port; /* thread port */ 
+
+	 /*
+	  * Apple threading things.
+	  */
+	int p_pthsize;
+	void* p_threadstart;
+	void* p_wqthread;
+	void* p_targconc;
+	unsigned long p_dispatchqueue_offset;
 };
 
 /* Future-safe accessor for struct task_struct's cpus_allowed. */
diff -Naur ./kos//include/linux/socket.h ./kern//include/linux/socket.h
--- ./kos//include/linux/socket.h	2012-06-09 00:43:43.000000000 -0400
+++ ./kern//include/linux/socket.h	2012-06-19 19:55:42.000000000 -0400
@@ -1,6 +1,17 @@
+/*
+ * socket.h
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Don't try this at home.
+ */
+
 #ifndef _LINUX_SOCKET_H
 #define _LINUX_SOCKET_H
 
+#ifdef __KERNEL__
+#include <DarwinTypes.h>	
+#endif
+
 /*
  * Desired design of maximum size and alignment (see RFC2553)
  */
@@ -9,6 +20,8 @@
 				/* Implementation specific desired alignment */
 
 struct __kernel_sockaddr_storage {
+	uint8_t	sa_len; /* [BSD] */
+
 	unsigned short	ss_family;		/* address family */
 	/* Following field(s) are implementation specific */
 	char		__data[_K_SS_MAXSIZE - sizeof(unsigned short)];
@@ -37,13 +50,14 @@
 # endif
 #endif /* __KERNEL__ */
 
-typedef unsigned short	sa_family_t;
+typedef uint8_t sa_family_t; /* [BSD] */
 
 /*
  *	1003.1g requires sa_family_t and that sa_data is char.
  */
  
 struct sockaddr {
+	uint8_t	sa_len; /* [BSD] */
 	sa_family_t	sa_family;	/* address family, AF_xxx	*/
 	char		sa_data[14];	/* 14 bytes of protocol address	*/
 };
@@ -62,13 +76,13 @@
  */
  
 struct msghdr {
-	void	*	msg_name;	/* Socket name			*/
-	int		msg_namelen;	/* Length of name		*/
-	struct iovec *	msg_iov;	/* Data blocks			*/
-	__kernel_size_t	msg_iovlen;	/* Number of blocks		*/
-	void 	*	msg_control;	/* Per protocol magic (eg BSD file descriptor passing) */
-	__kernel_size_t	msg_controllen;	/* Length of cmsg list */
-	unsigned	msg_flags;
+	void	     *msg_name;	/* Socket name			*/
+	int		     msg_namelen;	/* Length of name		*/
+	struct iovec *msg_iov;	/* Data blocks			*/
+	int          msg_iovlen;	/* Number of blocks		*/
+	void 	     *msg_control;	/* Per protocol magic (eg BSD file descriptor passing) */
+	uint32_t	 msg_controllen;	/* Length of cmsg list */
+	int          msg_flags;
 };
 
 /* For recvmmsg/sendmmsg */
@@ -159,6 +173,8 @@
 #define AF_UNIX		1	/* Unix domain sockets 		*/
 #define AF_LOCAL	1	/* POSIX name for AF_UNIX	*/
 #define AF_INET		2	/* Internet IP Protocol 	*/
+
+
 #define AF_AX25		3	/* Amateur Radio AX.25 		*/
 #define AF_IPX		4	/* Novell IPX 			*/
 #define AF_APPLETALK	5	/* AppleTalk DDP 		*/
diff -Naur ./kos//init/main.c ./kern//init/main.c
--- ./kos//init/main.c	2012-06-09 00:43:28.000000000 -0400
+++ ./kern//init/main.c	2012-06-23 11:01:41.000000000 -0400
@@ -812,6 +812,8 @@
 	kernel_execve(init_filename, argv_init, envp_init);
 }
 
+extern void __ke_runtime_init(void);
+
 /* This is a non __init function. Force it to be noinline otherwise gcc
  * makes it inline to init() and it becomes part of init.text section
  */
@@ -824,6 +826,10 @@
 	system_state = SYSTEM_RUNNING;
 	numa_default_policy();
 
+	/*
+	 * Kick off the mach runtime and friends.
+	 */
+	__ke_runtime_init();
 
 	current->signal->flags |= SIGNAL_UNKILLABLE;
 
diff -Naur ./kos//init/version.c ./kern//init/version.c
--- ./kos//init/version.c	2012-06-09 00:43:28.000000000 -0400
+++ ./kern//init/version.c	2012-08-03 12:13:38.000000000 -0400
@@ -38,8 +38,7 @@
 
 /* FIXED STRINGS! Don't touch! */
 const char linux_banner[] =
-	"Linux version " UTS_RELEASE " (" LINUX_COMPILE_BY "@"
-	LINUX_COMPILE_HOST ") (" LINUX_COMPILER ") " UTS_VERSION "\n";
+	"Mk version 0.1, Linux version " UTS_RELEASE "\n";
 
 const char linux_proc_banner[] =
 	"%s version %s"
diff -Naur ./kos//kernel/fork.c ./kern//kernel/fork.c
--- ./kos//kernel/fork.c	2012-06-09 00:43:47.000000000 -0400
+++ ./kern//kernel/fork.c	2012-07-21 09:51:20.000000000 -0400
@@ -650,9 +650,9 @@
  * Allocate a new mm structure and copy contents from the
  * mm structure of the passed in task structure.
  */
-struct mm_struct *dup_mm(struct task_struct *tsk)
+struct mm_struct *dup_mm_ex(struct task_struct *tsk, struct task_struct *from)
 {
-	struct mm_struct *mm, *oldmm = current->mm;
+	struct mm_struct *mm, *oldmm = from->mm;
 	int err;
 
 	if (!oldmm)
@@ -706,7 +706,12 @@
 	return NULL;
 }
 
-static int copy_mm(unsigned long clone_flags, struct task_struct * tsk)
+struct mm_struct *dup_mm(struct task_struct *tsk)
+{
+	return dup_mm_ex(tsk, current);
+}
+
+static int copy_mm_ex(unsigned long clone_flags, struct task_struct * tsk, struct task_struct *from)
 {
 	struct mm_struct * mm, *oldmm;
 	int retval;
@@ -725,7 +730,7 @@
 	 *
 	 * We need to steal a active VM for that..
 	 */
-	oldmm = current->mm;
+	oldmm = from->mm;
 	if (!oldmm)
 		return 0;
 
@@ -736,7 +741,7 @@
 	}
 
 	retval = -ENOMEM;
-	mm = dup_mm(tsk);
+	mm = dup_mm_ex(tsk, from);
 	if (!mm)
 		goto fail_nomem;
 
@@ -755,9 +760,10 @@
 	return retval;
 }
 
-static int copy_fs(unsigned long clone_flags, struct task_struct *tsk)
+static int copy_fs_ex(unsigned long clone_flags, struct task_struct *tsk, struct task_struct *from)
 {
-	struct fs_struct *fs = current->fs;
+	struct fs_struct *fs = from->fs;
+
 	if (clone_flags & CLONE_FS) {
 		/* tsk->fs is already what we want */
 		spin_lock(&fs->lock);
@@ -775,7 +781,12 @@
 	return 0;
 }
 
-static int copy_files(unsigned long clone_flags, struct task_struct * tsk)
+static int copy_fs(unsigned long clone_flags, struct task_struct *tsk)
+{
+	return copy_fs_ex(clone_flags, tsk, current);
+}
+
+static int copy_files_ex(unsigned long clone_flags, struct task_struct * tsk, struct task_struct* from)
 {
 	struct files_struct *oldf, *newf;
 	int error = 0;
@@ -783,7 +794,7 @@
 	/*
 	 * A background process may not have any files ...
 	 */
-	oldf = current->files;
+	oldf = from->files;
 	if (!oldf)
 		goto out;
 
@@ -802,10 +813,15 @@
 	return error;
 }
 
-static int copy_io(unsigned long clone_flags, struct task_struct *tsk)
+static int copy_files(unsigned long clone_flags, struct task_struct * tsk)
+{
+	return copy_files_ex(clone_flags, tsk, current);
+}
+
+static int copy_io_ex(unsigned long clone_flags, struct task_struct *tsk, struct task_struct *from)
 {
 #ifdef CONFIG_BLOCK
-	struct io_context *ioc = current->io_context;
+	struct io_context *ioc = from->io_context;
 
 	if (!ioc)
 		return 0;
@@ -827,12 +843,17 @@
 	return 0;
 }
 
-static int copy_sighand(unsigned long clone_flags, struct task_struct *tsk)
+static int copy_io(unsigned long clone_flags, struct task_struct *tsk)
+{
+	return copy_io_ex(clone_flags, tsk, current);
+}
+
+static int copy_sighand_ex(unsigned long clone_flags, struct task_struct *tsk, struct task_struct *from)
 {
 	struct sighand_struct *sig;
 
 	if (clone_flags & CLONE_SIGHAND) {
-		atomic_inc(&current->sighand->count);
+		atomic_inc(&from->sighand->count);
 		return 0;
 	}
 	sig = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);
@@ -840,10 +861,15 @@
 	if (!sig)
 		return -ENOMEM;
 	atomic_set(&sig->count, 1);
-	memcpy(sig->action, current->sighand->action, sizeof(sig->action));
+	memcpy(sig->action, from->sighand->action, sizeof(sig->action));
 	return 0;
 }
 
+static int copy_sighand(unsigned long clone_flags, struct task_struct *tsk)
+{
+	return copy_sighand_ex(clone_flags, tsk, current);
+}
+
 void __cleanup_sighand(struct sighand_struct *sighand)
 {
 	if (atomic_dec_and_test(&sighand->count))
@@ -873,7 +899,8 @@
 	INIT_LIST_HEAD(&sig->cpu_timers[2]);
 }
 
-static int copy_signal(unsigned long clone_flags, struct task_struct *tsk)
+/* [MACH]: extended copy */
+static int copy_signal_ex(unsigned long clone_flags, struct task_struct *tsk, struct task_struct* from)
 {
 	struct signal_struct *sig;
 
@@ -898,22 +925,27 @@
 	hrtimer_init(&sig->real_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
 	sig->real_timer.function = it_real_fn;
 
-	task_lock(current->group_leader);
-	memcpy(sig->rlim, current->signal->rlim, sizeof sig->rlim);
-	task_unlock(current->group_leader);
+	task_lock(from->group_leader);
+	memcpy(sig->rlim, from->signal->rlim, sizeof sig->rlim);
+	task_unlock(from->group_leader);
 
 	posix_cpu_timers_init_group(sig);
 
 	tty_audit_fork(sig);
 
-	sig->oom_adj = current->signal->oom_adj;
-	sig->oom_score_adj = current->signal->oom_score_adj;
+	sig->oom_adj = from->signal->oom_adj;
+	sig->oom_score_adj = from->signal->oom_score_adj;
 
 	mutex_init(&sig->cred_guard_mutex);
 
 	return 0;
 }
 
+static int copy_signal(unsigned long clone_flags, struct task_struct *tsk)
+{
+	return copy_signal_ex(clone_flags, tsk, current);
+}
+
 static void copy_flags(unsigned long clone_flags, struct task_struct *p)
 {
 	unsigned long new_flags = p->flags;
@@ -961,6 +993,13 @@
 	INIT_LIST_HEAD(&tsk->cpu_timers[2]);
 }
 
+extern int
+mach_platform_copy_thread(unsigned long clone_flags,
+	unsigned long stack_start,
+	unsigned long stk_sz,
+	struct task_struct *p,
+	struct pt_regs *regs);
+
 /*
  * This creates a new process as a copy of the old one,
  * but does not actually start it yet.
@@ -969,18 +1008,26 @@
  * parts of the process environment (as per the clone
  * flags). The actual kick-off is left to the caller.
  */
-static struct task_struct *copy_process(unsigned long clone_flags,
+static struct task_struct *copy_process_ex(unsigned long clone_flags,
 					unsigned long stack_start,
 					struct pt_regs *regs,
 					unsigned long stack_size,
 					int __user *child_tidptr,
 					struct pid *pid,
-					int trace)
+					int trace,
+					struct task_struct* from,
+					int mach_mode)
 {
 	int retval;
 	struct task_struct *p;
 	int cgroup_callbacks_done = 0;
 
+	/*
+	 * Can't copy remote task if we're not doing a thread clone.
+	 */
+	BUG_ON(!(clone_flags & CLONE_THREAD) && from != current);
+
+
 	if ((clone_flags & (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))
 		return ERR_PTR(-EINVAL);
 
@@ -1014,7 +1061,7 @@
 		goto fork_out;
 
 	retval = -ENOMEM;
-	p = dup_task_struct(current);
+	p = dup_task_struct(from);
 	if (!p)
 		goto fork_out;
 
@@ -1140,23 +1187,37 @@
 	if ((retval = audit_alloc(p)))
 		goto bad_fork_cleanup_policy;
 	/* copy all the process information */
-	if ((retval = copy_semundo(clone_flags, p)))
+
+	/* can't be fucked to sort out IPC semaphores */
+	/*
+	if ((retval = copy_semundo_ex(clone_flags, p, from)))
 		goto bad_fork_cleanup_audit;
-	if ((retval = copy_files(clone_flags, p)))
+	*/
+
+	/* perform extended copy */
+	if ((retval = copy_files_ex(clone_flags, p, from)))
 		goto bad_fork_cleanup_semundo;
-	if ((retval = copy_fs(clone_flags, p)))
+	if ((retval = copy_fs_ex(clone_flags, p, from)))
 		goto bad_fork_cleanup_files;
-	if ((retval = copy_sighand(clone_flags, p)))
+	if ((retval = copy_sighand_ex(clone_flags, p, from)))
 		goto bad_fork_cleanup_fs;
-	if ((retval = copy_signal(clone_flags, p)))
+	if ((retval = copy_signal_ex(clone_flags, p, from)))
 		goto bad_fork_cleanup_sighand;
-	if ((retval = copy_mm(clone_flags, p)))
+	if ((retval = copy_mm_ex(clone_flags, p, from)))
 		goto bad_fork_cleanup_signal;
 	if ((retval = copy_namespaces(clone_flags, p)))
 		goto bad_fork_cleanup_mm;
-	if ((retval = copy_io(clone_flags, p)))
+	if ((retval = copy_io_ex(clone_flags, p, from)))
 		goto bad_fork_cleanup_namespaces;
-	retval = copy_thread(clone_flags, stack_start, stack_size, p, regs);
+
+	/* need to use a different platform routine */
+	if (mach_mode) {
+		retval = mach_platform_copy_thread(clone_flags, stack_start, stack_size, p, regs);
+	}
+	else {
+		retval = copy_thread(clone_flags, stack_start, stack_size, p, regs);
+	}
+	
 	if (retval)
 		goto bad_fork_cleanup_io;
 
@@ -1179,6 +1240,8 @@
 		p->tgid = current->tgid;
 
 	if (current->nsproxy != p->nsproxy) {
+		BUG_ON(from != current); /* sanity */
+
 		retval = ns_cgroup_clone(p, pid);
 		if (retval)
 			goto bad_fork_free_pid;
@@ -1237,14 +1300,14 @@
 
 	/* CLONE_PARENT re-uses the old parent */
 	if (clone_flags & (CLONE_PARENT|CLONE_THREAD)) {
-		p->real_parent = current->real_parent;
-		p->parent_exec_id = current->parent_exec_id;
+		p->real_parent = from->real_parent;
+		p->parent_exec_id = from->parent_exec_id;
 	} else {
-		p->real_parent = current;
-		p->parent_exec_id = current->self_exec_id;
+		p->real_parent = from;
+		p->parent_exec_id = from->self_exec_id;
 	}
 
-	spin_lock(&current->sighand->siglock);
+	spin_lock(&from->sighand->siglock);
 
 	/*
 	 * Process group and session signals need to be delivered to just the
@@ -1255,8 +1318,8 @@
 	 * thread can't slip out of an OOM kill (or normal SIGKILL).
  	 */
 	recalc_sigpending();
-	if (signal_pending(current)) {
-		spin_unlock(&current->sighand->siglock);
+	if (signal_pending(from)) {
+		spin_unlock(&from->sighand->siglock);
 		write_unlock_irq(&tasklist_lock);
 		retval = -ERESTARTNOINTR;
 		goto bad_fork_free_pid;
@@ -1264,9 +1327,9 @@
 
 	if (clone_flags & CLONE_THREAD) {
 		current->signal->nr_threads++;
-		atomic_inc(&current->signal->live);
-		atomic_inc(&current->signal->sigcnt);
-		p->group_leader = current->group_leader;
+		atomic_inc(&from->signal->live);
+		atomic_inc(&from->signal->sigcnt);
+		p->group_leader = from->group_leader;
 		list_add_tail_rcu(&p->thread_group, &p->group_leader->thread_group);
 	}
 
@@ -1279,8 +1342,8 @@
 
 			p->signal->leader_pid = pid;
 			p->signal->tty = tty_kref_get(current->signal->tty);
-			attach_pid(p, PIDTYPE_PGID, task_pgrp(current));
-			attach_pid(p, PIDTYPE_SID, task_session(current));
+			attach_pid(p, PIDTYPE_PGID, task_pgrp(from));
+			attach_pid(p, PIDTYPE_SID, task_session(from));
 			list_add_tail(&p->sibling, &p->real_parent->children);
 			list_add_tail_rcu(&p->tasks, &init_task.tasks);
 			__get_cpu_var(process_counts)++;
@@ -1290,7 +1353,7 @@
 	}
 
 	total_forks++;
-	spin_unlock(&current->sighand->siglock);
+	spin_unlock(&from->sighand->siglock);
 	write_unlock_irq(&tasklist_lock);
 	proc_fork_connector(p);
 	cgroup_post_fork(p);
@@ -1344,6 +1407,20 @@
 	return ERR_PTR(retval);
 }
 
+/*
+ * Copy from current.
+ */
+static struct task_struct *copy_process(unsigned long clone_flags,
+					unsigned long stack_start,
+					struct pt_regs *regs,
+					unsigned long stack_size,
+					int __user *child_tidptr,
+					struct pid *pid,
+					int trace)
+{
+	return copy_process_ex(clone_flags, stack_start, regs, stack_size, child_tidptr, pid, trace, current, 0);
+}
+
 noinline struct pt_regs * __cpuinit __attribute__((weak)) idle_regs(struct pt_regs *regs)
 {
 	memset(regs, 0, sizeof(struct pt_regs));
@@ -1377,6 +1454,56 @@
 
 extern void ke_at_fork(struct task_struct *tsk, struct task_struct *parent, unsigned long clone_flags);
 
+/* Fork for something that will become a mach thread */
+long mk_thread_fork(unsigned long clone_flags,
+	      unsigned long stack_start,
+	      struct pt_regs *regs,
+	      unsigned long stack_size,
+	      struct task_struct* from,
+	      struct task_struct** out_task)
+{
+	struct task_struct *p;
+	int trace = 0;
+	long nr;
+
+	/* Sanity */
+	BUG_ON(clone_flags & CLONE_NEWUSER);
+	BUG_ON(clone_flags & CLONE_VFORK);
+	BUG_ON(clone_flags & CLONE_PARENT_SETTID);
+	BUG_ON(out_task == NULL);
+
+	/* Copy */
+	p = copy_process_ex(clone_flags, stack_start, regs, stack_size,
+			 NULL, NULL, trace, from, 1);
+	/*
+	 * Do this prior waking up the new thread - the thread pointer
+	 * might get invalid after that point, if the thread exits quickly.
+	 */
+	if (!IS_ERR(p))
+	{
+		trace_sched_process_fork(current, p);
+
+		nr = task_pid_vnr(p);
+
+		audit_finish_fork(p);
+
+		/*
+		 * We set PF_STARTING at creation in case tracing wants to
+		 * use this to distinguish a fully live task from one that
+		 * hasn't gotten to tracehook_report_clone() yet.  Now we
+		 * clear it and set the child going.
+		 */
+		p->flags &= ~PF_STARTING;
+		*out_task = p;
+	}
+	else
+	{
+		nr = PTR_ERR(p);
+	}
+
+	return nr;
+}
+
 /*
  *  Ok, this is the main fork-routine.
  *
diff -Naur ./kos//kernel/freezer.c ./kern//kernel/freezer.c
--- ./kos//kernel/freezer.c	2012-06-09 00:43:47.000000000 -0400
+++ ./kern//kernel/freezer.c	2012-08-04 09:34:25.000000000 -0400
@@ -22,6 +22,8 @@
 	clear_freeze_flag(current);
 }
 
+extern int __mach_task_suspended_loop(struct task_struct *tsk);
+
 /* Refrigerator is place where frozen processes are stored :-). */
 void refrigerator(void)
 {
@@ -30,13 +32,17 @@
 	long save;
 
 	task_lock(current);
-	if (freezing(current)) {
+
+	if (freezing(current))
+	{
 		frozen_process();
 		task_unlock(current);
-	} else {
+	} else
+	{
 		task_unlock(current);
 		return;
 	}
+
 	save = current->state;
 	pr_debug("%s entered refrigerator\n", current->comm);
 
@@ -49,8 +55,12 @@
 
 	for (;;) {
 		set_current_state(TASK_UNINTERRUPTIBLE);
+
+		__mach_task_suspended_loop(current);
+
 		if (!frozen(current))
 			break;
+
 		schedule();
 	}
 
diff -Naur ./kos//kernel/signal.c ./kern//kernel/signal.c
--- ./kos//kernel/signal.c	2012-06-09 00:43:48.000000000 -0400
+++ ./kern//kernel/signal.c	2012-07-21 13:23:35.000000000 -0400
@@ -880,6 +880,8 @@
 	return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
 }
 
+extern void ke_will_signal(struct task_struct *t, int sig);
+
 static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			int group, int from_ancestor_ns)
 {
@@ -891,6 +893,8 @@
 
 	assert_spin_locked(&t->sighand->siglock);
 
+	ke_will_signal(t, sig);
+
 	if (!prepare_signal(sig, t, from_ancestor_ns))
 		return 0;
 
diff -Naur ./kos//magenta/bsd_syscalls.c ./kern//magenta/bsd_syscalls.c
--- ./kos//magenta/bsd_syscalls.c	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/bsd_syscalls.c	2012-07-10 13:45:43.000000000 -0400
@@ -0,0 +1,48 @@
+/*
+ * bsd_syscall.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Some BSD system calls use weird argument types. So we 
+ * need to make sure that they are correct when they enter
+ * the syscall handlers and leave them.
+ */
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+#include "ke_runtime.h"
+
+long _user_bsd_lseek(unsigned int fd, long long offset, int whence)
+{
+	off_t ret;
+	
+	ret = sys_lseek(fd, (off_t)offset, whence);
+	return (long)(ret);
+}
\ No newline at end of file
diff -Naur ./kos//magenta/darwin_getdirentries.c ./kern//magenta/darwin_getdirentries.c
--- ./kos//magenta/darwin_getdirentries.c	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/darwin_getdirentries.c	2012-08-04 17:46:27.000000000 -0400
@@ -1,3 +1,10 @@
+/*
+ * darwin_getdirentries.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * BSD getdirentries syscall.
+ */
+
 #include <linux/time.h>
 #include <linux/kernel.h>
 #include <linux/mm.h>
@@ -111,11 +118,10 @@
 	return -EFAULT;
 }
 
-void get_dents_darwin(kmsg_get_directory_entries_t* km)
+size_t _user_getdirentries64(int fd, void *buf_, size_t bufsize, uint32_t *basep)
 {
-	unsigned int fd = km->fd;
-	void* dirent = km->buffer;
-	unsigned int count = km->buffer_len;
+	void* dirent = buf_;
+	unsigned int count = bufsize;
 
 	struct file * file;
 	darwin_dirent_t __user * lastdirent;
@@ -153,5 +159,5 @@
 out:
 	//printk(KERN_WARNING "get_dents_darwin(%d, %p, %d) = %d", km->fd, km->buffer, km->buffer_len, error);
 
-	__put_user(error, km->out_error);
+	return error;
 }
\ No newline at end of file
diff -Naur ./kos//magenta/Ipc.h ./kern//magenta/Ipc.h
--- ./kos//magenta/Ipc.h	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/Ipc.h	2012-08-05 16:08:36.000000000 -0400
@@ -0,0 +1,36 @@
+#ifndef _H_MG_IPC_
+#define _H_MG_IPC_
+
+#include "Standard.h"
+
+#include "ke_runtime.h"
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+kern_return_t Ipc_msg_receive_block(ipc_port* rcv_port,
+	task_port_t* task,
+	ipc_message** out_message,
+	size_t max_size,
+	boolean_t large);
+
+kern_return_t Ipc_msg_send_nonblock(ipc_port* dst_port, ipc_message* in_message);
+
+ipc_message* Ipc_message_allocate(mach_msg_header_t* head,
+	size_t size,
+	task_port_t* from_task);
+
+void Ipc_message_destroy(ipc_message* message);
+
+void Ipc_port_wake_waiters(ipc_port* port);
+
+void Ipc_port_add_queue(ipc_port* port, wait_queue_head_t* queue);
+
+kern_return_t Ipc_msg_send_block(ipc_port* dst_port, ipc_message* in_message);
+
+kern_return_t Ipc_msg_receive_nonblock(ipc_port* rcv_port,
+	task_port_t* task,
+	ipc_message** out_message,
+	size_t max_size,
+	boolean_t large);
+
+#endif
\ No newline at end of file
diff -Naur ./kos//magenta/ipc_types.h ./kern//magenta/ipc_types.h
--- ./kos//magenta/ipc_types.h	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/ipc_types.h	2012-08-05 18:18:37.000000000 -0400
@@ -22,6 +22,19 @@
 #define	MACH_RCV_MSG		0x00000002
 #define MACH_RCV_LARGE		0x00000004
 
+#define MACH_SEND_TIMEOUT	0x00000010
+#define MACH_SEND_INTERRUPT	0x00000040	/* libmach implements */
+#define MACH_SEND_NOTIFY	0x00000080	/* arm send-possible notify */
+#define MACH_SEND_ALWAYS	0x00010000	/* internal use only */
+#define MACH_SEND_TRAILER	0x00020000	
+
+#define MACH_RCV_TIMEOUT	0x00000100
+#define MACH_RCV_NOTIFY		0x00000200	/* reserved - legacy */
+#define MACH_RCV_INTERRUPT	0x00000400	/* libmach implements */
+#define MACH_RCV_OVERWRITE	0x00001000
+
+#define MACH_MSG_USER	0x10000000
+
 #define MACH_MSGH_BITS_ZERO		0x00000000
 #define MACH_MSGH_BITS_REMOTE_MASK	0x000000ff
 #define MACH_MSGH_BITS_LOCAL_MASK	0x0000ff00
@@ -120,8 +133,6 @@
 	mach_msg_id_t	msgh_id;
 } mach_msg_header_t;
 
-
-
 struct mach_msg_trap_data {
 	mach_msg_header_t* msg;
 	mach_msg_option_t option;
@@ -136,9 +147,11 @@
 {
 	mach_msg_header_t head; /* just the header, for routing */
 	mach_msg_header_t* msg; /* pointer to the message in the sender's space */
-	struct task_struct* sender; /* sender */
+	task_port_t* sender; /* sender */
 	
 	struct completion send_block; /* blocking the sender while the message is enqueued */
+
+	size_t size;
 	boolean_t received;
 } ipc_message;
 
@@ -146,4 +159,5 @@
 typedef int ipc_port_index;
 typedef struct mach_msg_trap_data mach_msg_trap_data_t;
 
+
 #endif
diff -Naur ./kos//magenta/ke_array.c ./kern//magenta/ke_array.c
--- ./kos//magenta/ke_array.c	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/ke_array.c	2012-07-13 09:16:09.000000000 -0400
@@ -5,12 +5,19 @@
  * Kernel array.
  */
 
- #include "ke_runtime.h"
+#include "ke_runtime.h"
 
- #define RefToImpl() ke_array_impl* impl = (ke_array_impl*)arr
- #define HaveUpdated() /**/
- #define RetainType(tt) /**/
- #define ReleaseType(tt) /**/
+#define RefToImpl() ke_array_impl* impl = (ke_array_impl*)arr
+#define HaveUpdated() /**/
+#define RetainType(tt) /**/
+#define ReleaseType(tt) /**/
+
+ke_storage_type* __ke_array_get_base(ke_array_t arr)
+{
+	RefToImpl();
+
+	return impl->array;
+}
 
 bool ke_array_init(ke_array_t arr, unsigned int capacity)
 {
@@ -54,22 +61,22 @@
 	}
 
 	newCapacity = (((newCapacity - 1) / impl->capacityIncrement) + 1)
-                * impl->capacityIncrement;
-    newSize = sizeof(ke_storage_type) * newCapacity;
+				* impl->capacityIncrement;
+	newSize = sizeof(ke_storage_type) * newCapacity;
 
-    newArray = ke_realloc(impl->array, newSize);
+	newArray = ke_realloc(impl->array, newSize);
 
-    if (!newArray) {
-    	/* we're fucked */
-    	ke_critical("ke_array_ensure_capacity(): reallocation failed!");
-    }
-    else {
-    	/* success */
-    	impl->capacity = newCapacity;
-    	impl->array = newArray;
-    }
+	if (!newArray) {
+		/* we're fucked */
+		ke_critical("ke_array_ensure_capacity(): reallocation failed!");
+	}
+	else {
+		/* success */
+		impl->capacity = newCapacity;
+		impl->array = newArray;
+	}
 
-    return impl->capacity;
+	return impl->capacity;
 }
 
 ke_storage_type ke_array_get(ke_array_t arr, unsigned int index)
@@ -79,13 +86,13 @@
 	if (index >= impl->count)
 	{
 		/* Out of bounds */
-        return (ke_storage_type)0;
-    }
-    else
-    {
-    	/* In bounds, so return */
-        return (ke_storage_type)impl->array[index];
-    }
+		return (ke_storage_type)0;
+	}
+	else
+	{
+		/* In bounds, so return */
+		return (ke_storage_type)impl->array[index];
+	}
 }
 
 unsigned int ke_array_get_count(ke_array_t arr)
@@ -94,6 +101,29 @@
 	return impl->count;
 }
 
+void ke_array_remove(ke_array_t arr, unsigned int index)
+{
+	RefToImpl();
+	ke_storage_type old_object;
+	unsigned int i;
+
+	if (index >= impl->count) {
+		return;
+	}
+
+	HaveUpdated();
+	old_object = impl->array[index];
+
+	impl->count--;
+
+	for (i = index; i < impl->count; i++) 
+	{
+		impl->array[i] = impl->array[i+1];
+	}
+
+	ReleaseType(old_object);
+}
+
 bool ke_array_set_at(ke_array_t arr, unsigned int index, ke_storage_type anObject)
 {
 	RefToImpl();
@@ -104,7 +134,7 @@
 	if ((index > impl->count) || !anObject)
 		return false;
 
-	// do we need more space?
+	/* do we need more space? */
 	if (newCount > impl->capacity && newCount > ke_array_ensure_capacity(arr, newCount))
 		return false;
 
diff -Naur ./kos//magenta/kern_return.h ./kern//magenta/kern_return.h
--- ./kos//magenta/kern_return.h	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/kern_return.h	2012-08-05 12:10:54.000000000 -0400
@@ -0,0 +1,400 @@
+/*
+ * Copyright (c) 2000 Apple Computer, Inc. All rights reserved.
+ *
+ * @APPLE_OSREFERENCE_LICENSE_HEADER_START@
+ * 
+ * This file contains Original Code and/or Modifications of Original Code
+ * as defined in and that are subject to the Apple Public Source License
+ * Version 2.0 (the 'License'). You may not use this file except in
+ * compliance with the License. The rights granted to you under the License
+ * may not be used to create, or enable the creation or redistribution of,
+ * unlawful or unlicensed copies of an Apple operating system, or to
+ * circumvent, violate, or enable the circumvention or violation of, any
+ * terms of an Apple operating system software license agreement.
+ * 
+ * Please obtain a copy of the License at
+ * http://www.opensource.apple.com/apsl/ and read it before using this file.
+ * 
+ * The Original Code and all software distributed under the License are
+ * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
+ * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
+ * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
+ * Please see the License for the specific language governing rights and
+ * limitations under the License.
+ * 
+ * @APPLE_OSREFERENCE_LICENSE_HEADER_END@
+ */
+/*
+ * @OSF_COPYRIGHT@
+ */
+/* 
+ * Mach Operating System
+ * Copyright (c) 1991,1990,1989,1988,1987 Carnegie Mellon University
+ * All Rights Reserved.
+ * 
+ * Permission to use, copy, modify and distribute this software and its
+ * documentation is hereby granted, provided that both the copyright
+ * notice and this permission notice appear in all copies of the
+ * software, derivative works or modified versions, and any portions
+ * thereof, and that both notices appear in supporting documentation.
+ * 
+ * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
+ * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND FOR
+ * ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
+ * 
+ * Carnegie Mellon requests users of this software to return to
+ * 
+ *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU
+ *  School of Computer Science
+ *  Carnegie Mellon University
+ *  Pittsburgh PA 15213-3890
+ * 
+ * any improvements or extensions that they make and grant Carnegie Mellon
+ * the rights to redistribute these changes.
+ */
+/*
+ */
+/*
+ *	File:	h/kern_return.h
+ *	Author:	Avadis Tevanian, Jr.
+ *	Date:	1985
+ *
+ *	Kernel return codes.
+ *
+ */
+
+#ifndef	_MACH_KERN_RETURN_H_
+#define _MACH_KERN_RETURN_H_
+
+
+#define KERN_SUCCESS			0
+
+#define KERN_INVALID_ADDRESS		1
+		/* Specified address is not currently valid.
+		 */
+
+#define KERN_PROTECTION_FAILURE		2
+		/* Specified memory is valid, but does not permit the
+		 * required forms of access.
+		 */
+
+#define KERN_NO_SPACE			3
+		/* The address range specified is already in use, or
+		 * no address range of the size specified could be
+		 * found.
+		 */
+
+#define KERN_INVALID_ARGUMENT		4
+		/* The function requested was not applicable to this
+		 * type of argument, or an argument is invalid
+		 */
+
+#define KERN_FAILURE			5
+		/* The function could not be performed.  A catch-all.
+		 */
+
+#define KERN_RESOURCE_SHORTAGE		6
+		/* A system resource could not be allocated to fulfill
+		 * this request.  This failure may not be permanent.
+		 */
+
+#define KERN_NOT_RECEIVER		7
+		/* The task in question does not hold receive rights
+		 * for the port argument.
+		 */
+
+#define KERN_NO_ACCESS			8
+		/* Bogus access restriction.
+		 */
+
+#define KERN_MEMORY_FAILURE		9
+		/* During a page fault, the target address refers to a
+		 * memory object that has been destroyed.  This
+		 * failure is permanent.
+		 */
+
+#define KERN_MEMORY_ERROR		10
+		/* During a page fault, the memory object indicated
+		 * that the data could not be returned.  This failure
+		 * may be temporary; future attempts to access this
+		 * same data may succeed, as defined by the memory
+		 * object.
+		 */
+
+#define	KERN_ALREADY_IN_SET		11
+		/* The receive right is already a member of the portset.
+		 */
+
+#define KERN_NOT_IN_SET			12
+		/* The receive right is not a member of a port set.
+		 */
+
+#define KERN_NAME_EXISTS		13
+		/* The name already denotes a right in the task.
+		 */
+
+#define KERN_ABORTED			14
+		/* The operation was aborted.  Ipc code will
+		 * catch this and reflect it as a message error.
+		 */
+
+#define KERN_INVALID_NAME		15
+		/* The name doesn't denote a right in the task.
+		 */
+
+#define	KERN_INVALID_TASK		16
+		/* Target task isn't an active task.
+		 */
+
+#define KERN_INVALID_RIGHT		17
+		/* The name denotes a right, but not an appropriate right.
+		 */
+
+#define KERN_INVALID_VALUE		18
+		/* A blatant range error.
+		 */
+
+#define	KERN_UREFS_OVERFLOW		19
+		/* Operation would overflow limit on user-references.
+		 */
+
+#define	KERN_INVALID_CAPABILITY		20
+		/* The supplied (port) capability is improper.
+		 */
+
+#define KERN_RIGHT_EXISTS		21
+		/* The task already has send or receive rights
+		 * for the port under another name.
+		 */
+
+#define	KERN_INVALID_HOST		22
+		/* Target host isn't actually a host.
+		 */
+
+#define KERN_MEMORY_PRESENT		23
+		/* An attempt was made to supply "precious" data
+		 * for memory that is already present in a
+		 * memory object.
+		 */
+
+#define KERN_MEMORY_DATA_MOVED		24
+		/* A page was requested of a memory manager via
+		 * memory_object_data_request for an object using
+		 * a MEMORY_OBJECT_COPY_CALL strategy, with the
+		 * VM_PROT_WANTS_COPY flag being used to specify
+		 * that the page desired is for a copy of the
+		 * object, and the memory manager has detected
+		 * the page was pushed into a copy of the object
+		 * while the kernel was walking the shadow chain
+		 * from the copy to the object. This error code
+		 * is delivered via memory_object_data_error
+		 * and is handled by the kernel (it forces the
+		 * kernel to restart the fault). It will not be
+		 * seen by users.
+		 */
+
+#define KERN_MEMORY_RESTART_COPY	25
+		/* A strategic copy was attempted of an object
+		 * upon which a quicker copy is now possible.
+		 * The caller should retry the copy using
+		 * vm_object_copy_quickly. This error code
+		 * is seen only by the kernel.
+		 */
+
+#define KERN_INVALID_PROCESSOR_SET	26
+		/* An argument applied to assert processor set privilege
+		 * was not a processor set control port.
+		 */
+
+#define KERN_POLICY_LIMIT		27
+		/* The specified scheduling attributes exceed the thread's
+		 * limits.
+		 */
+
+#define KERN_INVALID_POLICY		28
+		/* The specified scheduling policy is not currently
+		 * enabled for the processor set.
+		 */
+
+#define KERN_INVALID_OBJECT		29
+		/* The external memory manager failed to initialize the
+		 * memory object.
+		 */
+
+#define KERN_ALREADY_WAITING		30
+		/* A thread is attempting to wait for an event for which 
+		 * there is already a waiting thread.
+		 */
+
+#define KERN_DEFAULT_SET		31
+		/* An attempt was made to destroy the default processor
+		 * set.
+		 */
+
+#define KERN_EXCEPTION_PROTECTED	32
+		/* An attempt was made to fetch an exception port that is
+		 * protected, or to abort a thread while processing a
+		 * protected exception.
+		 */
+
+#define KERN_INVALID_LEDGER		33
+		/* A ledger was required but not supplied.
+		 */
+
+#define KERN_INVALID_MEMORY_CONTROL	34
+		/* The port was not a memory cache control port.
+		 */
+
+#define KERN_INVALID_SECURITY		35
+		/* An argument supplied to assert security privilege 	
+		 * was not a host security port.
+		 */
+		
+#define KERN_NOT_DEPRESSED		36
+		/* thread_depress_abort was called on a thread which
+		 * was not currently depressed.
+		 */
+		
+#define KERN_TERMINATED			37
+		/* Object has been terminated and is no longer available
+		 */
+
+#define KERN_LOCK_SET_DESTROYED		38
+		/* Lock set has been destroyed and is no longer available.
+		 */
+
+#define KERN_LOCK_UNSTABLE		39
+		/* The thread holding the lock terminated before releasing
+		 * the lock
+		 */
+
+#define KERN_LOCK_OWNED			40
+		/* The lock is already owned by another thread
+		 */
+
+#define KERN_LOCK_OWNED_SELF		41
+		/* The lock is already owned by the calling thread
+		 */
+
+#define KERN_SEMAPHORE_DESTROYED	42
+		/* Semaphore has been destroyed and is no longer available.
+		 */
+
+#define KERN_RPC_SERVER_TERMINATED	43
+		/* Return from RPC indicating the target server was 
+		 * terminated before it successfully replied 
+		 */
+
+#define KERN_RPC_TERMINATE_ORPHAN	44
+		/* Terminate an orphaned activation.
+		 */
+
+#define KERN_RPC_CONTINUE_ORPHAN	45
+		/* Allow an orphaned activation to continue executing.
+		 */
+
+#define	KERN_NOT_SUPPORTED		46
+		/* Empty thread activation (No thread linked to it)
+		 */
+
+#define	KERN_NODE_DOWN			47
+		/* Remote node down or inaccessible.
+		 */
+
+#define KERN_NOT_WAITING		48
+		/* A signalled thread was not actually waiting. */
+
+#define	KERN_OPERATION_TIMED_OUT        49
+		/* Some thread-oriented operation (semaphore_wait) timed out
+		 */
+
+#define KERN_CODESIGN_ERROR		50
+		/* During a page fault, indicates that the page was rejected
+		 * as a result of a signature check.
+		 */
+
+#define	KERN_RETURN_MAX			0x100
+		/* Maximum return value allowable
+		 */
+
+#define MACH_MSG_SUCCESS		0x00000000
+
+
+#define	MACH_MSG_MASK			0x00003e00
+		/* All special error code bits defined below. */
+#define	MACH_MSG_IPC_SPACE		0x00002000
+		/* No room in IPC name space for another capability name. */
+#define	MACH_MSG_VM_SPACE		0x00001000
+		/* No room in VM address space for out-of-line memory. */
+#define	MACH_MSG_IPC_KERNEL		0x00000800
+		/* Kernel resource shortage handling an IPC capability. */
+#define	MACH_MSG_VM_KERNEL		0x00000400
+		/* Kernel resource shortage handling out-of-line memory. */
+
+#define MACH_SEND_IN_PROGRESS		0x10000001
+		/* Thread is waiting to send.  (Internal use only.) */
+#define MACH_SEND_INVALID_DATA		0x10000002
+		/* Bogus in-line data. */
+#define MACH_SEND_INVALID_DEST		0x10000003
+		/* Bogus destination port. */
+#define MACH_SEND_TIMED_OUT		0x10000004
+		/* Message not sent before timeout expired. */
+#define MACH_SEND_INTERRUPTED		0x10000007
+		/* Software interrupt. */
+#define MACH_SEND_MSG_TOO_SMALL		0x10000008
+		/* Data doesn't contain a complete message. */
+#define MACH_SEND_INVALID_REPLY		0x10000009
+		/* Bogus reply port. */
+#define MACH_SEND_INVALID_RIGHT		0x1000000a
+		/* Bogus port rights in the message body. */
+#define MACH_SEND_INVALID_NOTIFY	0x1000000b
+		/* Bogus notify port argument. */
+#define MACH_SEND_INVALID_MEMORY	0x1000000c
+		/* Invalid out-of-line memory pointer. */
+#define MACH_SEND_NO_BUFFER		0x1000000d
+		/* No message buffer is available. */
+#define MACH_SEND_TOO_LARGE		0x1000000e
+		/* Send is too large for port */
+#define MACH_SEND_INVALID_TYPE		0x1000000f
+		/* Invalid msg-type specification. */
+#define MACH_SEND_INVALID_HEADER	0x10000010
+		/* A field in the header had a bad value. */
+#define MACH_SEND_INVALID_TRAILER	0x10000011
+		/* The trailer to be sent does not match kernel format. */
+#define MACH_SEND_INVALID_RT_OOL_SIZE	0x10000015
+		/* compatibility: no longer a returned error */
+
+#define MACH_RCV_IN_PROGRESS		0x10004001
+		/* Thread is waiting for receive.  (Internal use only.) */
+#define MACH_RCV_INVALID_NAME		0x10004002
+		/* Bogus name for receive port/port-set. */
+#define MACH_RCV_TIMED_OUT		0x10004003
+		/* Didn't get a message within the timeout value. */
+#define MACH_RCV_TOO_LARGE		0x10004004
+		/* Message buffer is not large enough for inline data. */
+#define MACH_RCV_INTERRUPTED		0x10004005
+		/* Software interrupt. */
+#define MACH_RCV_PORT_CHANGED		0x10004006
+		/* compatibility: no longer a returned error */
+#define MACH_RCV_INVALID_NOTIFY		0x10004007
+		/* Bogus notify port argument. */
+#define MACH_RCV_INVALID_DATA		0x10004008
+		/* Bogus message buffer for inline data. */
+#define MACH_RCV_PORT_DIED		0x10004009
+		/* Port/set was sent away/died during receive. */
+#define	MACH_RCV_IN_SET			0x1000400a
+		/* compatibility: no longer a returned error */
+#define	MACH_RCV_HEADER_ERROR		0x1000400b
+		/* Error receiving message header.  See special bits. */
+#define	MACH_RCV_BODY_ERROR		0x1000400c
+		/* Error receiving message body.  See special bits. */
+#define	MACH_RCV_INVALID_TYPE		0x1000400d
+		/* Invalid msg-type specification in scatter list. */
+#define	MACH_RCV_SCATTER_SMALL		0x1000400e
+		/* Out-of-line overwrite region is not large enough */
+#define MACH_RCV_INVALID_TRAILER	0x1000400f
+		/* trailer type or number of trailer elements not supported */
+#define MACH_RCV_IN_PROGRESS_TIMED      0x10004011
+
+#endif	/* _MACH_KERN_RETURN_H_ */
diff -Naur ./kos//magenta/ke_runtime.c ./kern//magenta/ke_runtime.c
--- ./kos//magenta/ke_runtime.c	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/ke_runtime.c	2012-08-06 10:27:43.000000000 -0400
@@ -1,5 +1,5 @@
 /*
- * ke_runtimey.c
+ * ke_runtime.c
  * Copyright (c) 2012 Christina Brooks
  *
  * Kernel runtime support.
@@ -9,10 +9,17 @@
 #include <linux/module.h>
 #include <linux/sched.h>
 #include <linux/binfmts.h>
+#include <linux/signal.h>
+
+#include "mach_port_types.h"
 
 /* External initializers */
 extern int init_mach_ipc(void);
+extern int init_macho_binfmt(void);
 static bool _ke_initialized = false;
+extern void __ke_memtest(void);
+extern void mach_host_init(void);
+extern void mach_thread_bootstrap(struct task_struct* task);
 
 void* ke_alloc(size_t size)
 {
@@ -24,13 +31,28 @@
 	kfree(ptr);
 }
 
+void ke_will_signal(struct task_struct *t, int sig)
+{
+	return;
+}
+
 void* ke_realloc(void* ptr, size_t size)
 {
 	return krealloc(ptr, size, GFP_KERNEL);
 }
 
+/*
+ * Called when the darwin system call number is invalid.
+ */
+void ke_darwin_syscall_error(int c)
+{
+	panic("ke_darwin_syscall_error(): invalid trap #: %d", c);
+}
+
 void ke_at_fork(struct task_struct *task, struct task_struct *parent, unsigned long clone_flags)
 {
+	boolean_t need_ref = false;
+
 	if (!_ke_initialized) {
 		return;
 	}
@@ -43,8 +65,34 @@
 		 * them from parents.
 		 */
 		
-		printk("ke_at_fork(): creating task port\n");
-		ke_setup_task_port(task);
+		Xlog("creating task port for task[%p]", task);
+		Native_setup_task(task);
+	}
+	else
+	{
+		need_ref = true;
+	}
+
+	if (task->mm)
+	{
+		/*
+		 * Every single user scheduler entry must have a thread
+		 * port attached to it.
+		 */
+
+		task->thread_port = NULL;
+
+		/* This should increase the refcount ... */
+		mach_thread_bootstrap(task);
+
+		if (!need_ref)
+		{
+			/* ... so decrease it. */
+			PortRelease(task->task_port);
+
+			/* And do a sanity check */
+			BUG_ON(PortGetRefcount(task->task_port) != 1);
+		}
 	}
 }
 
@@ -66,58 +114,51 @@
 			panic("ke_setup_exec(): pid 1 has a task port already");
 		}
 
-		printk("ke_setup_exec(): creating task port for pid 1\n");
-		ke_setup_task_port(current);
-	}
+		Xlog("creating task & thread ports for pid 1");
+		Native_setup_task(current);
+		mach_thread_bootstrap(current);
 
-	printk("ke_setup_exec(): setup\n");
+		__ke_memtest();
+	}
 }
 
 void ke_process_exit(struct task_struct *tsk)
 {
+	task_port_t* tp;
+	int refcount;
+
 	if (!_ke_initialized) {
 		return;
 	}
 
-	printk("ke_process_exit(): exit\n");
-}
-
-static void __ke_runtime_test(void)
-{
-	ke_array_t arr = ke_array_with_capacity(10);
+	/*
+	 * Only do it if the task has a task port.
+	 * Otherwise it's a kthread.
+	 */
+	if (tsk->task_port)
+	{
+		tp = Native_get_task(tsk);
 
-	ke_array_set_at(arr, 0, (ke_storage_type)1234);
-	ke_array_set_at(arr, 1, (ke_storage_type)4321);
-	ke_array_set_at(arr, 2, (ke_storage_type)5555);
-	ke_array_set_at(arr, 3, (ke_storage_type)777);
+		/* Thread is now dead, decrease the refcount */
+		mach_task_dec_thread_count(tp);
 
-	printk("2: %d 3: %d \n", (int)ke_array_get(arr, 2), (int)ke_array_get(arr, 3));
+		refcount = PortGetRefcount(tp) - 1; /* ignore the current ref */
+		
+		Xlog("exit, task port has %d references", refcount);
 
-	return;
+		PortRelease(tp);
+	}
 }
 
-static int __init __ke_runtime_init(void)
+int __init __ke_runtime_init(void)
 {
 	init_mach_ipc();
-
-	__ke_runtime_test();
-
+	init_macho_binfmt();
+	mach_host_init();
+	
 	_ke_initialized = true;
 
-	printk("ke_runtime_init(): runtime started\n");
+	Xlog("runtime started, size_t: %d", sizeof(size_t));
 	return 0;
 }
 
-static void __exit __ke_runtime_teardown(void)
-{
-	ke_critical("ke_runtime_teardown(): not allowed");
-}
-
-module_init(__ke_runtime_init);
-module_exit(__ke_runtime_teardown);
-
-
-/*
- * Fuck everything about this.
- */
-MODULE_LICENSE("Proprietary");
diff -Naur ./kos//magenta/ke_runtime.h ./kern//magenta/ke_runtime.h
--- ./kos//magenta/ke_runtime.h	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/ke_runtime.h	2012-08-06 10:15:12.000000000 -0400
@@ -8,6 +8,7 @@
 #ifndef _H_MG_KE_RUNTIME_
 #define _H_MG_KE_RUNTIME_
 
+#include "libkern.h"
 
 #include <linux/kernel.h>
 #include <linux/string.h>
@@ -19,9 +20,6 @@
 #define KE_TYPE_UNKNOWN 0
 #define KE_TYPE_ARRAY 1
 
-/* void bzero(void *s, size_t n); */
-#define bzero(ptr, sz) memset(ptr, 0, sz)
-
 /**/
 #define ke_storage_type void*
 #define Boolean int
@@ -55,9 +53,25 @@
 bool ke_array_set_at(ke_array_t arr, unsigned int index, ke_storage_type anObject);
 unsigned int ke_array_get_count(ke_array_t arr);
 bool ke_array_add(ke_array_t arr, ke_storage_type anObject);
+ke_storage_type* __ke_array_get_base(ke_array_t arr);
+
+int ke_log(const char *fmt, ...);
+int ke_warn(const char *fmt, ...);
+
+int OSLog(const char *fmt, ...);
+int OSLogFn(const char *fn, const char *fmt, ...);
+int OSWarnFn(const char *fn, const char *fmt, ...);
+
+#define XLog(...) OSLogFn(__FUNCTION__, __VA_ARGS__)
+#define XWarn(...) OSWarnFn(__FUNCTION__, __VA_ARGS__)
+
+/* gah easier to type */
+#define Xlog(...) OSLogFn(__FUNCTION__, __VA_ARGS__)
+#define Xwarn(...) OSWarnFn(__FUNCTION__, __VA_ARGS__)
+
 
 /* Port */
-void ke_setup_task_port(struct task_struct* task);
+void Native_setup_task(struct task_struct* task);
 
 #define ke_critical panic
 
diff -Naur ./kos//magenta/kext.c ./kern//magenta/kext.c
--- ./kos//magenta/kext.c	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/kext.c	2012-08-08 10:24:18.000000000 -0400
@@ -32,13 +32,28 @@
 #include <asm/uaccess.h>
 #include <asm/cacheflush.h>
 #include <linux/linkage.h>
+#include <linux/module.h>
 
 #include "ipc_types.h"
 #include "mach_kmsg.h"
 #include "ke_runtime.h"
 #include "loader.h"
 
-int (*ray)(void);
+typedef struct kernel_symbol ksym_t;
+
+/*
+ * Symbols in the main image's symbtab.
+ */
+extern const ksym_t __start___ksymtab[];
+extern const ksym_t __stop___ksymtab[];
+extern const ksym_t __start___ksymtab_gpl[];
+extern const ksym_t __stop___ksymtab_gpl[];
+extern const ksym_t __start___ksymtab_gpl_future[];
+extern const ksym_t __stop___ksymtab_gpl_future[];
+
+static Boolean _verbose_log = false;
+
+#define doIfVerbose() if (_verbose_log)
 
 typedef struct __KXFile {
 	unsigned char *fMachO;
@@ -47,9 +62,60 @@
 	uintptr_t fSegmentOffset;
 	char *fStringBase;
 	struct nlist *fSymbolBase;
-    const struct nlist *fLocalSyms;
+	const struct nlist *fLocalSyms;
+	int fStringSectionOrdinal;
+
+	unsigned char* fSegmentBase;
+
+	int fConstructorSize;
+	void* fConstructorBase;
 } KXFile;
 
+void *kmalloc_non_inline(size_t size, gfp_t flags)
+{
+	return kmalloc(size, flags);
+}
+EXPORT_SYMBOL(kmalloc_non_inline);
+
+const ksym_t*
+find_kernel_symbol_in(const char* name, const ksym_t* start, const ksym_t* end)
+{
+	const ksym_t* sym = start;
+
+	while (1) {
+		if (strcmp(sym->name, name) == 0) {
+			/* Found */
+			return sym;
+		}
+
+		sym++;
+
+		if (sym > end) {
+			break;
+		}
+	}
+
+	return FALSE;
+}
+
+ksym_t*
+find_kernel_symbol(const char* name)
+{
+	const ksym_t* sym = NULL;
+
+	if (!sym) {
+		sym = find_kernel_symbol_in(name, __start___ksymtab, __stop___ksymtab);
+	}
+
+	return (ksym_t*)sym;
+}
+
+void*
+kld_alloc(size_t sz)
+{
+	return ke_alloc(sz);
+}
+
 static const struct nlist *
 kld_find_symbol_by_name(KXFile *file, const char* name)
 {
@@ -95,13 +161,19 @@
 	sym = file->fSymbolBase;
 	
 	while (nsyms--) {
+		uint32_t addr = (uint32_t)entry;
 		/*
 		if ((sym->n_type & N_EXT))
 			return NULL;
 		*/
 		
-		if (sym->n_value == (unsigned long) entry && !(sym->n_type & N_STAB))
+		if (sym->n_desc & N_ARM_THUMB_DEF) {
+			addr = addr & ~1;
+		}
+
+		if (sym->n_value == addr && !(sym->n_type & N_STAB)) {
 			return sym;
+		}
 		
 		sym += 1;
 	}
@@ -115,7 +187,7 @@
 	uint32_t nreloc;
 	struct relocation_info *rinfo;
 	
-	sbase = (uint8_t*)sect->offset;
+	sbase = (uint8_t*)sect->addr;
 	nreloc = sect->nreloc;
 	rinfo = (struct relocation_info *)(file->fMachO + sect->reloff);
 	
@@ -123,42 +195,42 @@
 		void** entry;
 		void** abs_entry;
 		unsigned long r_symbolnum, r_length;
-		const struct nlist *symbol;
+		const struct nlist *symbol = NULL;
 		enum reloc_type_generic r_type;
-		void *addr;
+		void *addr = NULL;
 		
 		/* Ignore scattered relocations */
 		if ((rinfo->r_address & R_SCATTERED))
+		{
 			continue;
+		}
 		
 		/* This is why we can't have nice things */
 		entry = (void**)( (uintptr_t)rinfo->r_address + (uintptr_t)sbase );
-		abs_entry = ((void**)( (uintptr_t)file->fMachO + (uintptr_t)entry ));
+		abs_entry = ((void**)( (uintptr_t)file->fSegmentBase + (uintptr_t)entry ));
 		
 		r_type = (enum reloc_type_generic)rinfo->r_type;
 		r_length = rinfo->r_length;
 		
 		/*
-			In r_length, 2 stands for long.
+		 * In r_length, 2 stands for long.
 		 */
 		if (r_type != GENERIC_RELOC_VANILLA || r_length != 2)
+		{
 			continue;
+		}
 		
 		r_symbolnum = rinfo->r_symbolnum;
-		
-		printk(KERN_WARNING "KldRelocSect: {t=%d, ba=%p, aa=%p, ln=%d, n=%ld}\n",
-			   rinfo->r_type,
-			   (void*)rinfo->r_address, /* relative */
-			   entry, /* absolute (within the file) */
-			   rinfo->r_length,
-			   r_symbolnum);
-		
+
 		if (rinfo->r_extern) {
 			/* External symbol entry */
-			
+			long strx;
+			const char *symname;
+			ksym_t* ks; 
+
 			if(r_symbolnum >= file->fSymtab->nsyms)
 			{
-				printk(KERN_WARNING "KldRelocSect: invalid reloc entry\n");
+				Xlog("invalid reloc entry");
 				return false;
 			}
 			
@@ -175,33 +247,106 @@
 			symbol = &symbol[r_symbolnum];
 			
 			if (symbol->n_type != (N_EXT | N_UNDF)) {
-				printk(KERN_WARNING "KldRelocSect: invalid reloc symbol type - !(N_EXT | N_UNDF)\n");
+				Xwarn("invalid reloc symbol type - !(N_EXT | N_UNDF)");
+				return false;
+			}
+
+			strx = symbol->n_un.n_strx;
+			symname = file->fStringBase + strx;
+			
+			if (symname[0] == '_') {
+				symname++;
+			}
+			else {
+				Xwarn("'%s' doesn't start with '_'", symname);
 				return false;
 			}
+
+			ks = find_kernel_symbol(symname);
+			if (!ks) {
+				Xwarn("failed to resolve '%s'", symname);
+				return false;
+			}
+
+			doIfVerbose() {
+				Xlog("\tBind    : sym_addr=%p, r_addr= %p, l_addr= %p, nm= '%s', ks= %p",
+					(void*)symbol,
+					(void*)rinfo->r_address,
+					(void*)addr,
+					symname,
+					(void*)ks);
+			}	
+
+			*abs_entry = (void*)(ks->value);
 		}
 		else {
-			/* Local symbol entry */
-			
+			/*
+			 * Relocate a local symbol. Local symbols in object files
+			 * are not attached to each other which means that all jumps
+			 * have to be fixed up.
+			 */
+
 			/* Derp */
 			if (r_symbolnum == R_ABS)
+			{
+				rinfo++;
 				continue;
+			}
 			
 			/* Not this pointer crap again */
 			addr = *abs_entry;
+
+			if (r_symbolnum == file->fStringSectionOrdinal)
+			{
+				/*
+				 * This is a string section
+				 * Here we just need to slide the pointers relative to
+				 * the load address of the segment.
+				 */
+
+				doIfVerbose() {
+					Xlog("\tRelocate: (cstr) l_addr: %p, val: %p",
+						(void*)symbol,
+						(void*)addr);
+				}
+
+				*abs_entry = ((void*)( (uintptr_t)file->fSegmentBase + (uintptr_t)addr) );
+
+				rinfo++;
+				continue;
+			}
+
 			symbol = kld_find_symbol_by_address(file, addr);
 			
-			printk(KERN_WARNING "KldRelocSect: findByAddr(%p) = %p\n", 
-				   addr,
-				   symbol);
+			if (symbol) {
+				uint32_t val = symbol->n_value;
+
+				if (symbol->n_desc & N_ARM_THUMB_DEF) {
+					val |= 1;
+				}
+
+				/* reloc "(uintptr_t)sbase +" */
+				*abs_entry = ((void*)( (uintptr_t)file->fSegmentBase +  (uintptr_t)val ));
+
+				doIfVerbose() {
+					Xlog("\tRelocate: sym_record= %p, sect_base= %p, sym_value= %p, relocated_to= %p",
+						(void*)symbol,
+						(void*)sect->offset,
+						(void*)val,
+						(void*)*abs_entry);
+				}
+			}
+			else {
+
+				doIfVerbose() {
+					Xwarn("can't find symbol at %p (ord: %d)",
+						(void*)addr,
+						(int)r_symbolnum);
+				}
+
+				return false;
+			}
 		}
-		
-		/* Resolve */
-		
-		/* Good, move on */
-		printk(KERN_WARNING "KldRelocSect: FINAL {val=%p, sym=%p, ent=%p}\n",
-			   *abs_entry,
-			   symbol,
-			   rinfo);
 
 		rinfo++;
 	}
@@ -209,45 +354,60 @@
 	return true;
 }
 
+Boolean kld_transfer(KXFile* file, void* src, void* dest, size_t sz)
+{
+	void* in_src = (void*)((uintptr_t)file->fMachO + (uintptr_t)src);
+	bcopy(in_src, dest, sz);
+
+	return true;
+}
+
 Boolean kld_parse_symtab(KXFile* file)
 {
 	const struct nlist *sym;
-    unsigned int i, firstlocal = 0, nsyms;
-    unsigned long strsize;
-    const char *strbase;
-	
-	file->fSymbolBase = 
-	(struct nlist *)(file->fMachO + file->fSymtab->symoff); 
-	
-	file->fStringBase = 
-	(char *)(file->fMachO + file->fSymtab->stroff);
-	
-	i = 0;
+	unsigned int i, firstlocal = 0, nsyms;
+	const char *strbase;
+	unsigned int strsize;
+	unsigned int symsize;
+
 	nsyms = file->fSymtab->nsyms;
-	strsize = file->fSymtab->strsize;
-	strbase = file->fStringBase;
-	sym = file->fSymbolBase;
+	symsize = nsyms * sizeof(struct nlist);
 	
+	/* load the symbols */
+	sym = (const struct nlist *)kld_alloc(symsize);
+	kld_transfer(file, (void*)file->fSymtab->symoff, (void*)sym, symsize);
+	file->fSymbolBase = sym;
+
+	/* load the string table */
+	strsize = file->fSymtab->strsize;
+	strbase = kld_alloc(strsize);
+	kld_transfer(file, (void*)file->fSymtab->stroff, strbase, strsize);
+	file->fStringBase = strbase;
+
+	i = 0;
+
 	while (i < nsyms) {
 		long strx = sym->n_un.n_strx;
-        const char *symname = strbase + strx;
-        unsigned char n_type = sym->n_type & N_TYPE;
-		
-		printk(KERN_WARNING "KldParseSymtab: {type=%d, val=%p} '%s'\n",
-			   n_type,
-			   (void*)sym->n_value,
-			   symname);
+		const char *symname = strbase + strx;
+		unsigned char n_type = sym->n_type & N_TYPE;
 		
+		doIfVerbose() {
+			Xlog("type=%d, val=%p, name='%s'",
+				   n_type,
+				   (void*)sym->n_value,
+				   symname);
+		}
+
 		n_type = sym->n_type & (N_TYPE | N_EXT);
 		
-        /*
-			First exported symbol 
-			This is done for the sake of performance
+		/*
+		 * First exported symbol 
+		 * This is done for the sake of performance
 		 */
-        if ( !firstlocal && (n_type & N_EXT) ) {
-            firstlocal = i;
-            file->fLocalSyms = sym;
-        }
+		if ( !firstlocal && (n_type & N_EXT) ) {
+			firstlocal = i;
+			file->fLocalSyms = sym;
+		}
 		
 		/* Increment stuff */
 		i += 1;
@@ -255,33 +415,88 @@
 	}
 	
 	if (!file->fLocalSyms) {
-		printk(KERN_WARNING "KldParseSymtab: no symbols found\n");
+		Xlog("no symbols found");
 		return false;
 	}
 	
-	printk(KERN_WARNING "KldParseSymtab: {loc=%p}\n",
-		   file->fLocalSyms);
-	
+	doIfVerbose() {
+		Xlog("{loc=%p}",
+				file->fLocalSyms);
+	}
+
+	return true;
+}
+
+Boolean kld_map_sect(KXFile* file, struct section* sect)
+{
+	uintptr_t sect_mem_addr = 
+	((uintptr_t)( (uintptr_t)file->fSegmentBase + (uintptr_t)sect->addr ));
+
+	doIfVerbose() {
+		Xlog("addr: %p, name: '%s', type: %d, size: %d\n",
+				   (void*)sect->addr,
+				   sect->sectname,
+				   (int)(sect->flags & SECTION_TYPE),
+				   (int)sect->size);
+	}
+
+	if ((sect->flags & SECTION_TYPE) == S_ZEROFILL)
+	{
+		memset((void*)sect_mem_addr, 0, sect->size);
+	}
+	else {
+		kld_transfer(file, (void*)sect->offset, (void*)sect_mem_addr, sect->size);
+	}
+
+	if (strcmp("__constructor", sect->sectname) == 0)
+	{
+		/* global constructors */
+		file->fConstructorBase = (void*)sect_mem_addr;
+		file->fConstructorSize = sect->size;
+	}
+
 	return true;
 }
 
 Boolean kld_process_segment(KXFile* file, struct segment_command* seg) 
 {
-	struct section* sect;
-	uint32_t nsects;
-	
-	nsects = seg->nsects;
-	sect = (struct section*)((uintptr_t)seg + sizeof(struct segment_command));
-	
-	while (nsects--) {
-		printk(KERN_WARNING "KldProcessSemgnet: sect {nrel=%d} '%s' \n",
-			   sect->nreloc,
-			   sect->sectname);
-		
-		kld_relocate_section(file, sect, 0);
+	struct section* sect = NULL;
+	uint32_t nsects = seg->nsects;
+	uint32_t total_size = 0;
+	int i = 0;
+
+#define iterate_sections()  \
+	sect = (struct section*)((uintptr_t)seg + sizeof(struct segment_command)); \
+	for (i = 0; i < nsects; i++, sect++) \
+
+	/* calculate total size */
+	iterate_sections()
+	{
+		total_size += sect->size;
+	}
+
+	file->fSegmentBase = kld_alloc(total_size);
+
+	Xwarn("kext mapping region: %p - %p", file->fSegmentBase, file->fSegmentBase + total_size);
+
+	/* map sections */
+	iterate_sections()
+	{
+		kld_map_sect(file, sect);
 		
-		/* Over to the next section */
-		sect++;
+		if ((sect->flags & SECTION_TYPE) == S_CSTRING_LITERALS)
+		{
+			file->fStringSectionOrdinal = i+1;
+		}
+	}
+
+	/* perform relocation */
+	iterate_sections() 
+	{
+		if (!kld_relocate_section(file, sect, 0))
+		{
+			return false;
+		}
 	}
 	
 	return true;
@@ -289,8 +504,6 @@
 
 Boolean kld_file_map(void* buffer, long size, KXFile* file)
 {
-	bzero(file, sizeof(file));
-	
 	size_t macho_header_sz = sizeof(struct mach_header);
 	uint8_t* load_commands;
 	struct mach_header* head;
@@ -305,17 +518,39 @@
 	struct segment_command *seg_hdr;
 	uintptr_t sect_offset = 0;
 	uint32_t nsects = 0;
-	
+
+	bzero(file, sizeof(file));
+
 	head = buffer;
 	load_commands = buffer + macho_header_sz;
 	
+	/* sanity */
+	if (head->magic != MH_MAGIC)
+	{
+		Xwarn("kld_file_map: not a valid mach-o (invalid magic %p)",
+			(void*)head->magic);
+
+		return false;
+	}
+
+	/* we can only load object files */
+	if (head->filetype != MH_OBJECT)
+	{
+		Xwarn("kld_file_map: wrong mach-o type (invalid filetype %p)",
+			(void*)head->filetype);
+
+		return false;
+	}
+
 	offset = 0;
 	ncmds = head->ncmds;
 	
 	file->fMachO = buffer;
 	
-	printk(KERN_WARNING "KldMap: macho {fl=%d}\n", head->flags);
-	
+	doIfVerbose() {
+		Xlog("macho {fl=%d}", head->flags);
+	}
+
 	while (ncmds--) {
 		struct load_command	*lcp = 
 		(struct load_command *)(load_commands + offset);
@@ -327,7 +562,7 @@
 		    lcp->cmdsize < sizeof(struct load_command) ||
 		    offset > head->sizeofcmds + macho_header_sz)
 		{
-			printk(KERN_WARNING "KldMap: malformed load command\n");
+			Xlog("malformed load command");
 			return false;
 		}
 		
@@ -338,7 +573,7 @@
 			case LC_SEGMENT:
 			{
 				if (has_segment) {
-					printk(KERN_WARNING "KldMap: more than one segment in the file \n");
+					Xwarn("more than one segment in the file");
 					return false;
 				}
 				
@@ -349,14 +584,17 @@
 				
 				file->fSegmentOffset = seg_hdr->fileoff;
 				
-				printk(KERN_WARNING "KldMap: LC_SEGMENT {nsects=%d} \n",
-					   seg_hdr->nsects);
+				doIfVerbose() {
+					Xlog("LC_SEGMENT {nsects=%d}",
+					  	 seg_hdr->nsects);
+				}
 				
 				has_segment = TRUE;
 				
 				break;
 			}
 			case LC_UUID:
+			case LC_DYSYMTAB:
 			{
 				/* Do. Not. Care. */
 				break;
@@ -368,8 +606,8 @@
 			}
 			default:
 			{
-				printk(KERN_WARNING "KldMap: unsupported load command %d \n",
-					   lcp->cmd);
+				Xwarn("unsupported load command %d",
+						lcp->cmd);
 				
 				return false;
 				break;
@@ -378,7 +616,7 @@
 	}
 	
 	if (!file->fSymtab) {
-		printk(KERN_WARNING "KldMap: object file missing symbols \n");
+		Xwarn("object file missing symbols");
 		return false;
 	}
 	else {
@@ -386,18 +624,49 @@
 	}
 	
 	if (!has_segment) {
-		printk(KERN_WARNING "KldMap: object file missing segment \n");
+		Xwarn("object file missing segment");
 		return false;
 	}
 	else {
-		kld_process_segment(file, seg_hdr);
+		if (!kld_process_segment(file, seg_hdr))
+		{
+			return false;
+		}
 	}
 	
 	return true;
 }
 
+/*
+ * Gets absoulute function address that we can branch to.
+ * Sets the thumb bit if needed.
+ */
+void* kld_get_symbol_entry(KXFile* file, const struct nlist* nl)
+{
+	uintptr_t val;
+	uint16_t* addr;
+
+	/* sanity */
+	BUG_ON(file == NULL);
+	BUG_ON(nl == NULL);
 
-void kmsg_load_kext(kmsg_load_kext_msg_t* msg)
+	val = nl->n_value;
+	addr = (uint16_t*)((val + (uintptr_t)file->fSegmentBase));
+	
+	if (nl->n_desc & N_ARM_THUMB_DEF) {
+		addr = (uint16_t*)((unsigned int)addr | 1);
+	}
+
+	return (void*)addr;
+}
+
+void abi_test(int aa, long long aaa)
+{
+	ke_log("ABI_TEST: int: %d, long: %lld\n", aa, aaa);
+}
+EXPORT_SYMBOL(abi_test);
+
+int _user_load_kext(void* buffer, size_t size)
 {
 	/* 
 	 *	mach_msg_header_t head;
@@ -406,62 +675,71 @@
 	 */
 
 	Boolean ret;
-	size_t size;
 	void* buf;
+
 	const struct nlist* nl;
+	KXFile file;
 
- 	size = msg->buffer_len;
-	buf = ke_alloc(size);
+	buf = kld_alloc(size);
 
-	if (copy_from_user(buf, msg->buffer, size))
+	if (copy_from_user(buf, buffer, size))
 	{
-	 	printk(KERN_WARNING "kmsg_load_kext: goof \n");
-		return;
-	}
-
-	KXFile file;
-	kld_file_map(buf, size, &file);
-
-	nl = kld_find_symbol_by_name(&file, "_CoolStuff");
-	
-	if (nl == NULL) {
-		printk(KERN_WARNING "kmsg_load_kext: symbol not found \n");
-		return;
+	 	Xwarn("unable to copy out buffer!");
+		return KERN_FAILURE;
 	}
-
-	uintptr_t val = nl->n_value;
-	uint16_t* whatever = (uint16_t*)((val + file.fSegmentOffset + (uintptr_t)file.fMachO) | 1);
-	
-	ray = (void*)whatever;
 	
-	printk(KERN_WARNING "func {abs=%p, rel=%p, sect=%p} \n",
-		   (void*)ray,
-		   (void*)nl->n_value,
-		   (void*)file.fSegmentOffset);
-
-	printk(KERN_WARNING "instruct: %p \n", (void*)*(whatever));
-	printk(KERN_WARNING "call {%d} \n", ray());
-}
-
-
-
-
-
-
-
-
-
-
-
-
-
-
+	if (kld_file_map(buf, size, &file))
+	{
+		uintptr_t val;
+		uint16_t* addr;
+		int (*kmod_init)(void);
+		void (*static_cxx_constructor)(void);
+		void** ctor_base = NULL;
+		int kret = 0;
+		int ctor_iter = 0;
+
+		nl = kld_find_symbol_by_name(&file, "_kmod_start");
+		
+		if (nl == NULL) {
+			Xwarn("symbol not found");
+			return KERN_FAILURE;
+		}
 
+		/* call constructors */
+		ctor_base = file.fConstructorBase;
+		if (ctor_base != NULL)
+		{
+			for (ctor_iter = 0; ctor_iter < file.fConstructorSize; ctor_iter += 4)
+			{
+				const struct nlist* ctor_nl;
+				void* rel_sym_addr;
+				static_cxx_constructor = *ctor_base;
 
+				rel_sym_addr = ((void*)((uintptr_t)static_cxx_constructor - (uintptr_t)file.fSegmentBase));
 
+				ctor_nl = kld_find_symbol_by_address(&file, rel_sym_addr);
+				static_cxx_constructor = kld_get_symbol_entry(&file, ctor_nl);
 
+				Xlog("call_cxx_ctor: %p (nlist: %p) %d/%d!", static_cxx_constructor, ctor_nl, ctor_iter, file.fConstructorSize);
 
+				static_cxx_constructor();
 
+				ctor_base++;
+			}
+		}
 
+		kmod_init = kld_get_symbol_entry(&file, nl);
+			
+		/* Branch into the unknown */
+		kret = kmod_init();
 
+		Xlog("kmod returned %d", kret);
 
+		return KERN_SUCCESS;
+	}
+	else
+	{
+		Xwarn("failed to load object!");
+		return KERN_FAILURE;
+	}
+}
\ No newline at end of file
diff -Naur ./kos//magenta/libkern.c ./kern//magenta/libkern.c
--- ./kos//magenta/libkern.c	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/libkern.c	2012-08-04 17:47:18.000000000 -0400
@@ -0,0 +1,126 @@
+/*
+ * libkern.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Bits no one cares about.
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+#include <asm/thread_notify.h>
+
+#include "ke_runtime.h"
+#include "ipc_types.h"
+
+extern bool OSAtomicCompareAndSwap32( u_int32_t __oldValue, u_int32_t __newValue, volatile u_int32_t *__theValue );
+EXPORT_SYMBOL(OSAtomicCompareAndSwap32);
+
+void* kalloc(size_t size)
+{
+	void* ret = kmalloc(size, GFP_KERNEL);
+	return ret;
+}
+EXPORT_SYMBOL(kalloc);
+
+/* void *memcpy(void *dest, const void *src, size_t n); */
+void bcopy(const void *src, void *dest, size_t n)
+{
+	memmove(dest, src, n);
+}
+EXPORT_SYMBOL(bcopy);
+
+void bzero(void* base, size_t size)
+{
+	memset(base, 0, size);
+}
+EXPORT_SYMBOL(bzero);
+
+/* hax */
+void _Z5kfreePvm(void* addr, unsigned long size)
+{
+	kfree(addr);
+}
+EXPORT_SYMBOL(_Z5kfreePvm);
+
+/* pure virtual function can't ever be called */
+void __cxa_pure_virtual( void )    { panic("%s", __FUNCTION__); }
+void __pure_virtual( void )        { panic("%s", __FUNCTION__); }
+
+EXPORT_SYMBOL(__cxa_pure_virtual);
+EXPORT_SYMBOL(__pure_virtual);
+
+/* operator delete(void *) */
+void _ZdlPv(void* ptr)
+{	
+	kfree(ptr);
+}
+EXPORT_SYMBOL(_ZdlPv);
+
+/* operator delete[](void *) */
+void _ZdaPv(void* ptr)
+{	
+	kfree(ptr);
+}
+EXPORT_SYMBOL(_ZdaPv);
+
+/* operator new[](unsigned long) */
+void* _Znam(unsigned long size)
+{
+	void* ret;
+
+	ret = kalloc(size);
+
+	if (!ret) {
+		panic("new(): c++ allocation failed!");
+	}
+
+	bzero(ret, size);
+
+	return ret;
+}
+EXPORT_SYMBOL(_Znam);
+
+/* operator new(unsigned long) */
+void* _Znwm(unsigned long size)
+{
+	void* ret;
+
+	ret = kalloc(size);
+
+	if (!ret) {
+		panic("new(): c++ allocation failed!");
+	}
+
+	bzero(ret, size);
+
+	return ret;
+}
+EXPORT_SYMBOL(_Znwm);
\ No newline at end of file
diff -Naur ./kos//magenta/libkern.h ./kern//magenta/libkern.h
--- ./kos//magenta/libkern.h	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/libkern.h	2012-08-04 17:47:23.000000000 -0400
@@ -0,0 +1,21 @@
+/*
+ * libkern.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Bits no one cares about.
+ */
+
+#ifndef _H_MG_LIBK_
+#define _H_MG_LIBK_
+
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+
+#include <DarwinTypes.h>
+#include <MachO.h>
+
+void bzero(void* base, size_t size);
+void bcopy(const void *src, void *dest, size_t n);
+
+#endif
\ No newline at end of file
diff -Naur ./kos//magenta/loader.h ./kern//magenta/loader.h
--- ./kos//magenta/loader.h	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/loader.h	2012-06-16 17:04:07.000000000 -0400
@@ -12,6 +12,27 @@
 #include <DarwinTypes.h>
 #include <MachO.h>
 
+/* Section */
+
+ /*
+ * The flags field of a section structure is separated into two parts a section
+ * type and section attributes.  The section types are mutually exclusive (it
+ * can only have one type) but the section attributes are not (it may have more
+ * than one attribute).
+ */
+#define SECTION_TYPE		 0x000000ff	/* 256 section types */
+#define SECTION_ATTRIBUTES	 0xffffff00	/*  24 section attributes */
+
+/* Constants for the type of a section */
+#define	S_REGULAR		0x0	/* regular section */
+#define	S_ZEROFILL		0x1	/* zero fill on demand section */
+#define	S_CSTRING_LITERALS	0x2	/* section with only literal C strings*/
+#define	S_4BYTE_LITERALS	0x3	/* section with only 4 byte literals */
+#define	S_8BYTE_LITERALS	0x4	/* section with only 8 byte literals */
+#define	S_LITERAL_POINTERS	0x5	/* section with only pointers to */
+					/*  literals */
+
+
 /* Nlist */
 
 #define	N_STAB	0xe0  /* if any of these bits set, a symbolic debugging entry */
diff -Naur ./kos//magenta/Log.c ./kern//magenta/Log.c
--- ./kos//magenta/Log.c	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/Log.c	2012-08-08 10:19:02.000000000 -0400
@@ -0,0 +1,129 @@
+/*
+ * Log.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Logging stuff.
+ */
+
+#include "ke_runtime.h"
+
+/*
+ * Logging routine.
+ */
+#define ChristinasSillyUartDebugging 1
+#define BRIGHT 		1
+
+#define BLACK 		0
+#define RED		1
+#define GREEN		2
+#define YELLOW		3
+#define BLUE		4
+#define MAGENTA		5
+#define CYAN		6
+#define	WHITE		7
+#define VT_DEFAULT  9
+
+#define default_attributes "\33[0m"
+
+int OSLog(const char *fmt, ...)
+{
+	va_list args;
+	int r;
+
+#if defined(ChristinasSillyUartDebugging)
+	char pre[13];
+	sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, WHITE + 30, BLUE + 40);
+	printk("%s[os]%s: ", pre, default_attributes);
+#endif
+
+	va_start(args, fmt);
+	r = vprintk(fmt, args);
+	va_end(args);
+
+	printk("\n");
+
+	return r;
+}
+
+#define LOGFNC GREEN
+int OSLogFn(const char *fn, const char *fmt, ...)
+{
+	va_list args;
+	int r;
+
+#if defined(ChristinasSillyUartDebugging)
+	char pre[13];
+	sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, LOGFNC + 30, VT_DEFAULT);
+	printk("%s[kern]%s ", pre, default_attributes);
+
+	sprintf(pre, "%c[%d;%d;%dm", 0x1B, 0, LOGFNC + 30, VT_DEFAULT + 40);
+	printk("%s%s():%s ", pre, fn, default_attributes);
+#endif
+
+	va_start(args, fmt);
+	r = vprintk(fmt, args);
+	va_end(args);
+
+	printk("\n");
+
+	return r;
+}
+
+int OSWarnFn(const char *fn, const char *fmt, ...)
+{
+	va_list args;
+	int r;
+
+#if defined(ChristinasSillyUartDebugging)
+	char pre[13];
+	sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, RED + 30, VT_DEFAULT);
+	printk("%s[warn]%s ", pre, default_attributes);
+
+	sprintf(pre, "%c[%d;%d;%dm", 0x1B, 0, RED + 30, VT_DEFAULT + 40);
+	printk("%s%s():%s ", pre, fn, default_attributes);
+#endif
+
+	va_start(args, fmt);
+	r = vprintk(fmt, args);
+	va_end(args);
+
+	printk("\n");
+
+	return r;
+}
+
+int ke_log(const char *fmt, ...)
+{
+	va_list args;
+	int r;
+
+#if defined(ChristinasSillyUartDebugging)
+	char pre[13];
+	sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, WHITE + 30, BLUE + 40);
+	printk("%s[kern]%s: ", pre, default_attributes);
+#endif
+
+	va_start(args, fmt);
+	r = vprintk(fmt, args);
+	va_end(args);
+
+	return r;
+}
+
+int ke_warn(const char *fmt, ...)
+{
+	va_list args;
+	int r;
+
+#if defined(ChristinasSillyUartDebugging)
+	char pre[13];
+	sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, WHITE + 30, RED + 40);
+	printk("%s[kern]%s: ", pre, default_attributes);
+#endif
+
+	va_start(args, fmt);
+	r = vprintk(fmt, args);
+	va_end(args);
+
+	return r;
+}
\ No newline at end of file
diff -Naur ./kos//magenta/mach.c ./kern//magenta/mach.c
--- ./kos//magenta/mach.c	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/mach.c	1969-12-31 19:00:00.000000000 -0500
@@ -1,409 +0,0 @@
-/*
- * mach.c
- * Copyright (c) 2012 Christina Brooks
- *
- * Mach routines.
- */
-
-#include <linux/module.h>
-
-#include <linux/time.h>
-#include <linux/kernel.h>
-#include <linux/mm.h>
-#include <linux/mman.h>
-#include <linux/errno.h>
-#include <linux/signal.h>
-#include <linux/string.h>
-#include <linux/fs.h>
-#include <linux/file.h>
-#include <linux/stat.h>
-#include <linux/fcntl.h>
-#include <linux/ptrace.h>
-#include <linux/user.h>
-#include <linux/binfmts.h>
-#include <linux/personality.h>
-#include <linux/init.h>
-#include <linux/coredump.h>
-#include <linux/slab.h>
-#include <linux/namei.h>
-#include <linux/security.h>
-#include <linux/syscalls.h>
-#include <linux/kfifo.h>
-
-#include <asm/system.h>
-#include <asm/uaccess.h>
-#include <asm/cacheflush.h>
-#include <linux/linkage.h>
-
-#include "ipc_types.h"
-#include "mach_kmsg.h"
-
-/*
-	Port list.
-*/
-static ke_port_t ports[MAX_PORT_COUNT];
-static DECLARE_RWSEM(ports_sem);
-
-/* Handler for kernel messages */
-extern int kmsg_handle(mach_msg_header_t* msg);
-
-/*
-	Mutex for kmsgs.
-*/
-DEFINE_MUTEX(kmsg_exec_mutex);
-
-/*
- * Returns a new kernel port.
- *
- * XXX
- * This port allocator is temporary. I should really use a pid map with
- * a linked list of slabs to store the ports.
- */
-ke_port_t* ke_port_allocate(uint16_t type)
-{
-	ke_port_t* prt = NULL;
-	int i = 0;
-
-	down_write(&ports_sem);
-	while (i < MAX_PORT_COUNT) {
-		if (ports[i].type == KE_PORT_TYPE_FREE) {
-			prt = &ports[i];
-			prt->type = type;
-			break;
-		}
-
-		i++;
-	}
-	up_write(&ports_sem);
-
-	return prt;
-}
-
-/*
- * Finds a port by its mach port name.
- */
-ke_port_t* ke_port_find_named(mach_port_t name)
-{
-	ke_port_t* prt = NULL;
-	int i = 0;
-
-	down_read(&ports_sem);
-	while (i < MAX_PORT_COUNT) {
-		if (ports[i].mp == name) {
-			prt = &ports[i];
-			break;
-		}
-
-		i++;
-	}
-	up_read(&ports_sem);
-
-	return prt;
-}
-
-void ke_setup_task_port(struct task_struct* task)
-{
-	ke_port_t* kprt = NULL;
-
-	kprt = ke_port_allocate(KE_PORT_TYPE_TASK);
-	if (!kprt) {
-		panic("ke_setup_task_port(): unable to creat task port for %p", task);
-	}
-
-	/* Set the task descriptor */
-	kprt->c.tp.task = task;
-
-	/* And set the port */
-	task->task_port = (void*)kprt;
-
-	printk("ke_setup_task_port(): task %p got port %d\n", task, kprt->mp);
-}
-
-ke_port_t* ipc_port_allocate(struct task_struct* task) {
-	ke_port_t* kprt = NULL;
-	ipc_port* prt = NULL;
-	
-	kprt = ke_port_allocate(KE_PORT_TYPE_IPC);
-	if (!kprt) {
-		return NULL;
-	}
-
-	prt = &(kprt->c.ipc);
-
-	/* create a message queue */
-	if(kfifo_alloc(&(prt->queue), PAGE_SIZE, GFP_KERNEL)) {
-		panic("allocate_ipc_port: baaaaad queue alloc");
-	}
-
-	/* 
-		create a completion variable to hang on if the
-		queue is empty 
-	*/
-	init_completion(&(prt->wait_for_enqueued_data));
-
-	return kprt;
-}
-
-static void dump_mach_msg_hdr(mach_msg_header_t* head) {
-	return;
-
-	printk(KERN_WARNING "Mach Message:\n"
-	"\tbits: %p\n\tsize: %d\n\tremote: %d\n\tlocal: %d\n\tid : %d\n"
-	,(void*)head->msgh_bits, head->msgh_size, head->msgh_remote_port, head->msgh_local_port, head->msgh_id);
-}
-
-SYSCALL_DEFINE1(mach_msg_trap, struct mach_msg_trap_data __user *, usr_data)
-{
-	mach_msg_trap_data_t trap_data;
-	mach_msg_header_t tmsg;
-	mach_msg_header_t* msg;
-	ipc_message* im;
-	ipc_message* rm;
-	ke_port_t* remote;
-	ke_port_t* local;
-	int retval = 0;
-	//boolean_t internal_message = 0;
-	mach_port_t sswp; /* for swaps */
-
-	if (!current) {
-		panic("mach_msg_trap(): used without user context");
-	}
-
-	/* read in the trap data */
-	if (copy_from_user(&trap_data, usr_data, sizeof(mach_msg_trap_data_t)))
-		return -EFAULT;
-	/* read in the temp message header */	
-	if (copy_from_user(&tmsg, trap_data.msg, sizeof(mach_msg_header_t)))
-		return -EFAULT;
-
-	/*
-		Read in the entire inline message. We leave an empty space
-		at the end so we can place the message trailer there.
-
-		XXX: Needs some sort of a bounds check for kalloc.
-	*/
-	msg = (mach_msg_header_t*)kmalloc(tmsg.msgh_size + LARGEST_TRAILER_SIZE, GFP_KERNEL);
-	if (copy_from_user(msg, trap_data.msg, tmsg.msgh_size))
-		return -EFAULT;
-
-	dump_mach_msg_hdr(msg);
-
-
-	/*
-		*** KMSG message. ***
-	*/
-	if (msg->msgh_remote_port == 0 &&
-		trap_data.option & MACH_SEND_MSG) {
-		/*
-			This is a kmsg, so handle it.
-
-			Kmsgs (kernel messages) are special mach messages that
-			are not enqueued. They are handled immediatedly. They are
-			sent to remote port 0 with the MACH_SEND_MSG flag.
-		*/
-
-		mutex_lock(&kmsg_exec_mutex);
-		if (msg->msgh_id == KMSG_MACH_PORT_ALLOCATE) {
-			/*
-				Allocate a new mach port. The only type of ports
-				the userland may allocate via this function are IPC ports.
-			*/
-			kmsg_mach_port_allocate_msg_t* km = (kmsg_mach_port_allocate_msg_t*)msg;
-			ke_port_t* prt = ipc_port_allocate(current);
-			mach_port_t mp = prt->mp;
-
-			if (copy_to_user(km->port_out, &mp, sizeof(mach_port_t)))
-				retval = -EFAULT;
-		}
-		else {
-			/* This is not an IPC related message, so offload it */
-			retval = kmsg_handle(msg);
-		}
-		mutex_unlock(&kmsg_exec_mutex);
-
-		/* This is it, destroy the message. */
-		kfree(msg);
-		return retval;
-	}
-
-	if (tmsg.msgh_bits & MACH_MSGH_BITS_COMPLEX)
-	{
-		/* Complex messages are not supported yet */
-		printk("mach_msg(): complex messages not yet supported\n");
-		return -EINVAL;
-	}
-
-	/*
-		*** IPC message send. ***
-	*/
-	if (trap_data.option & MACH_SEND_MSG &&
-		tmsg.msgh_remote_port != 0) 
-	{
-		/*
-			Caller wants to send a mach message.
-		*/
-
-		/* 1). Find out where it wants to send it to. */
-		remote = ke_port_find_named(tmsg.msgh_remote_port);
-		if (!remote) {
-			 printk("mach_msg(): nonexistent remote port\n");
-			/* baaad port */
-			kfree(msg);
-			return -EINVAL;
-		}
-
-		/* Check the port type */
-		if (remote->type == KE_PORT_TYPE_TASK)
-		{
-			/* Task port, do special handling */
-
-			kfree(msg);
-			return 0;
-		}
-		else if (remote->type == KE_PORT_TYPE_IPC)
-		{
-			/* Do nothing for now */
-		}
-		else 
-		{
-			/* Can't send to this port type */
-			printk("mach_msg(): invalid remote port type\n");
-			kfree(msg);
-			return -EINVAL;
-		}
-
-		/* 2). Prepare the message. */
-		im = (ipc_message*)kmalloc(sizeof(ipc_message), GFP_KERNEL);
-		im->sender = current;
-		im->msg = msg;
-		im->head = tmsg; /* inline header */
-		im->received = 0;
-		init_completion(&(im->send_block)); /* block */
-
-		/* 3). Enqueue a pointer to the message. */
-		kfifo_in(&(remote->c.ipc.queue), &im, sizeof(im));
-		printk("enqueued message at %p\n", im);
-
-		/* 
-			4). If the receiver is waiting for queue writes, let it know.
-				that a new message just came in.
-		*/
-		complete(&(remote->c.ipc.wait_for_enqueued_data));
-	}
-
-
-	/*
-		*** IPC message receive. ***
-	*/
-	if (trap_data.option & MACH_RCV_MSG &&
-		tmsg.msgh_local_port != 0)
-	{
-		/*
-			Caller wants to receive a mach message.
-		*/
-		local = ke_port_find_named(tmsg.msgh_local_port);
-		if (!local || local->type != KE_PORT_TYPE_IPC) {
-			printk("mach_msg(): invalid local port\n");
-			/* baaad port */
-			retval = -EINVAL;
-			goto out;
-		}
-
-		if (kfifo_is_empty(&(local->c.ipc.queue))) {
-			/*
-				1). If the queue is empty, wait until something writes to it.
-			*/
-			wait_for_completion(&(local->c.ipc.wait_for_enqueued_data));
-			//printk("completion lock lifted\n", im);
-			if (kfifo_is_empty(&(local->c.ipc.queue))) {
-				/*
-					This should never happen.
-					
-					(someone just told us that a message was sent but
-					 there are no messages in the queue)
-				*/
-				panic("MACH_RCV_MSG: queue empty after completion");
-			}
-		}
-
-		/* 2). Dequeue the message pointer. */
-		kfifo_out(&(local->c.ipc.queue), &rm, sizeof(rm));
-		printk("dequeued message at %p\n", rm);
-
-		/* 
-			3). Check if this is an internal (on the same thread) message.
-				If it is, don't wait for completion at the end.
-		*/
-		if (im == rm) {
-			//internal_message = 1;
-		}
-
-		/* 
-			4). Fixup the message.
-				This involves reversing the ports and adding a trailer.
-		*/
-
-		sswp = rm->msg->msgh_local_port;
-		rm->msg->msgh_local_port = rm->msg->msgh_remote_port;
-		rm->msg->msgh_remote_port = sswp;
-		/* XXX: trailer */
-		/* grow by the trailer size */
-		//rm->msg->msgh_size += LARGEST_TRAILER_SIZE;
-
-		/* 5). Copy the message into the userspace. */
-		if (copy_to_user(trap_data.msg, rm->msg, rm->msg->msgh_size))
-		{
-			printk("can't write message %p\n", rm);
-			retval = -EFAULT;
-			goto out;
-		}
-
-		rm->received = 1;
-
-		/* 6). If the receiver is waiting for completion, let it know that we're done */
-		complete(&(rm->send_block));
-	}
-
-	retval = 0;
-out:
-	if (trap_data.option & MACH_SEND_MSG &&
-		tmsg.msgh_local_port != 0)
-	{
-		if (!im->received) {
-			/* Block this thread until the sent message is dequeued */
-			wait_for_completion(&(im->send_block));
-		}
-
-		/* Destroy the copied message buffer */
-		kfree(im->msg);
-
-		/* Destroy the ipc_message */
-		kfree(im);
-	}
-
-	return retval;
-}
-
-int init_mach_ipc(void)
-{
-	/*
-	 * Initialize all slots for valid port names.
-	 * The port names are going to start at 20.
-	 */
-	int vl = 20;
-	int i = 0;
-
-
-	down_write(&ports_sem);
-	while (i < MAX_PORT_COUNT) {
-		ports[i].mp = (mach_port_t)vl;
-
-		vl++;
-		i++;
-	}
-	up_write(&ports_sem);
-
-	printk("init_mach_ipc(): started mach ipc subsystem {max_ports=%d}\n", MAX_PORT_COUNT);
-
-	return 0;
-}
diff -Naur ./kos//magenta/mach_core.c ./kern//magenta/mach_core.c
--- ./kos//magenta/mach_core.c	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_core.c	2012-08-08 11:32:35.000000000 -0400
@@ -0,0 +1,602 @@
+/*
+ * mach_core.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Core support for:
+ * 	    > mach objects
+ *      > ipc spaces
+ *      > port rights
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+#include "VM.h"
+
+/*
+	Port list.
+*/
+static DECLARE_RWSEM(ports_sem);
+static task_port_t* kernel_task;
+static DEFINE_MUTEX(port_ref_modify_lock);
+
+#define RefModifyLockDown() mutex_lock(&port_ref_modify_lock)
+#define RefModifyLockUp() mutex_unlock(&port_ref_modify_lock)
+
+/* Task port ops */
+kern_return_t task_message_handle(void* payload, void* trap_data);
+ke_port_ops_t _task_port_ops = {task_message_handle};
+
+
+/*
+ * Zones used by the slab allocators.
+ */
+static struct kmem_cache* zone_port_rights;
+
+/* Handler for kernel messages */
+extern int kmsg_handle(mach_msg_header_t* msg);
+extern kern_return_t ipc_message_handle(void* payload);
+
+/*
+	Mutex for kmsgs.
+*/
+DEFINE_MUTEX(kmsg_exec_mutex);
+
+task_port_t* get_kernel_task(void)
+{
+	return kernel_task;
+}
+
+kern_return_t Task_get_object_if_receive(mach_port_t user_port, Obj** out, uint16_t type)
+{
+	ke_port_right_t* name;
+
+	name = Task_find_right(user_port);
+	if (!name) {
+		return KERN_INVALID_NAME;
+	}
+	if (!name->port) {
+		RightDecrementRefCount(name, r_kernel);
+		return KERN_FAILURE;
+	}
+
+	if (type == KE_PORT_TYPE_ANY)
+	{
+		type = name->port->type;
+	}
+
+	if (!IsReceiveRight(name) || name->port->type != type)
+	{
+		PortRelease(name->port);
+		RightDecrementRefCount(name, r_kernel);
+		return KERN_INVALID_RIGHT;
+	}
+
+	*out = name->port;
+	RightDecrementRefCount(name, r_kernel);
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t Task_get_object_if_send(mach_port_t user_port, Obj** out, uint16_t type)
+{
+	ke_port_right_t* name;
+
+	name = Task_find_right(user_port);
+	if (!name) {
+		return KERN_INVALID_NAME;
+	}
+	if (!name->port) {
+		RightDecrementRefCount(name, r_kernel);
+		return KERN_FAILURE;
+	}
+
+	if (type == KE_PORT_TYPE_ANY)
+	{
+		type = name->port->type;
+	}
+
+	if (!IsSendRight(name) || name->port->type != type)
+	{
+		PortRelease(name->port);
+		RightDecrementRefCount(name, r_kernel);
+		return KERN_INVALID_RIGHT;
+	}
+
+	*out = name->port;
+	RightDecrementRefCount(name, r_kernel);
+
+	return KERN_SUCCESS;
+}
+
+boolean_t __is_receive_right(ke_port_right_t* right)
+{
+	int count;
+
+	count = atomic_read(&right->r_receive);
+
+	if (count == 1) {
+		return true;
+	}
+	else if (count > 1) {
+		panic("__is_receive_right(): DEBUG: r_receive is over 1");
+	}
+
+	return false;
+}
+
+boolean_t __is_send_right(ke_port_right_t* right)
+{
+	int count;
+
+	count = atomic_read(&right->r_send);
+
+	if (count) {
+		return true;
+	}
+
+	return false;
+}
+
+boolean_t __is_port_set_right(ke_port_right_t* right)
+{
+	int count;
+
+	count = atomic_read(&right->r_port_set);
+
+	if (count) {
+		return true;
+	}
+
+	return false;
+}
+
+Obj* Obj_allocate(uint16_t object_type,
+	size_t object_size, 
+	ke_port_ops_t* object_operations)
+{
+	Obj* prt = NULL;
+
+	prt = (Obj*)kmalloc(object_size, GFP_KERNEL);
+
+	BUG_ON(prt == NULL);
+
+	memset(prt, 0, object_size);
+	
+	prt->type = object_type;
+	prt->active = true;
+	prt->ops = object_operations;
+	mutex_init(&prt->mtx);
+
+	/* One initial reference */
+	atomic_set(&prt->refs, 1);
+
+	return prt;
+}
+
+/*
+ * Returns a new kernel port.
+ */
+ke_port_t* Obj_allocate_old(uint16_t type)
+{
+	size_t port_size;
+
+	if (type == KE_PORT_TYPE_TASK) {
+		port_size = sizeof(task_port_t);
+	}
+	else if (type == KE_PORT_TYPE_IPC) {
+		port_size = sizeof(ipc_port);
+	}
+	else if (type == KE_PORT_TYPE_PORT_SET) {
+		port_size = sizeof(ipc_port_set);
+	}
+	else if (type == KE_PORT_TYPE_HOST) {
+		port_size = sizeof(host_port_t);
+	}
+	else if (type == KE_PORT_TYPE_THREAD) {
+		port_size = sizeof(thread_port_t);
+	}
+	else if (type == KE_PORT_TYPE_SEMAPHORE) {
+		port_size = sizeof(sem_port_t);
+	}
+	else {
+		panic("ke_port_allocate(): unknown port type");
+	}
+
+	return Obj_allocate(type, port_size, NULL);
+}
+
+boolean_t Obj_is_active(ke_port_t* port)
+{
+	boolean_t active;
+	active = port->active;
+
+	return active;
+}
+
+int Obj_get_refcount(ke_port_t* port)
+{
+	int ar;
+	ar = atomic_read(&port->refs);
+	return ar;
+}
+
+void Obj_release(ke_port_t* port)
+{
+	int ar;
+	ar = atomic_dec_return(&port->refs);
+
+	//ke_log("ke_port_up(%p): refcount %d\n", port, ar);
+
+	if (ar == 0) {
+		Xwarn("port[%p], refcount hit 0, need to release!", port);
+	}
+
+	if (ar < 0) {
+		panic("port refcount is smaller than 0, something is broken!");
+	}
+}
+
+boolean_t Obj_retain(ke_port_t* port)
+{
+	if (!PortActive(port)) {
+		ke_warn("ke_port_down(%p): *** inactive\n", port);
+		return false;
+	}
+	else {
+		int ar;
+		ar = atomic_inc_return(&port->refs);
+
+		//ke_log("ke_port_down(%p): refcount %d\n", port, ar);
+
+		return true;
+	}
+}
+
+ke_port_right_t* Right_allocate(void)
+{
+	ke_port_right_t* right;
+
+	right = (ke_port_right_t*)kmem_cache_alloc(zone_port_rights, GFP_KERNEL);
+
+	atomic_set(&(right->r_receive), 0);
+	atomic_set(&(right->r_send), 0);
+	atomic_set(&(right->r_port_set), 0);
+	atomic_set(&(right->r_send), 0);
+	atomic_set(&(right->r_kernel), 0);
+}
+
+void Task_add_right(task_port_t* space, ke_port_right_t* rr)
+{
+	PortLock(space);
+
+	list_add(&(rr->list), &(space->port_rights));
+
+	PortUnlock(space);
+}
+
+void ke_teardown_task(task_port_t* space) { panic("%s", __FUNCTION__); }
+
+thread_port_t* Native_get_thread(struct task_struct* task)
+{
+	RefModifyLockDown();
+
+	thread_port_t* tp = (thread_port_t*)task->thread_port;
+	PortRetain(tp);
+
+	RefModifyLockUp();
+
+	return tp;
+}
+
+task_port_t* Native_get_task(struct task_struct* task)
+{
+	RefModifyLockDown();
+
+	task_port_t* tp = (task_port_t*)task->task_port;
+	PortRetain(tp);
+
+	RefModifyLockUp();
+
+	return tp;
+}
+
+thread_port_t* Native_get_current_thread(void)
+{
+	return Native_get_thread(current);
+}
+
+task_port_t* Native_get_current_task(void)
+{
+	return Native_get_task(current);
+}
+
+
+/*
+ * Either gets an existing port right or adds it to the 
+ * ipc space (if add is specified).
+ */
+ke_port_right_t* Task_get_right(task_port_t* space, ke_port_t* fprt, boolean_t add)
+{
+	struct list_head *p;
+	ke_port_right_t* rr = NULL;
+
+	PortLock(space);
+
+	if (space->port.type != KE_PORT_TYPE_TASK) {
+		/* Only tasks can store rights */
+		PortUnlock(space);
+		goto out;
+	}
+
+	list_for_each (p, &(space->port_rights)) {
+		rr = list_entry(p, ke_port_right_t, list);
+		if (rr->port == fprt) {
+			PortUnlock(space);
+			goto out;
+		}
+	}
+
+	PortUnlock(space);
+
+	if (add)
+	{
+		/*
+		 * Right not found in the list, we need to add
+		 * a new one to it.
+		 */
+		rr = Right_allocate();
+		rr->port = fprt;
+		rr->name = Task_create_name(space);
+		Task_add_right(space, rr);
+	}
+	else
+	{
+		rr = NULL;
+		goto out_f;
+	}
+
+out:
+	if (rr) {
+		RightIncrementRefCount(rr, r_kernel);
+	}
+out_f:
+	return rr;
+}
+
+/*
+ * Creates a brand new port (not a right, an actual port)
+ * in the space. Also sets up a empty right for the port.
+ * The unassosciated right is returned.
+ * This function sets up a new port name for the port.
+ */
+ke_port_right_t* Obj_new(uint16_t type)
+{
+	ke_port_right_t* rr;
+	ke_port_t* kprt;
+
+	kprt = Obj_allocate_old(type);
+
+	/* Set up the first right */
+	rr = Right_allocate();
+	rr->port = kprt;
+	rr->urefs = 1;
+
+	return rr;
+}
+
+
+/*
+ * Finds a port right.
+ */
+ke_port_right_t* Task_find_right(mach_port_t name)
+{
+	ke_port_right_t* prt = NULL;
+	task_port_t* space;
+	ke_port_right_t* rr;
+	struct list_head *p;
+
+	space = ke_get_current_task();
+
+	RefModifyLockDown();
+
+	PortLock(space);
+	list_for_each (p, &(space->port_rights)) {
+		rr = list_entry(p, ke_port_right_t, list);
+		if (rr->name == name) {
+			prt = rr;
+		}
+	}
+	PortUnlock(space);
+
+	PortRelease(space);
+	
+	if (prt) {
+		if (PortRetain(prt->port)) {
+			/* Nothing */
+		}
+		else {
+			/*
+			 * Right points to an inactive port.
+			 * Pretend it doesn't exist.
+			 */
+			RefModifyLockUp();
+			return NULL;
+		}
+	}
+
+	RefModifyLockUp();
+
+	if (prt) {
+		RightIncrementRefCount(rr, r_kernel);
+	}
+	return prt;
+}
+
+/*
+ * Finds a port by its port name in the local
+ * ipc space. If it is not found, returns NULL.
+ */
+ke_port_t* Task_find_port(mach_port_t name)
+{
+	ke_port_t* prt = NULL;
+	ke_port_right_t* rr;
+
+	rr = Task_find_right(name);
+	if (rr) {
+		prt = rr->port;
+		RightDecrementRefCount(rr, r_kernel);
+	}
+
+	return prt;
+}
+
+mach_port_t Task_create_name(task_port_t* space)
+{
+	int id = 0;
+	int res = 0;
+	if (idr_pre_get(&(space->name_pool), GFP_KERNEL) == 0) {
+		panic("ke_get_new_port_name_in_space(): idr failure");
+	}
+
+	res = idr_get_new_above(&(space->name_pool), NULL, 20, &id);
+
+	if (res != 0)
+	{
+		panic("ke_get_new_port_name_in_space(): idr failure 2");
+	} 
+
+	return id;
+}
+
+kern_return_t task_message_handle(void* payload, void* trap_data)
+{
+	panic("task_message_handle");
+}
+
+ke_port_right_t* Task_allocate(void)
+{
+	task_port_t* kprt = NULL;
+	ke_port_right_t* rr = NULL;
+
+	rr = ke_new_port(KE_PORT_TYPE_TASK);
+	if (!rr || !rr->port) {
+		panic("ke_create_ipc_space(): unable to create a new ipc space");
+	}
+	kprt = (task_port_t*)rr->port;
+
+	kprt->port.ops = &_task_port_ops;
+	atomic_set(&(kprt->thread_count), 0);
+
+	/* Initalize the port right list */
+	INIT_LIST_HEAD(&(kprt->port_rights));
+
+	/* Initialize IDR for allocating port names */
+	idr_init(&(kprt->name_pool));
+
+	return rr;
+}
+
+void Native_setup_task(struct task_struct* task)
+{
+	ke_port_right_t* rr = Task_allocate();
+	task_port_t* kprt = (task_port_t*)rr->port;
+
+	/* Set the task descriptor */
+	kprt->task = task;
+
+	/* And set the port */
+	task->task_port = (void*)kprt;
+
+	/* Add a receive right for the kernel */
+	rr->name = ke_get_new_port_name_in_space(kernel_task);
+	RightIncrementRefCount(rr, r_receive);
+	ke_add_right_to_space(kernel_task, rr);
+
+	/* Add a send right to the task */
+	rr = Right_allocate();
+	rr->port = (ke_port_t*)kprt;
+	rr->name = ke_get_new_port_name_in_space(kprt);
+	RightIncrementRefCount(rr, r_send);
+	ke_add_right_to_space(kprt, rr);
+
+	Xlog("task %p got port %d", task, rr->name);
+}
+
+static void dump_mach_msg_hdr(mach_msg_header_t* head) {
+	return;
+
+	printk(KERN_WARNING "Mach Message:\n"
+	"\tbits: %p\n\tsize: %d\n\tremote: %d\n\tlocal: %d\n\tid : %d\n"
+	,(void*)head->msgh_bits, head->msgh_size, head->msgh_remote_port, head->msgh_local_port, head->msgh_id);
+}
+
+kern_return_t mach_port_destroy(ipc_space_t task, mach_port_name_t name)
+{
+	return KERN_FAILURE;
+}
+
+SYSCALL_DEFINE1(mach_msg_trap, struct mach_msg_trap_data __user *, usr_data)
+{
+	printk("sys_mach_msg_trap(): obsolete, do not use!");
+	return KERN_FAILURE;
+}
+
+kern_return_t _user_mach_msg_trap(struct mach_msg_trap_data __user* usr_data)
+{
+	panic("ate bad food!");
+}
+
+int init_mach_ipc(void)
+{
+	ke_port_right_t* rr = NULL;
+	ke_port_t* kprt = NULL;
+
+	zone_port_rights = 
+	kmem_cache_create("zone_port_rights", sizeof(ke_port_right_t), 0, SLAB_PANIC, NULL);
+
+	if (!zone_port_rights) {
+		panic("init_mach_ipc(): failed to create port right slab");
+	}
+
+	/*
+	 * Create an IPC space for the kernel.
+	 */
+	rr = Task_allocate();
+	kprt = rr->port;
+	kernel_task = (task_port_t*)kprt;
+
+	XLog("started mach ipc subsystem");
+
+	return 0;
+}
diff -Naur ./kos//magenta/mach_host.c ./kern//magenta/mach_host.c
--- ./kos//magenta/mach_host.c	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_host.c	2012-07-21 15:26:29.000000000 -0400
@@ -0,0 +1,119 @@
+/*
+ * mach_host.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Mach host.
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ke_runtime.h"
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+/* Host port ops */
+kern_return_t host_message_handle(void* payload, void* trap_data);
+ke_port_ops_t _host_port_ops = {host_message_handle};
+
+host_port_t* _host_self;
+
+ke_port_right_t* mach_host_allocate(task_port_t* space)
+{
+	host_port_t* prt = NULL;
+	ke_port_right_t* rr = NULL;
+
+	rr = ke_new_port(KE_PORT_TYPE_HOST);
+	if (!rr || !rr->port) {
+		return NULL;
+	}
+	prt = (host_port_t*)rr->port;
+
+	/* operations*/
+	prt->port.ops = &_host_port_ops;
+
+	rr->name = ke_get_new_port_name_in_space(space);
+	ke_add_right_to_space(space, rr);
+
+	return rr;
+}
+
+kern_return_t _user_host_info(mach_port_t host, integer_t flavor, integer_t* ret, integer_t* len)
+{
+	return KERN_FAILURE;
+}
+
+kern_return_t host_message_handle(void* payload, void* trap_data__)
+{
+	mach_msg_trap_data_t* trap_data = (mach_msg_trap_data_t*)trap_data__;
+	mach_msg_header_t* msg = (mach_msg_header_t*)payload;
+	kern_return_t retval;
+
+	retval = KERN_FAILURE;
+
+	return retval;
+}
+
+mach_port_t _user_host_self(void)
+{
+	/* We should already hold the send right*/
+	task_port_t* tp = ke_get_current_task();
+	ke_port_right_t* rcv = ke_get_right_in_space(tp, (ke_port_t*)_host_self, true);
+
+	if (rcv) {
+		mach_port_t nm = rcv->name;
+		PortRelease(tp);
+		return nm;
+	}
+	else {
+		/*
+		 * This shouldn't ever happen.
+		 */
+		ke_warn("_user_host_self(): failed!");
+		return 0;
+	}
+}
+
+void mach_host_init(void)
+{
+	ke_port_right_t* rcv;
+
+	rcv = mach_host_allocate(get_kernel_task());
+
+	BUG_ON(rcv == NULL);
+	BUG_ON(rcv->port == NULL);
+
+	_host_self = rcv->port;
+
+	ke_log("mach_host_init(): host initialized (self = %p)!\n", _host_self);
+}
\ No newline at end of file
diff -Naur ./kos//magenta/mach_kmsg.c ./kern//magenta/mach_kmsg.c
--- ./kos//magenta/mach_kmsg.c	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/mach_kmsg.c	2012-08-06 11:00:25.000000000 -0400
@@ -1,79 +1,483 @@
-#include <linux/time.h>
-#include <linux/kernel.h>
-#include <linux/mm.h>
-#include <linux/mman.h>
-#include <linux/errno.h>
-#include <linux/signal.h>
-#include <linux/string.h>
-#include <linux/fs.h>
-#include <linux/file.h>
-#include <linux/stat.h>
-#include <linux/fcntl.h>
-#include <linux/ptrace.h>
-#include <linux/user.h>
-#include <linux/binfmts.h>
-#include <linux/personality.h>
-#include <linux/init.h>
-#include <linux/coredump.h>
-#include <linux/slab.h>
-#include <linux/namei.h>
-#include <linux/security.h>
-#include <linux/syscalls.h>
-#include <linux/kfifo.h>
-
-#include <asm/system.h>
-#include <asm/uaccess.h>
-#include <asm/cacheflush.h>
-#include <linux/linkage.h>
-
-#include "ipc_types.h"
-#include "mach_kmsg.h"
-
-void get_dents_darwin(kmsg_get_directory_entries_t* km);
-void kmsg_load_kext(kmsg_load_kext_msg_t* msg);
-
-#define MsgToKmsg(type) type* km = (type*)msg;
-
-void kmsg_mach_task_self(kmsg_mach_task_self_msg_t* km)
-{
-	ke_port_t* kprt = ((ke_port_t*)current->task_port);
-	if (kprt) {
-		put_user(kprt->mp, km->out_port);
+/*
+ * mach_kmsg.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Support for IPC transactions.
+ */
+
+#include "Ipc.h"
+
+#define KERN_IPC_QUEUE_EMPTY 300
+
+
+#define MAX_USER_MESSAGE_SIZE 81920 /* Twenty pages should be enough for anything */
+
+int kmsg_handle(mach_msg_header_t* msg) { panic("%s", __FUNCTION__); }
+
+ipc_message* Ipc_message_allocate(mach_msg_header_t* head,
+	size_t size,
+	task_port_t* from_task)
+{
+	ipc_message* msg = (ipc_message*)kmalloc(sizeof(ipc_message), GFP_KERNEL);
+
+	msg->msg = head;
+	msg->head = *(head); /* inline header */
+	msg->received = 0;
+	msg->size = size;
+
+	/* Make sure the task port is not deallocated while in transit */
+	PortRetain(from_task);
+
+	msg->sender = from_task;
+
+	return msg;
+}
+
+void Ipc_message_destroy(ipc_message* message)
+{
+	PortRelease(message->sender);
+	kfree(message);
+}
+
+void Ipc_port_wake_waiters(ipc_port* port)
+{
+	wait_queue_head_t** queues;
+	unsigned int count;
+	unsigned int i = 0;
+
+	spin_lock(&port->wait_list_lock);
+
+	count = ke_array_get_count(port->wait_list);
+	queues = __ke_array_get_base(port->wait_list);
+
+	/* wake up all the queues */
+	for (i = 0; i < count; i++)
+	{
+		wait_queue_head_t* q = queues[i];
+		wake_up(q);
 	}
-	else {
-		printk(KERN_ALERT "mach task port invalid for task %p", current);
+
+	spin_unlock(&port->wait_list_lock);
+
+	Xlog("(%p) woken %d waiter(s)", port, count);
+}
+
+kern_return_t Ipc_msg_send_nonblock(ipc_port* dst_port, ipc_message* in_message)
+{
+	kern_return_t retval;
+	mach_port_t swap;
+
+	/* Redundant sanity checks */
+	if (dst_port->port.type != KE_PORT_TYPE_IPC)
+	{
+		retval = KERN_FAILURE;
+		goto out;
+	}
+
+	/* Make sure that the port is still active */
+	if (!dst_port->port.active)
+	{
+		retval = KERN_TERMINATED;
+		goto out;
+	}
+
+	/* XXX: MOVE TO RCV!!!! AND RESOLVE THE FUCKING PORTS.  */
+	swap = in_message->msg->msgh_local_port;
+	in_message->msg->msgh_local_port = in_message->msg->msgh_remote_port;
+	in_message->msg->msgh_remote_port = swap;
+
+	/* Send message */
+	if (kfifo_in((&dst_port->queue), &in_message, sizeof(in_message)) != sizeof(in_message))
+	{
+		panic("ipc_msg_send_nonblock(): kfifo_in failed!");
+	}
+
+	Xlog("enqueued msg[%p] => ipc_port[%p]", in_message, dst_port);
+
+	/* Just sent something, so wake the queues */
+	Ipc_port_wake_waiters(dst_port);
+
+	/* sucess, I guess */
+	retval = KERN_SUCCESS;
+
+out:
+	return retval;
+}
+
+void Ipc_port_add_queue(ipc_port* port, wait_queue_head_t* queue)
+{
+	ke_storage_type qq = (ke_storage_type)queue;
+
+	spin_lock(&port->wait_list_lock);
+	ke_array_add(port->wait_list, qq);
+	spin_unlock(&port->wait_list_lock);
+}
+
+kern_return_t Ipc_msg_send_block(ipc_port* dst_port, ipc_message* in_message)
+{
+	return Ipc_msg_send_nonblock(dst_port, in_message);
+}
+
+/*
+ * 
+ */
+kern_return_t Ipc_message_process(task_port_t* task, ipc_message* message)
+{
+	return MACH_MSG_SUCCESS;
+}
+
+/*
+ * Receive a message from an IPC port. Doesn't block.
+ */
+kern_return_t Ipc_msg_receive_nonblock(ipc_port* rcv_port,
+	task_port_t* task,
+	ipc_message** out_message,
+	size_t max_size,
+	boolean_t large)
+{
+	kern_return_t retval;
+	boolean_t too_large = false;
+
+	BUG_ON(!rcv_port);
+	BUG_ON(!out_message);
+
+	/* Redundant sanity checks */
+	if (rcv_port->port.type != KE_PORT_TYPE_IPC)
+	{
+		retval = MACH_RCV_INVALID_NAME;
+		goto out;
+	}
+
+	/* Make sure that the port is still active */
+	if (!rcv_port->port.active)
+	{
+		retval = MACH_RCV_PORT_DIED;
+		goto out;
+	}
+
+	/* See if the queue is empty */
+	if (kfifo_is_empty(&rcv_port->queue))
+	{
+		retval = MACH_RCV_IN_PROGRESS;
+		goto out;
+	}
+
+	/* check if the message fits into the dest buffer */
+	if (max_size != 0)
+	{
+		size_t msg_size;
+
+		/* peek into the queue */
+		BUG_ON(kfifo_out_peek(&(rcv_port->queue), out_message, sizeof(out_message)) != sizeof(out_message));
+		
+		msg_size = (*out_message)->size;
+
+		if (msg_size > max_size)
+		{
+			/* too large */
+			too_large = true;
+		}
+	}
+
+	/*
+	 * If the message is too large ang RCV_LARGE is off, dequeue the message
+	 * but return an error. If it's too large but it's on, do not dequeue message
+	 * but return an error. Otherwise, just dequeue and return success.
+	 */
+	if (!too_large || (too_large && !large))
+	{
+		if (kfifo_out(&(rcv_port->queue), out_message, sizeof(out_message)) != sizeof(out_message))
+		{
+			panic("ipc_msg_receive_nonblock(): kfifo_out failed!");
+		}
+	}
+
+	(*out_message)->received = true;
+
+	if (!too_large)
+	{
+		Xlog("dequeued msg[%p] <= ipc_port[%p]", *out_message, rcv_port);
+		retval = Ipc_message_process(task, *out_message);
 	}
+	else
+	{
+		retval = MACH_RCV_TOO_LARGE;
+	}
+
+out:
+	return retval;
+}
+
+kern_return_t Ipc_msg_receive_block(ipc_port* rcv_port,
+	task_port_t* task,
+	ipc_message** out_message,
+	size_t max_size,
+	boolean_t large)
+{
+	kern_return_t retval;
+	int qr = 0; /* queue wait result */
+
+	Xlog("(%p): waiting for enqueued data ...", rcv_port);
+	qr = wait_event_interruptible((rcv_port->wait_queue),
+									(retval = Ipc_msg_receive_nonblock(rcv_port,
+										task,
+										out_message,
+										max_size,
+										large)) != MACH_RCV_IN_PROGRESS);
+			
+	if (qr == -ERESTARTSYS)
+	{
+		Xlog("(%p) aborted!\n", rcv_port);
+
+		retval = MACH_RCV_INTERRUPTED;
+		goto out;
+	}
+	else 
+	{
+		Xwarn("(%p) receieved message, return code %d\n", rcv_port, retval);
+	}
+
+out:
+	return retval;
+}
+
+void* Ipc_msg_copyin_user(void* msg, size_t size)
+{
+	mach_msg_header_t* buffer;
+
+	if (size == 0) {
+		return NULL;
+	}
+
+	buffer = kmalloc(size, GFP_KERNEL);
+
+	if (copy_from_user((void*)buffer, msg, size)) {
+		/* we screwed up */
+		return NULL;
+	}
+
+	return buffer;
 }
 
-int kmsg_handle(mach_msg_header_t* msg)
+/*
+	mach_msg_bits_t	msgh_bits;
+	mach_msg_size_t	msgh_size;
+	mach_port_t		msgh_remote_port;
+	mach_port_t		msgh_local_port;
+	mach_msg_size_t msgh_reserved;
+	mach_msg_id_t	msgh_id;
+*/
+
+
+kern_return_t Ipc_get_suitable_receiver(mach_port_t user_port, Obj** out)
 {
-	switch (msg->msgh_id)
+	ke_port_right_t* name;
+
+	name = Task_find_right(user_port);
+	if (!name) {
+		return KERN_INVALID_NAME;
+	}
+	if (!name->port) {
+		RightDecrementRefCount(name, r_kernel);
+		return KERN_FAILURE;
+	}
+
+	if (!IsReceiveRight(name) && !IsPortSetRight(name))
 	{
-		case KMSG_GET_DIRECTORY_ENTRIES:
+		PortRelease(name->port);
+		RightDecrementRefCount(name, r_kernel);
+		return KERN_INVALID_RIGHT;
+	}
+
+	*out = name->port;
+	RightDecrementRefCount(name, r_kernel);
+
+	return KERN_SUCCESS;
+}
+
+/*
+typedef struct
+{
+	struct __Task* task;
+
+	void* rcv_buffer;
+	size_t rcv_size;
+
+	struct __Obj* snd_reply;
+	void* snd_msg;
+	size_t snd_size;
+
+	int options;
+	
+} ipc_trap_data_t;
+*/
+
+kern_return_t mach_msg_overwrite(
+	mach_msg_header_t* msg,
+	int option,
+	natural_t send_size,
+	natural_t rcv_size,
+	mach_port_t rcv_name,
+	natural_t timeout,
+	mach_port_t notify,
+	void* rcv_msg)
+{
+	ipc_trap_data_t _tdata;
+	ipc_trap_data_t* tdata = &_tdata;
+	kern_return_t ret = KERN_FAILURE;
+
+	Obj* destination = NULL;
+	Obj* reply = NULL;
+	Obj* receive = NULL;
+
+	memset(tdata, 0, sizeof(ipc_trap_data_t));
+
+	if (option & MACH_MSG_USER) {
+		option |= MACH_RCV_OVERWRITE;
+	}
+
+	tdata->options = option;
+	tdata->task = Native_get_current_task();
+
+	if (option & MACH_RCV_OVERWRITE) {
+		tdata->rcv_buffer = (void*)rcv_msg;
+	}
+	else {
+		tdata->rcv_buffer = (void*)msg;
+	}
+
+	tdata->snd_size = send_size;
+	tdata->snd_msg = msg;
+	tdata->rcv_size = rcv_size;
+
+	/*
+	 * Either send or receive could potentially block.
+	 * But we send first anyway.
+	 */
+
+	if (option & MACH_SEND_MSG)
+	{
+		/* Resolve reply port if needed */
+		if (msg->msgh_local_port != 0)
 		{
-			MsgToKmsg(kmsg_get_directory_entries_t);
-			get_dents_darwin(km);
+			ret = Task_get_object_if_receive(msg->msgh_local_port, &reply, KE_PORT_TYPE_IPC);
+
+			if (ret != KERN_SUCCESS) {
+				Xwarn("Invalid reply port\n");
+				ret = MACH_SEND_INVALID_REPLY;
+				goto out_send_error;
+			}
 
-			return 0;
+			tdata->snd_reply = reply;
 		}
-		case KMSG_LOAD_KEXT:
+
+		/* Resolve destination port */
+		ret = Task_get_object_if_send(msg->msgh_remote_port, &destination, KE_PORT_TYPE_ANY);
+
+		if (ret == KERN_SUCCESS && destination->ops->msg_send)
 		{
-			MsgToKmsg(kmsg_load_kext_msg_t);
-			kmsg_load_kext(km);
+			/* Forward the send operation to the handler */
+			ret = destination->ops->msg_send(destination, tdata);
 
-			return 0;
+			if (ret != MACH_MSG_SUCCESS) {
+				Xwarn("Error from msg_send (%p)", (void*)ret);
+				goto out_send_error;
+			}
 		}
-		case KMSG_MACH_TASK_SELF:
+		else
 		{
-			MsgToKmsg(kmsg_mach_task_self_msg_t);
-			kmsg_mach_task_self(km);
+			Xwarn("Invalid destination port (%d)", ret);
+			ret = MACH_SEND_INVALID_DEST;
+			goto out_send_error;
+		}
+	}
+
+	/* So these two are not released */
+	destination = NULL;
+	reply = NULL;
+
+	if (option & MACH_RCV_MSG)
+	{
+		/* Resolve receive port */
+		ret = Ipc_get_suitable_receiver(rcv_name, &receive);
 
-			return 0;
+		if (ret == KERN_SUCCESS && receive->ops->msg_receive)
+		{
+			/* Forward the send operation to the handler */
+			ret = receive->ops->msg_receive(receive, tdata);
+
+			if (ret != MACH_MSG_SUCCESS) {
+				Xwarn("Error from msg_receive (%p)", (void*)ret);
+				goto out_rcv_error;
+			}
 		}
-		default:
+		else
 		{
-			printk("kmsg_handle(): invalid kernel message (id: %d)\n", msg->msgh_id);
-			return -EINVAL;
+			Xwarn("Invalid receive port (%d)", ret);
+			ret = MACH_RCV_INVALID_NAME;
+			goto out_rcv_error;
 		}
 	}
+
+	receive = NULL;
+
+	goto out;
+
+out_rcv_error:
+	if (receive) {
+		PortRelease(receive);
+	}
+out_send_error:
+	if (destination) {
+		PortRelease(destination);
+	}
+	if (reply) {
+		PortRelease(reply);
+	}
+out:
+	return ret;
+}
+
+kern_return_t _user_mach_msg_overwrite_trap(
+	void* msg,
+	int option,
+	natural_t send_size,
+	natural_t rcv_size,
+	mach_port_t rcv_name,
+	natural_t timeout,
+	mach_port_t notify,
+	void* rcv_msg)
+{
+	void* copyin_buffer;
+	kern_return_t retval;
+
+	/*
+	 * Copy out the message buffer from the userspace if
+	 * we are sending a message.
+	 */
+	if (option & MACH_SEND_MSG)
+	{
+		copyin_buffer = Ipc_msg_copyin_user(msg, send_size);
+		if (!copyin_buffer) {
+			retval = MACH_SEND_INVALID_DATA;
+			goto out;
+		}
+	}
+
+	option |= MACH_MSG_USER;
+
+	Xlog("msg=%p, option=%p, send_size=%d, rcv_size=%d, rcv_name=%d, timeout=%d, notify=%d, rcv_msg=%p",
+		msg, option, send_size, rcv_size, rcv_name, timeout, notify, rcv_msg);
+
+	retval = mach_msg_overwrite(copyin_buffer,
+		option,
+		send_size,
+		rcv_size,
+		rcv_name,
+		timeout,
+		notify,
+		msg); /* pointer to the user buffer */
+
+out:
+	return retval;
 }
\ No newline at end of file
diff -Naur ./kos//magenta/macho_loader.c ./kern//magenta/macho_loader.c
--- ./kos//magenta/macho_loader.c	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/macho_loader.c	2012-08-06 11:01:48.000000000 -0400
@@ -88,13 +88,25 @@
 				int, int, unsigned long);
 
 
-
 /* 
 	Impl
 	#####################################################
 */
 #define round_page(_v) (((_v) + PAGE_SIZE - 1) & ~(PAGE_SIZE - 1))
 
+#define LINK_TABLE_ADDR 0x80014000
+#define LINK_TABLE_SIZE PAGE_SIZE*2
+
+typedef struct {
+	uint32_t entry_count;
+	size_t table_size;
+} linker_image_table_header_t;
+
+typedef struct {
+	uintptr_t load_addr;
+	size_t size;
+	const char* name;
+} linker_image_entry_t;
 
 static struct linux_binfmt macho_format = {
 		.module		= THIS_MODULE,
@@ -126,7 +138,7 @@
 		struct file *interpreter, unsigned long *interp_map_addr,
 		unsigned long no_base)
 {
-	panic("load_macho_interp: not implemented, use ml_loadDylinker instead. ");
+	panic("load_macho_interp: not implemented, use macho_get_dylinker instead. ");
 }
 
 
@@ -160,7 +172,7 @@
 typedef int	vm_offset_t;
 typedef int	vm_size_t;
 
-static int ml_loadDylinker(struct linux_binprm *bprm, int file_size, struct dylinker_command * lcp, struct file **linker_file) {
+static int macho_get_dylinker(struct linux_binprm *bprm, int file_size, struct dylinker_command * lcp, struct file **linker_file) {
 	/*
 		Setup the dynamic linker.
 	*/
@@ -180,33 +192,33 @@
 	} while (*p++);
 
 	if (_verboseLog) 
-		printk(KERN_WARNING "ml_loadDylinker: dynamic linker is @'%s'\n", name);
+		printk(KERN_WARNING "macho_get_dylinker: dynamic linker is @'%s'\n", name);
 
 	/*
 		Load the linker executable file.
 	*/
 	*linker_file = open_exec(name);
 	if (IS_ERR(*linker_file)) {
-		printk(KERN_WARNING "ml_loadDylinker: can't execute the dynamic linker\n");
+		printk(KERN_WARNING "macho_get_dylinker: can't execute the dynamic linker\n");
 		return(LOAD_BADMACHO);
 	}
 
 	return LOAD_SUCCESS;
 }
 
-static int ml_loadUnixThread(struct linux_binprm *bprm, int file_size, struct arm_thread_command * tcp, void** entry) {
+static int macho_load_unix_thread(struct linux_binprm *bprm, int file_size, struct arm_thread_command * tcp, void** entry) {
 	/*
 		Setup the main thread.
 	*/
 	
 	/* sanity */
 	if (tcp->flavor != ARM_THREAD_STATE) {
-		printk(KERN_WARNING "ml_loadUnixThread: main thread is of the wrong type %d (need %d)\n",
+		printk(KERN_WARNING "macho_load_unix_thread: main thread is of the wrong type %d (need %d)\n",
 				tcp->flavor,
 				ARM_THREAD_STATE);
 	}
 	else if (tcp->count != 17) {
-		printk(KERN_WARNING "ml_loadUnixThread: has the wrong number of arm registers %d (need %d)\n",
+		printk(KERN_WARNING "macho_load_unix_thread: has the wrong number of arm registers %d (need %d)\n",
 				tcp->count,
 				17);
 	}
@@ -215,7 +227,7 @@
 		
 		/* Entry point */
 		if (_verboseLog)
-			printk(KERN_WARNING "ml_loadUnixThread: success, pc @ %d\n", tcp->state.r15);
+			printk(KERN_WARNING "macho_load_unix_thread: success, pc @ %d\n", tcp->state.r15);
 		
 		*entry = (void*)tcp->state.r15;
 	}
@@ -223,7 +235,7 @@
 	return LOAD_SUCCESS;
 }
 
-static int ml_loadSegment(struct linux_binprm *bprm,
+static int macho_load_segment(struct linux_binprm *bprm,
 						  int file_size,
 						  struct segment_command* scp,
 						  int* top,
@@ -253,18 +265,18 @@
 	*/
 	/* is the command right? */
 	if (scp->cmdsize < segment_command_size) {
-		printk(KERN_WARNING "ml_loadSegment(%.*s): malformed command", 16, scp->segname);
+		printk(KERN_WARNING "macho_load_segment(%.*s): malformed command", 16, scp->segname);
 		return (LOAD_BADMACHO);
 	}
 	/* is the segment in range? */
 	if (scp->fileoff + scp->filesize < scp->fileoff ||
 		scp->fileoff + scp->filesize > (uint64_t)file_size) {
-		printk(KERN_WARNING "ml_loadSegment(%.*s): out of range", 16, scp->segname);
+		printk(KERN_WARNING "macho_load_segment(%.*s): out of range", 16, scp->segname);
 		return (LOAD_BADMACHO);
 	}
 	/* is page aligned? */
 	if ((scp->fileoff & (PAGE_SIZE-1)) != 0) {
-		printk(KERN_WARNING "ml_loadSegment(%.*s): not page aligned", 16, scp->segname);
+		printk(KERN_WARNING "macho_load_segment(%.*s): not page aligned", 16, scp->segname);
 		return (LOAD_BADMACHO);
 	}
 	
@@ -274,7 +286,7 @@
 		Print some info about the segment.
 	*/
 	if (_verboseLog)
-		printk(KERN_WARNING "ml_loadSegment(%.*s): addr %d, filesize %d, vmsize %d\n",
+		printk(KERN_WARNING "macho_load_segment(%.*s): addr %d, filesize %d, vmsize %d\n",
 				16,
 				scp->segname,
 				map_addr,
@@ -298,7 +310,7 @@
 		addr = PAGE_ALIGN(map_addr + slide);
 		
 		if (_verboseLog)
-			printk(KERN_WARNING "ml_loadSegment(%.*s): seg mmap @ %d, offset %d \n",
+			printk(KERN_WARNING "macho_load_segment(%.*s): seg mmap @ %d, offset %d \n",
 					16,
 					scp->segname,
 					addr,
@@ -323,20 +335,20 @@
 			*/
 			if (map_offset == 0) {
 				if (_verboseLog)
-					printk(KERN_WARNING "ml_loadSegment(%.*s): this is the base segment \n", 16, scp->segname);
+					printk(KERN_WARNING "macho_load_segment(%.*s): this is the base segment \n", 16, scp->segname);
 				
 				*first_text = (void*)(addr);
 			}
 		}
 		
 		if ((mapped) <= 0) {
-			printk(KERN_WARNING "ml_loadSegment(%.*s): map file seg failed \n", 16, scp->segname);
+			printk(KERN_WARNING "macho_load_segment(%.*s): map file seg failed \n", 16, scp->segname);
 			ret = LOAD_RESOURCE;
 			goto out;
 		}
 		else {
 			if (_verboseLog)
-				printk(KERN_WARNING "ml_loadSegment(%.*s): mapped in @ %d \n", 16, scp->segname, (void*)mapped);
+				printk(KERN_WARNING "macho_load_segment(%.*s): mapped in @ %d \n", 16, scp->segname, (void*)mapped);
 		}
 		
 		/*
@@ -346,7 +358,7 @@
 		delta_size = map_size - scp->filesize;
 		if (delta_size > 0) {
 			if (_verboseLog)
-				printk(KERN_WARNING "ml_loadSegment(%.*s): fixxuuup \n", 16, scp->segname);	
+				printk(KERN_WARNING "macho_load_segment(%.*s): fixxuuup \n", 16, scp->segname);	
 		}
 	}
 	
@@ -359,7 +371,7 @@
 		addr = PAGE_ALIGN(map_addr + map_size + slide);
 		
 		if (_verboseLog)
-			printk(KERN_WARNING "ml_loadSegment(%.*s): mmap @ %d, size: %d\n", 16, scp->segname, addr, delta_size);
+			printk(KERN_WARNING "macho_load_segment(%.*s): mmap @ %d, size: %d\n", 16, scp->segname, addr, delta_size);
 		
 		/* lock */
 		down_write(&current->mm->mmap_sem);
@@ -374,13 +386,13 @@
 		up_write(&current->mm->mmap_sem);
 		
 		if ((mapped) <= 0) {
-			printk(KERN_WARNING "ml_loadSegment(%.*s): map anon failed \n", 16, scp->segname);
+			printk(KERN_WARNING "macho_load_segment(%.*s): map anon failed \n", 16, scp->segname);
 			ret = LOAD_RESOURCE;
 			goto out;
 		}
 		else {
 			if (_verboseLog)
-				printk(KERN_WARNING "ml_loadSegment(%.*s): anon chunk mapped in @%p \n", 16, scp->segname, (void*)mapped);
+				printk(KERN_WARNING "macho_load_segment(%.*s): anon chunk mapped in @%p \n", 16, scp->segname, (void*)mapped);
 		}
 	}
 	
@@ -396,7 +408,7 @@
 	return ret;
 }
 
-static int ml_getFileSize(struct file* file) {
+static int macho_get_file_size(struct file* file) {
 	/* file size from struct file */
 	
 	/* sanity checks */
@@ -410,7 +422,7 @@
 	return file->f_path.dentry->d_inode->i_size;
 }
 
-static int ml_checkImage(struct file* file, macho_header* head) 
+static int macho_validate_image(struct file* file, macho_header* head) 
 {
 	/*
 		Sanity checks.
@@ -420,7 +432,7 @@
 	size_t macho_header_sz = sizeof(macho_header);
 	
 	if (head->magic != MH_MAGIC) {
-		printk(KERN_WARNING "ml_checkImage: binary is not a macho binary (magic: 0x%p) \n", (void*)head->magic);
+		printk(KERN_WARNING "macho_validate_image: binary is not a macho binary (magic: 0x%p) \n", (void*)head->magic);
 		retval = -ENOEXEC;
 		goto out_ret;
 	}
@@ -429,33 +441,33 @@
 		Validate architecture.
 	*/
 	if (head->cputype != CPU_TYPE_ARM) {
-		printk(KERN_WARNING "ml_checkImage: wrong architecture in the executable\n");
+		printk(KERN_WARNING "macho_validate_image: wrong architecture in the executable\n");
 		retval = -EINVAL;
 		goto out_ret;
 	}
 	
 	/*
-		Run ARM-specific validation checks
-	*/
+	 * Run ARM-specific validation checks
+	 */
 	if (head->cputype == CPU_TYPE_ARM) {
 		if (head->cpusubtype == CPU_SUBTYPE_ARM_V7)
 		{
 			if (cpu_architecture() != CPU_ARCH_ARMv7) {
-				printk(KERN_WARNING "ml_checkImage: armv7 executables are not supported by the current platform\n");
+				printk(KERN_WARNING "macho_validate_image: armv7 executables are not supported by the current platform\n");
 				retval = -EINVAL;
 				goto out_ret;
 			}
 		}
-		else if (head->cpusubtype == CPU_SUBTYPE_ARM_V6)
+		else if (head->cpusubtype == CPU_SUBTYPE_ARM_V6 || head->cpusubtype == 0)
 		{
-			if (cpu_architecture() != CPU_ARCH_ARMv6) {
-				printk(KERN_WARNING "ml_checkImage: armv6 executables are not supported by the current platform\n");
+			if (cpu_architecture() != CPU_ARCH_ARMv6 && cpu_architecture() != CPU_ARCH_ARMv7) {
+				printk(KERN_WARNING "macho_validate_image: armv6 executables are not supported by the current platform\n");
 				retval = -EINVAL;
 				goto out_ret;
 			}
 		}
 		else {
-			printk(KERN_WARNING "ml_checkImage: unrecognized arm version in the executable (%d)\n", head->cpusubtype);
+			printk(KERN_WARNING "macho_validate_image: unrecognized arm version in the executable (%d)\n", head->cpusubtype);
 			retval = -EINVAL;
 			goto out_ret;
 		}
@@ -466,9 +478,9 @@
 	 	Make sure the file size can be retrieved in order 
 	  	to perform sanity checks on the file.
 	 */
-	file_size = ml_getFileSize(file);
+	file_size = macho_get_file_size(file);
 	if (file_size < 0) {
-		printk(KERN_WARNING "ml_checkImage: can't retrieve binary size \n");
+		printk(KERN_WARNING "macho_validate_image: can't retrieve binary size \n");
 		retval = -EINVAL;
 		goto out_ret;
 	}
@@ -480,22 +492,22 @@
 	retval = -EINVAL;
 	/* can we map it? */
 	if (!file->f_op||!file->f_op->mmap) {
-		printk(KERN_WARNING "ml_checkImage: binary file can't be mapped in \n");
+		printk(KERN_WARNING "macho_validate_image: binary file can't be mapped in \n");
 		goto out_ret;
 	}
 	/* sane lc size? */
 	if ((off_t)(macho_header_sz + head->sizeofcmds) > file_size) {
-		printk(KERN_WARNING "ml_checkImage: malformed load commands size \n");
+		printk(KERN_WARNING "macho_validate_image: malformed load commands size \n");
 		goto out_ret;
 	}
 	if (head->filetype != MH_EXECUTE) {
-		printk(KERN_WARNING "IGN:ml_checkImage: macho file is not executable \n");
+		printk(KERN_WARNING "IGN:macho_validate_image: macho file is not executable \n");
 		//goto out_ret;
 	}
 	
 	/* Print some info about the macho file */
 	if (_verboseLog)
-		printk(KERN_WARNING "ml_checkImage: valid macho file: \n\tmagic: 0x%p \n\tsize: %d\n",
+		printk(KERN_WARNING "macho_validate_image: valid macho file: \n\tmagic: 0x%p \n\tsize: %d\n",
 				(void*)head->magic,
 				file_size);
 	
@@ -505,7 +517,7 @@
 	return retval;
 }
 
-static int ml_bootstrapDylinker(struct file* file, /* file for the dylinker*/
+static int macho_load_dylinker(struct file* file, /* file for the dylinker*/
 								int* top_data, /* top of image data */
 								void** first_text,
 								void** entry_point) /* first text segment of the linker */
@@ -519,7 +531,7 @@
 	size_t macho_header_sz = sizeof(macho_header);
 	macho_header* head = kmalloc(macho_header_sz, GFP_KERNEL);
 	int file_size = 0;
-	
+
 	/* this is for LC loader */
 	int ret = 0;
 	size_t offset;
@@ -528,24 +540,24 @@
 	uint8_t* addr;
 	
 	if (_verboseLog)
-		printk(KERN_WARNING "ml_bootstrapDylinker: loading dynamic linker @ %d\n", load_addr);
+		printk(KERN_WARNING "macho_load_dylinker: loading dynamic linker @ %d\n", load_addr);
 
 	/*
 		Read in the macho header.
 	*/
 	kernel_read(file, 0, head, macho_header_sz);
 
-	retval = ml_checkImage(file, head);
+	retval = macho_validate_image(file, head);
 	if (retval) {
 		retval = LOAD_BADMACHO;
-		printk(KERN_WARNING "ml_bootstrapDylinker: dylinker image failed sanity checks, not loading \n");
+		printk(KERN_WARNING "macho_load_dylinker: dylinker image failed sanity checks, not loading \n");
 		goto out_ret;
 	}
 	
 	/*
-		XXX: this should be retrieved by ml_checkImage()
+		XXX: this should be retrieved by macho_validate_image()
 	*/
-	file_size = ml_getFileSize(file);
+	file_size = macho_get_file_size(file);
 	
 	/*
 		Read the load commands from the file.
@@ -572,7 +584,7 @@
 		    lcp->cmdsize < sizeof(struct load_command) ||
 		    offset > head->sizeofcmds + macho_header_sz)
 		{
-			printk(KERN_WARNING "ml_bootstrapDylinker: malformed binary - lc overflow \n");
+			printk(KERN_WARNING "macho_load_dylinker: malformed binary - lc overflow \n");
 			goto lc_ret;
 		}
 		
@@ -587,7 +599,7 @@
 				/*
 					Load and slide a dylinker segment.
 				*/
-				ret = ml_loadSegment(&bprm,
+				ret = macho_load_segment(&bprm,
 									file_size,
 									(struct segment_command*)lcp,
 									top_data, /* keep bumping the same top_data */
@@ -595,20 +607,20 @@
 									load_addr); /* slide up */
 				
 				if (ret != LOAD_SUCCESS) {
-					printk(KERN_WARNING "ml_bootstrapDylinker: segment loading failure \n");
+					printk(KERN_WARNING "macho_load_dylinker: segment loading failure \n");
 					goto lc_ret;
 				}
 				break;
 			}
 			case LC_UNIXTHREAD:
 			{
-				ret = ml_loadUnixThread(&bprm,
+				ret = macho_load_unix_thread(&bprm,
 										file_size,
 										(struct arm_thread_command*)lcp,
 										entry_point);
 										
 				if (ret != LOAD_SUCCESS) {
-					printk(KERN_WARNING "ml_bootstrapDylinker: unix thread loading failure \n");
+					printk(KERN_WARNING "macho_load_dylinker: unix thread loading failure \n");
 					goto lc_ret;
 				}
 				break;
@@ -616,7 +628,7 @@
 			default: 
 			{
 				if (_verboseLog)
-					printk(KERN_WARNING "ml_bootstrapDylinker: unsupported lc 0x%p \n", (void*)lcp->cmd);
+					printk(KERN_WARNING "macho_load_dylinker: unsupported lc 0x%p \n", (void*)lcp->cmd);
 				
 				break;
 			}
@@ -640,6 +652,9 @@
 
 static void wire_weird_pages(void)
 {
+	int ret;
+	void* addr;
+
 	/* 0x80000000 */
 	if (dpages[0] == NULL)
 	{
@@ -648,7 +663,7 @@
 
 
 	down_write(&current->mm->mmap_sem);
-	int ret = 
+	ret = 
 	install_special_mapping(current->mm,
 		0x80000000,
 		PAGE_SIZE,
@@ -656,13 +671,39 @@
 		dpages);
 	up_write(&current->mm->mmap_sem);
 
-	void* addr = page_address(dpages[0]);
+	addr = page_address(dpages[0]);
 
 	memset(addr, 'w', PAGE_SIZE);
 
 	printk("wired weird page! (%p, %d, %p)\n", dpages[0], ret, addr);
 }
 
+static void macho_setup_link_table(void)
+{
+	void* mapped = LINK_TABLE_ADDR;
+	size_t sz = LINK_TABLE_SIZE;
+	linker_image_table_header_t* th;
+
+	down_write(&current->mm->mmap_sem);
+
+	mapped = 		
+	do_mmap(NULL,
+			mapped,
+			sz,
+			PROT_WRITE | PROT_READ,
+			MAP_FIXED | MAP_PRIVATE,
+			0);
+
+	up_write(&current->mm->mmap_sem);
+
+	th = (linker_image_table_header_t*)mapped;
+
+	__put_user((uint32_t)2, &th->entry_count);
+	__put_user((size_t)sz, &th->table_size);
+	
+	printk("mapped link table @ %p\n", mapped);
+}
+
 static int load_macho_binary(struct linux_binprm *bprm, struct pt_regs *regs)
 { 
 	unsigned long def_flags = 0;
@@ -673,23 +714,54 @@
 	size_t macho_header_sz = sizeof(macho_header);
 	macho_header* head = ((macho_header*)bprm->buf);
 	struct file *linker_file = NULL;
+	int dylinker_load_addr;
+
+	size_t offset;
+	size_t oldoffset;
+	uint32_t ncmds;
+	uint8_t* addr;
+
+	int ret = 0;
 	
+	/* Top of the image data. This is needed to position the heap. */
+	int top_data = 0;
+	
+	/* First text segment where the mach header is. */
+	void* first_text = 0;
+	void* first_text_linker = 0;
+
+	/* Stack environment (grows down on ARM). */
+	uint32_t* stack = bprm->p;
+	uint32_t* argv_array;
+	uint32_t* argv;
+	uint32_t* envp_array;
+	uint32_t* envp;
+	uint32_t total_argv_size;
+	uint32_t total_env_size;
+
+	/* Arg stuff */
+	uint32_t argc;
+	uint32_t envc;
+	char* p;
+
+	linker_image_entry_t* ee;
+
 	/* have we got enough space? */
 	if (!head) {
 		retval = -ENOMEM;
 		goto out_ret;
 	}
 	
-	retval = ml_checkImage(bprm->file, head);
+	retval = macho_validate_image(bprm->file, head);
 	if (retval) {
 		printk(KERN_WARNING "load_macho_binary: image failed sanity checks, not loading \n");
 		goto out_ret;
 	}
 	
 	/*
-		XXX: this should be retrieved by ml_checkImage()
+		XXX: this should be retrieved by macho_validate_image()
 	*/
-	file_size = ml_getFileSize(bprm->file);
+	file_size = macho_get_file_size(bprm->file);
 	
 	/*
 		The file seems to be alright, so set up an environment for the 
@@ -701,13 +773,15 @@
 		panic("load_macho_binary: flush_old_exec failed\n");
 	}
 	else {
+		unsigned int personality;
+
 		current->flags &= ~PF_FORKNOEXEC;
 		current->mm->def_flags = def_flags;
 		
 		setup_new_exec(bprm);
 		
 		/* set personality */
-		unsigned int personality = current->personality & ~PER_MASK;
+		personality = current->personality & ~PER_MASK;
 		personality |= PER_LINUX;
 		
 		/*
@@ -735,29 +809,11 @@
 	/*
 		Read the load commands from the file.
 	*/
-	size_t offset;
-	size_t oldoffset;
-	uint32_t ncmds;
-	uint8_t* addr;
-
 	offset = 0;
 	ncmds = head->ncmds;
 	addr = kmalloc(head->sizeofcmds, GFP_KERNEL); /***/
 	retval = -EINVAL;
 	
-	int ret = 0;
-	
-	/*
-		Top of the image data. This is needed to position the heap.
-	*/
-	int top_data = 0;
-	
-	/*
-		First text segment where the mach header is.
-	*/
-	void* first_text = 0;
-	void* first_text_linker = 0;
-	
 	/* read in load commands */
 	kernel_read(bprm->file, macho_header_sz, addr, head->sizeofcmds);
 	
@@ -784,14 +840,14 @@
 		 */
 		switch(lcp->cmd) {
 			case LC_SEGMENT:
-				ret = ml_loadSegment(bprm, file_size, (struct segment_command*)lcp, &top_data, &first_text, 0);
+				ret = macho_load_segment(bprm, file_size, (struct segment_command*)lcp, &top_data, &first_text, 0);
 				if (ret != LOAD_SUCCESS) {
 					printk(KERN_WARNING "load_macho_binary: segment loading failure \n");
 					goto lc_ret;
 				}
 				break;
 			case LC_LOAD_DYLINKER:
-				ret = ml_loadDylinker(bprm, file_size, (struct dylinker_command*)lcp, &linker_file);
+				ret = macho_get_dylinker(bprm, file_size, (struct dylinker_command*)lcp, &linker_file);
 				if (ret != LOAD_SUCCESS) {
 					printk(KERN_WARNING "load_macho_binary: dylinker loading failure \n");
 					goto lc_ret;
@@ -801,7 +857,7 @@
 				}
 				break;
 			case LC_UNIXTHREAD:
-				ret = ml_loadUnixThread(bprm, file_size, (struct arm_thread_command*)lcp, &entry_point);
+				ret = macho_load_unix_thread(bprm, file_size, (struct arm_thread_command*)lcp, &entry_point);
 				if (ret != LOAD_SUCCESS) {
 					printk(KERN_WARNING "load_macho_binary: unix thread loading failure \n");
 					goto lc_ret;
@@ -819,9 +875,9 @@
 		Bootstrap the dynamic linker if needed.
 	*/
 	if (linker_file) {
-		int dylinker_load_addr = top_data;
+		dylinker_load_addr = top_data;
 		
-		ml_bootstrapDylinker(linker_file,
+		macho_load_dylinker(linker_file,
 							&top_data,
 							&first_text_linker,
 							&entry_point);
@@ -861,17 +917,6 @@
 	set_binfmt(&macho_format);
 	install_exec_creds(bprm);
 
-	/*
-		Stack (grows down on ARM).
-	*/
-	uint32_t* stack = bprm->p;
-	uint32_t* argv_array;
-	uint32_t* argv;
-	uint32_t* envp_array;
-	uint32_t* envp;
-	uint32_t total_argv_size;
-	uint32_t total_env_size;
-
 	/* Construct envp array. */
 	envp = envp_array = stack = (uint32_t*)stack - ((bprm->envc+1));
 
@@ -881,9 +926,9 @@
 	if (_verboseLog)
 		printk(KERN_WARNING "load_macho_binary: setting up stack @ %p ...\n", (uint32_t*)stack);
 
-	uint32_t argc = bprm->argc;
-	uint32_t envc = bprm->envc;
-	char* p = bprm->p;
+	argc = bprm->argc;
+	envc = bprm->envc;
+	p = bprm->p;
 
 	/* Set up argv pointers */
 	current->mm->arg_start = (unsigned long)p;
@@ -950,8 +995,8 @@
 	memset(regs->uregs, 0, sizeof(regs->uregs));
 	regs->ARM_cpsr = USR_MODE;	
 
-	/* not sure */
-	if (elf_hwcap & HWCAP_THUMB && initial_pc & 1)
+	/* If the entry point is THUMB, set the thumb bit */
+	if (initial_pc & 1)
 		regs->ARM_cpsr |= PSR_T_BIT;
 		
 	/* set up control regs */	
@@ -964,11 +1009,26 @@
 	regs->ARM_r1 = stack[1];	/* r1 (argv) */
 	regs->ARM_r0 = stack[0];	/* r0 (argc) */	
 	
+	/* ABI */
+	regs->ARM_r7 = stack;	/* FP */
+
 	/* this will work for mmu and nonmmu */
 	nommu_start_thread(regs);
 	
 	wire_weird_pages();	
-			
+	macho_setup_link_table();
+
+	ee = (linker_image_entry_t*)(((char*)LINK_TABLE_ADDR) + sizeof(linker_image_entry_t));
+
+	/* main image */
+	__put_user(0, &ee->load_addr);
+	__put_user(dylinker_load_addr, &ee->size);
+
+	ee += 1;
+
+	__put_user(dylinker_load_addr, &ee->load_addr);
+	__put_user((uint32_t)top_data - (uint32_t)dylinker_load_addr, &ee->size);
+
 	/*
 		Binary is now loaded. Return 0 to signify success.
 	*/
@@ -986,19 +1046,33 @@
 		return retval;
 }
 
+#define MAX_UNWIND 20
+
+/*
+ * Because there isn't a better word to describe it.
+ */
 static int fucking_core_dumper(struct coredump_params *cprm)
 {
+	linker_image_table_header_t* tb = (linker_image_table_header_t*)LINK_TABLE_ADDR;
+	linker_image_entry_t* ee;
+	uint32_t count;
+	int i;
+	const char* pc_lib;
+	uint32_t* fp; /* frame pointer */
+	uint32_t call_stack[MAX_UNWIND];
+	uint32_t spos = 0;
+
 	printk(KERN_WARNING "----- Core Dump -----\n");
 
-	printk(KERN_WARNING "PID: %d", current->pid);
+	printk(KERN_WARNING "PID: %d\n", current->pid);
 
-	printk(KERN_WARNING "Received Signal: %ld", cprm->signr);
+	printk(KERN_WARNING "Received Signal: %ld\n", cprm->signr);
 
 	printk(KERN_WARNING "Register Dump:\n"
 	"\tpc @ %p (%d), sp @ %p \n"
 	"\tr0 @ %p, r1 @ %p, r2 @ %p, r3 @ %p, r4 @ %p \n"
 	"\tr5 @ %p, r6 @ %p, r7 @ %p, r8 @ %p, r9 @ %p \n"
-	"\tr10 @ %p, lr @ %p,\n",
+	"\tr10 @ %p, lr @ %p, cpsr @ %p (thumb: %d)\n",
 	(void*)cprm->regs->ARM_pc,
 	(int)cprm->regs->ARM_pc,
 	(void*)cprm->regs->ARM_sp,
@@ -1013,37 +1087,133 @@
 	(void*)cprm->regs->ARM_r8,
 	(void*)cprm->regs->ARM_r9,
 	(void*)cprm->regs->ARM_r10,
-	(void*)cprm->regs->ARM_lr);
-	
+	(void*)cprm->regs->ARM_lr,
+	(void*)cprm->regs->ARM_cpsr,
+	(int)(cprm->regs->ARM_cpsr & PSR_T_BIT));
+	
+	printk(KERN_WARNING "----- Call Stack -----\n");
+
+	/* unwind darwin stack */
+	fp = (uint32_t*)cprm->regs->ARM_r7;
+	while (spos < MAX_UNWIND)
+	{
+		uint32_t* new_fp;
+
+		/* Get saved LR and R7 */
+
+		if (get_user(call_stack[spos], &fp[1])) {
+			printk("\t*** Unwinding failed 0 (memory error @ %p)\n", &fp[1]);
+			break;
+		}
+
+		if (get_user(new_fp, &fp[0])) {
+			printk("\t*** Unwinding failed 1 (memory error @ %p)\n", &fp[0]);
+			break;
+		}
+
+		printk("\t%d: lr:%p r7:%p\n", spos, call_stack[spos], new_fp);
+
+		fp = new_fp;
+		spos++;
+	}
+
+	/* walk link table */
+	if (get_user(count, &tb->entry_count)) {
+		printk(" *** Unable to access link table in user memory!\n");
+		return 0;
+	}
+
+	ee = (linker_image_entry_t*)(((char*)tb) + sizeof(linker_image_entry_t));
+
+	printk(KERN_WARNING "----- Loaded Images -----\n");
+
+	if ((sizeof(linker_image_entry_t) * count) > LINK_TABLE_SIZE)
+	{
+		printk(" *** Link table corrupt!\n");
+	}
+	else
+	{
+		for (i = 0; i < count; i++)
+		{
+			int ii;
+			size_t sl;
+			const char* lname;
+			size_t image_size;
+			uintptr_t load_addr;
+			uint32_t loc = (uint32_t)cprm->regs->ARM_pc;
+			uint32_t lrr = (uint32_t)cprm->regs->ARM_lr;
+
+			linker_image_entry_t* t = &(ee[i]);
+
+			if (i > 1)
+			{
+				sl = strlen_user(t->name);
+
+				if (sl == 0)
+				{
+					lname = "<unknown>";
+				}
+				else
+				{
+					lname = (const char*)kmalloc(sl, GFP_KERNEL);
+					__copy_from_user(lname, t->name, sl);
+				}
+			}
+			else if (i == 0)
+			{
+				lname = "<main_image>";
+			}
+			else /*(i == 1)*/
+			{
+				lname = "<linker>";
+			}
+
+			__get_user(image_size, &t->size);
+			__get_user(load_addr, &t->load_addr);
+
+			printk("\t%s {%d - %d}\n", lname, load_addr, (uint32_t)load_addr + (uint32_t)image_size);
+
+			if (loc > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > loc)
+			{
+				uint32_t rel_pc = loc - (uint32_t)load_addr;
+
+				/* pc is in range */
+				printk("\t\t > [PC] in image @ %p (%d), abs: %p\n", (void*)rel_pc, rel_pc, (void*)loc);
+			}
+
+			if (lrr > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > lrr)
+			{
+				uint32_t rel_lr = lrr - (uint32_t)load_addr;
+
+				/* lr is in range */
+				printk("\t\t > [LR] in image @ %p (%d), abs: %p\n", (void*)rel_lr, rel_lr, (void*)lrr);
+			}
+
+			for (ii = 0; ii < spos; ii++)
+			{
+				uint32_t stack_pos = call_stack[ii];
+				if (stack_pos > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > stack_pos)
+				{
+					uint32_t rel_sp = stack_pos - (uint32_t)load_addr;
+
+					/* lr is in range */
+					printk("\t\t > [SP: %d] in image @ %p (%d), abs: %p\n", ii, (void*)rel_sp, rel_sp, (void*)stack_pos);
+				}
+			}
+		}
+	}
+
 	return 0;
 }
 
-/* This is really simpleminded and specialized - we are loading an
-   a.out library that is given an ELF header. */
 static int load_macho_library(struct file *file)
 {
 	panic("load_macho_library: not implemented.");
 }
 
-/* CoreDump code stripped from here */
-
-static int __init init_macho_binfmt(void)
+int __init init_macho_binfmt(void)
 {
 	printk(KERN_WARNING "init_macho_binfmt: MachO binary loader initialized! (load: %p) \n", load_macho_binary);
 	
 	return register_binfmt(&macho_format);
 }
-
-static void __exit exit_macho_binfmt(void)
-{
-	unregister_binfmt(&macho_format);
-}
-
-module_init(init_macho_binfmt);
-module_exit(exit_macho_binfmt);
-
-
-/*
- * Fuck everything about this.
- */
-MODULE_LICENSE("GPL");
diff -Naur ./kos//magenta/mach_port_types.h ./kern//magenta/mach_port_types.h
--- ./kos//magenta/mach_port_types.h	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/mach_port_types.h	2012-08-05 18:16:24.000000000 -0400
@@ -4,15 +4,27 @@
 #include <linux/kernel.h>
 #include <linux/kfifo.h>
 #include <linux/list.h>
+#include <linux/idr.h>
+#include <linux/wait.h>
 
 #include <DarwinTypes.h>
 #include <MachO.h>
 
+#include "kern_return.h"
+#include "ke_runtime.h"
+
 #define FALSE 0
 #define TRUE 1
 
 #define MAX_PORT_COUNT 4096
 
+typedef int	clock_res_t;
+struct mach_timespec {
+	unsigned int	tv_sec;			/* seconds */
+	clock_res_t		tv_nsec;		/* nanoseconds */
+};
+typedef struct mach_timespec	mach_timespec_t;
+
 typedef unsigned int natural_t;
 typedef int integer_t;
 typedef int boolean_t;
@@ -21,6 +33,21 @@
 typedef natural_t mach_port_right_t;
 typedef int mach_port_delta_t;
 
+typedef mach_port_t mach_port_name_t;
+
+typedef int kern_return_t;
+
+typedef unsigned int mach_msg_type_name_t;
+
+#define MACH_MSG_TYPE_MOVE_RECEIVE	16	/* Must hold receive rights */
+#define MACH_MSG_TYPE_MOVE_SEND		17	/* Must hold send rights */
+#define MACH_MSG_TYPE_MOVE_SEND_ONCE	18	/* Must hold sendonce rights */
+#define MACH_MSG_TYPE_COPY_SEND		19	/* Must hold send rights */
+#define MACH_MSG_TYPE_MAKE_SEND		20	/* Must hold receive rights */
+#define MACH_MSG_TYPE_MAKE_SEND_ONCE	21	/* Must hold receive rights */
+#define MACH_MSG_TYPE_COPY_RECEIVE	22	/* Must hold receive rights */
+
+
 #define MACH_PORT_RIGHT_SEND            ((mach_port_right_t) 0)
 #define MACH_PORT_RIGHT_RECEIVE         ((mach_port_right_t) 1)
 #define MACH_PORT_RIGHT_SEND_ONCE       ((mach_port_right_t) 2)
@@ -31,58 +58,217 @@
 #define KE_PORT_TYPE_FREE 0
 #define KE_PORT_TYPE_TASK 1
 #define KE_PORT_TYPE_IPC 2
+#define KE_PORT_TYPE_PORT_SET 3
+#define KE_PORT_TYPE_HOST 4
+#define KE_PORT_TYPE_THREAD 5
+#define KE_PORT_TYPE_SEMAPHORE 6
 
-typedef struct __ke_port_t ke_port_t;
+#define KE_PORT_TYPE_ANY 100
 
 typedef enum {
     kMachPortRightSend = 0x1,
     kMachPortRightReceive = 0x2,
     kMachPortRightSendOnce = 0x4,
-    /*STYLE4 = 0x8,
-    STYLE5 = 0x10,
-    STYLE6 = 0x20,
-    STYLE7 = 0x40,
-    STYLE8 = 0x80*/
+    /* 0x8, 0x10, 0x20, 0x40,*/
+    kMachPortRightKernel = 0x80,
 } ke_right_type_t;
 
+struct __Task;
+struct __Obj;
+
+typedef struct
+{
+	struct __Task* task;
+
+	void* rcv_buffer;
+	size_t rcv_size;
+	boolean_t rcv_user;
+	
+	struct __Obj* snd_reply;
+	void* snd_msg;
+	size_t snd_size;
+
+	int options;
+	
+} ipc_trap_data_t;
+
+typedef struct __ke_port_ops_t
+{
+	/*
+	 * obsolete
+	 */
+	kern_return_t (*msg_handler)(void* payload, void* trap_data);
+
+	/*
+	 * New operations. NULL if not supported.
+	 */
+	kern_return_t (*msg_send)(struct __Obj* port, ipc_trap_data_t* info);
+	kern_return_t (*msg_receive)(struct __Obj* port, ipc_trap_data_t* info);
+} ke_port_ops_t;
+
+/* This must be at the top of each port object type */
+typedef struct __Obj
+{
+	uint16_t type; /* port type */
+	atomic_t refs; /* refcount */
+	struct mutex mtx; /* general lock */
+	boolean_t active; /* can it be retrieved from a right? */
+
+	ke_port_ops_t* ops; /* operations */
+} Obj;
+
+#define ke_port_t Obj
+
 typedef struct 
 {
+	ke_port_t port; /***/
+
 	struct task_struct *task; /* task which owns the port */
 	
 	struct completion wait_for_enqueued_data;
-	struct kfifo queue; /* queue */
+	wait_queue_head_t wait_queue; /* wait queue */
+	struct kfifo queue; /* msg queue */
 
+	ke_array_t wait_list;
+	spinlock_t wait_list_lock;
+
+	boolean_t dead;
 	boolean_t allocated; 
+
+	/* mk_timer */
+	struct timer_list ktimer;
 } ipc_port;
 
+typedef struct 
+{
+	ke_port_t port; /***/
+
+	wait_queue_head_t wait_queue;
+
+	ke_array_t port_list;
+	spinlock_t port_list_lock;
+
+	unsigned int last_iter;
+} ipc_port_set;
+
 typedef struct
 {
 	ke_port_t* port;
-	ke_right_type_t rights;
+	mach_port_t	name; /* port name */
 	int urefs;
 
+	atomic_t r_receive;
+	atomic_t r_send;
+	atomic_t r_send_once;
+	atomic_t r_port_set;
+
+	atomic_t r_kernel;
+
 	struct list_head list;
 } ke_port_right_t;
 
+typedef struct
+{
+	ke_port_t port;
+} host_port_t;
+
 /*
  * This structure represents a task port as well
  * the task's IPC space and other stuff.
  */
-typedef struct 
+typedef struct __Task
 {
+	ke_port_t port;
+
 	struct task_struct *task; /* task which owns the port */
-	ke_port_right_t* port_rights; /* list of port rights for this task */
+
+	struct idr name_pool;
+	struct list_head port_rights; /* list of port rights for this task */
+
+	atomic_t thread_count;
 } task_port_t;
 
-typedef struct __ke_port_t
+
+typedef struct
 {
-	mach_port_t	mp; /* port name */
-	uint16_t type; /* port type */
+	ke_port_t port;
+
+	struct task_struct *task; /* task which owns the port */
+
+	atomic_t suspend_count;
+	boolean_t new_task;
+	boolean_t exiting;
+	boolean_t can_cancel;
+	boolean_t frozen;
+} thread_port_t;
+
+typedef struct
+{
+	ke_port_t port;
+} sem_port_t;
+
+task_port_t* Native_get_current_task(void); /* [RetainPort] */
+ke_port_t* Task_find_port(mach_port_t name); /* [RetainPort] */
+ke_port_right_t* Task_find_right(mach_port_t name); /* [RetainPort][RetainRight] */
+task_port_t* Native_get_task(struct task_struct* task); /* [RetainPort] */
+thread_port_t* Native_get_thread(struct task_struct* task); /* [RetainPort] */
+thread_port_t* Native_get_current_thread(void); /* [RetainPort] */
+
+#define ke_get_current_task Native_get_current_task
+#define ke_port_find_named Task_find_port
+#define ke_right_find_named Task_find_right
+#define ke_get_task_port Native_get_task
+#define ke_get_thread_port Native_get_thread
+
+/*
+ * [RetainRight]
+ * fprt must be a valid port. Port is not retained by this.
+ */
+ke_port_right_t* Task_get_right(task_port_t* space, ke_port_t* fprt, boolean_t add); 
+
+#define ke_get_right_in_space Task_get_right
+
+kern_return_t mach_task_port_for_name(mach_port_t user_port, task_port_t** out); /* [RetainPort] */
+kern_return_t Task_get_object_if_send(mach_port_t user_port, Obj** out, uint16_t type); /* [RetainPort] */
+kern_return_t Task_get_object_if_receive(mach_port_t user_port, Obj** out, uint16_t type); /* [RetainPort] */
+
+mach_port_t Task_create_name(task_port_t* space);
+ke_port_right_t* Obj_new(uint16_t type);
+void Task_add_right(task_port_t* space, ke_port_right_t* rr);
+
+#define ke_add_right_to_space Task_add_right
+#define ke_new_port Obj_new
+#define ke_get_new_port_name_in_space Task_create_name
+
+boolean_t Obj_is_active(ke_port_t* port);
+
+typedef task_port_t* ipc_space_t;
+
+int Obj_get_refcount(ke_port_t* port);
+void Obj_release(ke_port_t* port);
+boolean_t Obj_retain(ke_port_t* port);
+
+task_port_t* get_kernel_task(void);
+
+boolean_t __is_port_set_right(ke_port_right_t* right);
+boolean_t __is_receive_right(ke_port_right_t* right);
+boolean_t __is_send_right(ke_port_right_t* right);
+
+#define PortLock(x) mutex_lock(&(((ke_port_t*)x)->mtx))
+#define PortUnlock(x) mutex_unlock(&(((ke_port_t*)x)->mtx))
+
+#define PortRetain(x) Obj_retain((Obj*)x)
+#define PortRelease(x) Obj_release((Obj*)x)
+#define PortGetRefcount(x) Obj_get_refcount((Obj*)x)
+
+#define PortActive(x) Obj_is_active((ke_port_t*)x)
+#define RightIncrementRefCount(x, y) atomic_inc(&(x->y))
+#define RightDecrementRefCount(x, y) atomic_dec(&(x->y))
+#define IsReceiveRight(x) __is_receive_right(x)
+#define IsSendRight(x) __is_send_right(x)
+#define IsPortSetRight(x) __is_port_set_right(x)
 
-	union {
-		ipc_port ipc;
-		task_port_t tp;
-	} c;
-} ke_port_t;
+void mach_task_inc_thread_count(task_port_t* tport);
+void mach_task_dec_thread_count(task_port_t* tport);
 
 #endif 
\ No newline at end of file
diff -Naur ./kos//magenta/mach_semaphore.c ./kern//magenta/mach_semaphore.c
--- ./kos//magenta/mach_semaphore.c	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_semaphore.c	2012-07-19 11:35:08.000000000 -0400
@@ -0,0 +1,170 @@
+/*
+ * mach_semaphore.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * lol, what's a semaphore?
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ke_runtime.h"
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+kern_return_t sem_message_handle(void* payload, void* trap_data);
+ke_port_ops_t _sem_port_ops = {
+	.msg_handler = sem_message_handle
+};
+
+kern_return_t sem_message_handle(void* payload, void* trap_data__)
+{
+	mach_msg_trap_data_t* trap_data = (mach_msg_trap_data_t*)trap_data__;
+	mach_msg_header_t* msg = (mach_msg_header_t*)payload;
+	kern_return_t retval;
+
+	retval = KERN_FAILURE;
+
+	return retval;
+}
+
+ke_port_right_t* mach_sem_allocate(task_port_t* space)
+{
+	sem_port_t* prt = NULL;
+	ke_port_right_t* rr = NULL;
+
+	rr = ke_new_port(KE_PORT_TYPE_SEMAPHORE);
+	if (!rr || !rr->port) {
+		return NULL;
+	}
+	prt = (sem_port_t*)rr->port;
+
+	/* operations */
+	prt->port.ops = &_sem_port_ops;
+
+	rr->name = ke_get_new_port_name_in_space(space);
+	ke_add_right_to_space(space, rr);
+
+	return rr;
+}
+
+#define xxxxx() panic("mach_sem: %s not impl", __FUNCTION__);
+
+/*
+ * Gets the port if it's valid and we have the send right.
+ */
+kern_return_t mach_sem_get(mach_port_t user_port, sem_port_t** out)
+{
+	ke_port_right_t* name;
+
+	name = ke_right_find_named(user_port);
+	if (!name) {
+		return KERN_INVALID_NAME;
+	}
+	if (!name->port) {
+		RightDecrementRefCount(name, r_kernel);
+		return KERN_FAILURE;
+	}
+
+	if (!IsSendRight(name) || name->port->type != KE_PORT_TYPE_SEMAPHORE)
+	{
+		PortRelease(name->port);
+		RightDecrementRefCount(name, r_kernel);
+		return KERN_INVALID_RIGHT;
+	}
+
+	*out = (sem_port_t*)name->port;
+	RightDecrementRefCount(name, r_kernel);
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t _user_semaphore_create(mach_port_t _task, mach_port_t *semaphore, int policy, int value)
+{
+	task_port_t* task;
+	kern_return_t ret;
+	ke_port_right_t* rcv;
+	ke_port_right_t* snd;
+
+	ret = mach_task_port_for_name(_task, &task);
+	if (ret != KERN_SUCCESS) {
+		return ret;
+	}
+
+	rcv = mach_sem_allocate(get_kernel_task());
+
+	snd = ke_get_right_in_space(task, (ke_port_t*)rcv->port, true);
+
+	RightIncrementRefCount(snd, r_send);
+	RightDecrementRefCount(snd, r_kernel);
+	PortRelease(task);
+
+	__put_user(snd->name, semaphore);
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t _user_semaphore_wait(mach_port_t semaphore)
+{
+	xxxxx();
+}
+
+kern_return_t _user_semaphore_signal(mach_port_t semaphore) 
+{
+	xxxxx();
+}
+
+kern_return_t _user_semaphore_signal_all(mach_port_t semaphore)
+{
+	xxxxx();
+}
+
+kern_return_t _user_semaphore_timedwait(mach_port_t semaphore, mach_timespec_t wait_time)
+{
+	xxxxx();
+}
+
+kern_return_t _user_semaphore_timedwait_signal(mach_port_t wait_semaphore, mach_port_t signal_semaphore, mach_timespec_t wait_time)
+{
+	xxxxx();
+}
+
+kern_return_t _user_semaphore_wait_signal(mach_port_t wait_semaphore, mach_port_t signal_semaphore)
+{
+	xxxxx();
+}
+
+kern_return_t _user_semaphore_signal_thread(mach_port_t semaphore, void* thread)
+{
+	xxxxx();
+}
\ No newline at end of file
diff -Naur ./kos//magenta/mach_task.c ./kern//magenta/mach_task.c
--- ./kos//magenta/mach_task.c	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_task.c	2012-08-06 15:09:10.000000000 -0400
@@ -0,0 +1,1213 @@
+/*
+ * mach_task.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Support for mach tasks, mach threads, their appropriate
+ * ports and bsd threads.
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+#include <linux/freezer.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+#include <asm/thread_notify.h>
+
+#include "ke_runtime.h"
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+#include "VM.h"
+
+/* Thread port ops */
+kern_return_t thread_message_handle(void* payload, void* trap_data);
+ke_port_ops_t _thread_port_ops = {thread_message_handle};
+
+typedef struct {
+	void* start_fn;
+	void* wstart_fn;
+	int thread_size;
+	void* pthread_start_fn;
+	void* workq;
+	uint64_t tsd;
+} bsd_reg_args_t;
+
+typedef struct {
+	void* func;
+	void* func_arg;
+	void* stack;
+	void* thread;
+	unsigned int flags;
+} bsd_crt_args_t;
+
+/* context switch and restoration code */
+asmlinkage void ret_from_fork(void) __asm__("ret_from_fork");
+asmlinkage void Return_to_user_from_swi(void) __asm__("Return_to_user_from_swi");
+
+kern_return_t mach_thread_for_name(mach_port_t user_port, thread_port_t** out)
+{
+	return Task_get_object_if_send(user_port, (Obj**)out, KE_PORT_TYPE_THREAD);
+}
+
+static struct task_struct* Task_get_native(task_port_t* space)
+{
+	struct task_struct* ret;
+
+	ret = space->task;
+	if (ret == NULL) {
+		panic("Task_get_native(): task port %p doesn't have a native task", space);
+	}
+
+	return ret;
+}
+
+static struct task_struct* Thread_get_native(thread_port_t* space)
+{
+	struct task_struct* ret;
+
+	ret = space->task;
+	if (ret == NULL) {
+		panic("Thread_get_native(): thread port %p doesn't have a native task", space);
+	}
+
+	return ret;
+}
+
+#define THREAD_NOTIFY_COPY      3
+
+ke_port_right_t* mach_thread_allocate(task_port_t* space)
+{
+	thread_port_t* prt = NULL;
+	ke_port_right_t* rr = NULL;
+
+	rr = ke_new_port(KE_PORT_TYPE_THREAD);
+	if (!rr || !rr->port) {
+		return NULL;
+	}
+	prt = (thread_port_t*)rr->port;
+
+	/* operations*/
+	prt->port.ops = &_thread_port_ops;
+
+	rr->name = Task_create_name(space);
+	Task_add_right(space, rr);
+
+	return rr;
+}
+
+kern_return_t thread_message_handle(void* payload, void* trap_data__)
+{
+	//mach_msg_trap_data_t* trap_data = (mach_msg_trap_data_t*)trap_data__;
+	//mach_msg_header_t* msg = (mach_msg_header_t*)payload;
+	kern_return_t retval;
+
+	retval = KERN_FAILURE;
+
+	return retval;
+}
+
+kern_return_t mach_task_vm_allocate(task_port_t* port,
+	uintptr_t* addr,
+	size_t size,
+	boolean_t anywhere)
+{
+	struct task_struct* ts = Task_get_native(port);
+	return VM_allocate(ts, addr, size, anywhere);
+}
+
+kern_return_t _user_vm_allocate(mach_port_t task,
+	uintptr_t* addr, /* __user */
+	size_t size,
+	boolean_t anywhere)
+{
+	task_port_t* port;
+	kern_return_t ret;
+	uintptr_t iaddr;
+
+	__get_user(iaddr, addr);
+
+	ret = mach_task_port_for_name(task, &port);
+	if (ret != KERN_SUCCESS) {
+		Xwarn("_user_vm_allocate(): failed with %d", ret);
+		return ret;
+	}
+
+	ret = mach_task_vm_allocate(port, &iaddr, size, anywhere);
+
+	__put_user(iaddr, addr);
+
+	PortRelease(port);
+	return ret;
+}
+
+
+#define PTHREAD_START_CUSTOM	0x01000000
+#define PTHREAD_START_SETSCHED	0x02000000
+#define PTHREAD_START_DETACHED	0x04000000
+
+/*
+long do_fork(unsigned long clone_flags,
+	      unsigned long stack_start,
+	      struct pt_regs *regs,
+	      unsigned long stack_size,
+	      int __user *parent_tidptr,
+	      int __user *child_tidptr)
+*/
+
+/*
+	We're calling this:
+
+	_pthread_start(pthread_t self,
+		mach_port_t kport,
+		void *(*fun)(void *),
+		void * funarg,
+		size_t stacksize,
+		unsigned int pflags)
+*/
+
+/* called out by 'copy_process_ex' in 'kernel/fork.c' */
+int
+mach_platform_copy_thread(unsigned long clone_flags,
+	unsigned long stack_start,
+	unsigned long stk_sz,
+	struct task_struct *p,
+	struct pt_regs *regs)
+{
+	struct thread_info *thread = task_thread_info(p);
+	struct pt_regs *childregs = task_pt_regs(p);
+	
+	*childregs = *regs;
+	childregs->ARM_pc = 0xcafebabe;
+
+	memset(&thread->cpu_context, 0, sizeof(struct cpu_context_save));
+	thread->cpu_context.sp = (unsigned long)childregs;
+	thread->cpu_context.pc = (unsigned long)ret_from_fork;
+
+	clear_ptrace_hw_breakpoint(p);
+
+	if (clone_flags & CLONE_SETTLS)
+		thread->tp_value = regs->ARM_r3;
+
+	thread_notify(THREAD_NOTIFY_COPY, thread);
+
+	return 0;
+}
+
+void mach_task_inc_thread_count(task_port_t* tport)
+{
+	atomic_inc_return(&tport->thread_count);
+	PortRetain(tport);
+}
+
+void mach_task_dec_thread_count(task_port_t* tport)
+{
+	int ar;
+	ar = atomic_dec_return(&tport->thread_count);
+	PortRelease(tport);
+	BUG_ON(ar < 0);
+}
+
+void mach_thread_bootstrap(struct task_struct* task)
+{
+	ke_port_right_t* rr;
+	ke_port_right_t* rcv = NULL;
+	task_port_t* tp;
+	task_port_t* cur;
+
+	tp = get_kernel_task(); /* can't use current */
+	cur = Native_get_task(task); /* can't use current */
+
+	rcv = mach_thread_allocate(tp);
+
+	mach_task_inc_thread_count(cur);
+
+	if (rcv) {
+		/* release kernel port? */
+
+		/* Add a send right to the task */
+		rr = ke_get_right_in_space(cur, (ke_port_t*)rcv->port, true);
+		RightIncrementRefCount(rr, r_send);
+
+		/* Create a relationship */
+		task->thread_port = rcv->port;
+		((thread_port_t*)rcv->port)->task = task;
+
+		RightDecrementRefCount(rr, r_kernel);
+
+		Xlog("mach_thread_bootstrap(): bootstraped mach thread for task[%p] (mtask[%p]) with name[%d]", task, cur, rr->name);
+
+		PortRelease(cur);
+	}
+	else {
+		panic("mach_thread_bootstrap(): can't bootstrap mach thread for task[%p]", task);
+	}
+}
+
+ke_port_right_t* mach_thread_bootstrap_for_space(task_port_t* tport)
+{
+	ke_port_right_t* rr;
+	ke_port_right_t* rcv = NULL;
+	task_port_t* tp;
+	task_port_t* cur;
+
+	tp = get_kernel_task(); /* can't use current */
+	cur = tport;
+
+	rcv = mach_thread_allocate(tp);
+
+	mach_task_inc_thread_count(cur);
+
+	if (rcv) {
+		/* release kernel port? */
+
+		/* Add a send right to the task */
+		rr = Task_get_right(cur, (ke_port_t*)rcv->port, true);
+		RightIncrementRefCount(rr, r_send);
+
+		Xlog("mach_thread_bootstrap(): bootstraped mach thread for mtask[%p] with name[%d]", cur, rr->name);
+	
+		return rr;
+	}
+	else {
+		panic("mach_thread_bootstrap(): can't bootstrap mach thread for mtask[%p]", cur);
+	}
+}
+
+long mk_thread_fork(unsigned long clone_flags,
+	      unsigned long stack_start,
+	      struct pt_regs *regs,
+	      unsigned long stack_size,
+	      struct task_struct* from,
+	      struct task_struct** out_task);
+
+kern_return_t thread_create(task_port_t* parent_task, ke_port_right_t** child_thread)
+{
+	unsigned long flags;
+	long fork_ret;
+	struct pt_regs regs;
+	struct task_struct* new_task = NULL;
+
+	thread_port_t* mk_thread;
+	ke_port_right_t* mk_thread_right;
+
+	/* Zero out all the registers */
+	memset(&regs, 0, sizeof(regs));
+
+	/*
+	 * ARM sanity
+	 * This is needed to enforce userland execution for this thread.
+	 */
+	regs.ARM_cpsr = USR_MODE;
+	regs.ARM_cpsr |= PSR_ENDSTATE;
+
+	/* Clone flags for threads */
+	flags = SIGCHLD | CLONE_FS | CLONE_FILES | CLONE_SIGHAND | CLONE_VM | CLONE_THREAD;
+
+	/* Create a mach thread object */
+	mk_thread_right = mach_thread_bootstrap_for_space(parent_task);
+	mk_thread = (thread_port_t*)mk_thread_right->port;
+
+	/* Set bits */
+	mk_thread->new_task = true;
+	atomic_set(&mk_thread->suspend_count, 1);
+
+	/* Fork */
+	fork_ret = 
+	mk_thread_fork(flags,
+		(unsigned long)0,
+		&regs,
+		(unsigned long)0,
+		Task_get_native(parent_task),
+		&new_task);
+
+	BUG_ON(new_task == NULL);
+
+	/* Link the task with the thread port */
+	new_task->thread_port = (void*)mk_thread;
+	mk_thread->task = new_task;
+
+	/* Return the port right to the thread */
+	*child_thread = mk_thread_right;
+
+	/* All done */
+	return KERN_SUCCESS;
+}
+
+extern bool freeze_task(struct task_struct *p, bool sig_only);
+extern int thaw_process(struct task_struct *p);
+
+kern_return_t __task_stop_uninterruptable(struct task_struct *tsk)
+{
+	if (freeze_task(tsk, false))
+	{
+		Xlog("suspended native task %p", tsk);
+		return KERN_SUCCESS;
+	}
+	else
+	{
+		return KERN_FAILURE;
+	}
+}
+
+kern_return_t __task_cont_uninterruptable(struct task_struct *tsk)
+{
+	if (thaw_process(tsk))
+	{
+		Xlog("resumed native task %p", tsk);
+		return KERN_SUCCESS;
+	}
+	else
+	{
+		return KERN_FAILURE;
+	}
+}
+
+int __mach_task_suspended_loop(struct task_struct *tsk)
+{
+	/*
+	 * this allows us to interrupt frozen tasks
+	 * even though they're not actually interruptable
+	 *
+	 * here it is safe to assume that the thread port
+	 * will not be released.
+	 */
+
+	thread_port_t* thread = tsk->thread_port;
+
+	if (fatal_signal_pending(tsk) || thread->exiting)
+	{
+		__task_cont_uninterruptable(tsk);
+	}
+
+	if (thread->exiting) {
+		/* let the task suicide itself */
+		do_exit(0);
+	}
+
+	 return 0;
+}
+
+
+kern_return_t __thread_resume(thread_port_t* target_thread)
+{
+	if (target_thread->new_task)
+	{
+		/* clone_flags is ignored anyway */
+		wake_up_new_task(Thread_get_native(target_thread), 0);
+
+		target_thread->new_task = false;
+	}
+	else if (target_thread->frozen)
+	{
+		__task_cont_uninterruptable(Thread_get_native(target_thread));
+	}
+	else
+	{
+		panic("__thread_resume(%p): thread is not suspended", target_thread);
+	}
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t __thread_suspend(thread_port_t* target_thread)
+{
+	if (target_thread->new_task)
+	{
+		/* no-op, as the thread is already suspended */
+	}
+	else if (!target_thread->frozen)
+	{
+		__task_stop_uninterruptable(Thread_get_native(target_thread));
+	}
+	else
+	{
+		panic("__thread_suspend(%p): thread is already suspended", target_thread);
+	}
+}
+
+kern_return_t thread_abort(thread_port_t* target_thread)
+{
+	/*
+	 * This call is not supported because it makes no
+	 * sense on Linux.
+	 */
+	panic("thread_abort is not supported!");
+}
+
+kern_return_t thread_suspend(thread_port_t* target_thread)
+{
+	int ar;
+
+	ar = atomic_inc_return(&target_thread->suspend_count);
+
+	if (ar == 1) {
+		return __thread_suspend(target_thread);
+	}
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t thread_resume(thread_port_t* target_thread)
+{
+	int ar;
+
+	ar = atomic_dec_return(&target_thread->suspend_count);
+
+	if (ar == 0) {
+		return __thread_resume(target_thread);
+	}
+
+	return KERN_SUCCESS;
+}
+
+
+typedef struct arm_thread_state arm_thread_state_t;
+
+/*
+	uint32_t r0;
+	uint32_t r1;
+	uint32_t r2;
+	uint32_t r3;
+	uint32_t r4;
+	uint32_t r5;
+	uint32_t r6;
+	uint32_t r7;
+	uint32_t r8;
+	uint32_t r9;
+	uint32_t r10;
+	uint32_t r11;
+	uint32_t r12;
+	uint32_t r13; //sp
+	uint32_t r14; //lr
+	uint32_t r15; //pc
+	uint32_t r16; //cpsr
+*/
+
+kern_return_t thread_get_state(thread_port_t* target, natural_t flavor, void* old_state, natural_t* count)
+{
+	natural_t max_buffer;
+	natural_t st_size;
+	arm_thread_state_t* state;
+
+	struct pt_regs *regs;
+	struct task_struct* ltask;
+
+
+	max_buffer = *count;
+	st_size = sizeof(arm_thread_state_t);
+	state = (arm_thread_state_t*)old_state;
+
+	if (st_size < max_buffer) {
+		Xwarn("thread_get_state(): buffer too small!");
+		return KERN_FAILURE;
+	}
+
+	/* Fetch task */
+	ltask = Thread_get_native(target);
+	BUG_ON(ltask == NULL);
+
+	/* Fetch registers */
+	regs = task_pt_regs(ltask);
+
+	/* Transfer */
+	state->r0 = (uint32_t)regs->ARM_r0;
+	state->r1 = (uint32_t)regs->ARM_r1;
+	state->r2 = (uint32_t)regs->ARM_r2;
+	state->r3 = (uint32_t)regs->ARM_r3;
+	state->r4 = (uint32_t)regs->ARM_r4;
+	state->r5 = (uint32_t)regs->ARM_r5;
+	state->r6 = (uint32_t)regs->ARM_r6;
+	state->r7 = (uint32_t)regs->ARM_r7;
+	state->r8 = (uint32_t)regs->ARM_r8;
+	state->r9 = (uint32_t)regs->ARM_r9;
+	state->r10 = (uint32_t)regs->ARM_r10;
+	state->r11 = (uint32_t)regs->ARM_fp;
+	state->r12 = (uint32_t)regs->ARM_ip;
+
+	state->r13 = (uint32_t)regs->ARM_sp;
+	state->r14 = (uint32_t)regs->ARM_lr;
+	state->r15 = (uint32_t)regs->ARM_pc;
+
+	state->r16 = (uint32_t)regs->ARM_cpsr;
+
+	/* All done! */
+	return KERN_SUCCESS;
+}
+
+kern_return_t thread_set_state(thread_port_t* target, natural_t flavor, void* new_state, natural_t new_state_count)
+{
+	arm_thread_state_t* state = (arm_thread_state_t*)new_state;
+	struct pt_regs *regs;
+	struct task_struct* ltask;
+	struct thread_info *thread;
+
+	if (new_state_count != sizeof(arm_thread_state_t)) {
+		/* Wrong size */
+		return KERN_FAILURE;
+	}
+
+	ltask = Thread_get_native(target);
+	BUG_ON(ltask == NULL);
+
+	regs = task_pt_regs(ltask);
+
+	/* transfer things */
+	regs->ARM_r0 = (unsigned long)state->r0;
+	regs->ARM_r1 = (unsigned long)state->r1;
+	regs->ARM_r2 = (unsigned long)state->r2;
+	regs->ARM_r3 = (unsigned long)state->r3;
+	regs->ARM_r4 = (unsigned long)state->r4;
+	regs->ARM_r5 = (unsigned long)state->r5;
+	regs->ARM_r6 = (unsigned long)state->r6;
+	regs->ARM_r7 = (unsigned long)state->r7;
+	regs->ARM_r8 = (unsigned long)state->r8;
+	regs->ARM_r9 = (unsigned long)state->r9;
+	regs->ARM_r10 = (unsigned long)state->r10;
+	regs->ARM_fp = (unsigned long)state->r11;
+	regs->ARM_ip = (unsigned long)state->r12;
+
+	regs->ARM_sp = (unsigned long)state->r13;
+	regs->ARM_lr = (unsigned long)state->r14;
+	regs->ARM_pc = (unsigned long)state->r15;
+
+	regs->ARM_cpsr = (unsigned long)state->r16;
+
+	/* Alter the CPU context */ 
+	thread = task_thread_info(ltask);
+
+	memset(&thread->cpu_context, 0, sizeof(struct cpu_context_save));
+	thread->cpu_context.sp = (unsigned long)regs;
+	thread->cpu_context.pc = (unsigned long)ret_from_fork;
+
+	clear_ptrace_hw_breakpoint(ltask);
+
+	return KERN_SUCCESS;
+}
+
+static int __force_tkill(struct task_struct* tsk, int sig)
+{
+	/* force_sig_info(int sig, struct siginfo *info, struct task_struct *t) */
+
+	int ret;
+
+	ret = send_sig(sig, tsk, 1);
+
+	return ret;
+}
+
+
+void thread_exception_return(void)
+{
+	thread_port_t* tp;
+	boolean_t exiting;
+
+	BUG_ON(current == NULL);
+
+	tp = Native_get_current_thread();
+	exiting = tp->exiting;
+
+	PortRelease(tp);
+
+	/* well, we can't return because we're exiting */
+	if (exiting) {
+		do_exit(0);
+	}
+
+	/* leave kernel mode */
+	Return_to_user_from_swi();
+}
+
+kern_return_t thread_terminate_sig(thread_port_t* target, int sig)
+{
+	struct task_struct* task;
+
+	task = Thread_get_native(target);
+
+	target->exiting = true;
+
+	__force_tkill(task, sig);
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t thread_terminate(thread_port_t* target)
+{
+	struct task_struct* task;
+	task = Thread_get_native(target);
+
+	return thread_terminate_sig(target, SIGKILL);
+}
+
+/**/
+#define r_sp r13
+#define r_lr r14
+#define r_pc r15
+#define r_cpsr r16
+
+kern_return_t bsdthread_create_fork_arm(void* stack, void* fn, void* arg, size_t stack_size, void* thread_addr)
+{
+	task_port_t* current_task;
+	thread_port_t* mk_thread;
+	ke_port_right_t* mk_thread_right;
+
+	arm_thread_state_t _regs;
+	arm_thread_state_t* regs;
+
+	uint32_t initial_pc;
+
+	regs = &_regs;
+	current_task = Native_get_task(current);
+	initial_pc = (uint32_t)current->p_threadstart;
+
+	thread_create(current_task, &mk_thread_right);
+	mk_thread = (thread_port_t*)mk_thread_right->port;
+
+	Xwarn("bsdthread_create_fork_arm(): mach thread forked, task[%p], mtask[%p]", mk_thread->task, mk_thread->task->task_port);
+
+	PortRelease(current_task);
+
+	/* Okay, set the initial thread state */
+	regs->r0 = (uint32_t)thread_addr;
+	regs->r1 = (uint32_t)mk_thread_right->name;
+	regs->r2 = (uint32_t)fn;
+	regs->r3 = (uint32_t)arg;
+	regs->r4 = (uint32_t)stack_size;
+	regs->r5 = (uint32_t)0;
+
+	/* Stack pointer */
+	regs->r_sp = (uint32_t)stack;
+
+	/* Entry point */
+	regs->r_pc = (uint32_t)(initial_pc & ~1);	
+
+	/* Userland mode & endinaness */
+	regs->r_cpsr = USR_MODE; 
+	regs->r_cpsr |= PSR_ENDSTATE;
+
+	/* Start execution in thumb mode? */
+	if (initial_pc & 1) {
+		regs->r_cpsr |= PSR_T_BIT;
+	}
+
+	thread_set_state(mk_thread, 0, regs, sizeof(_regs));
+
+	thread_resume(mk_thread);
+
+	return KERN_SUCCESS;
+}
+
+void* _user_bsdthread_create(void* _args)
+{
+	bsd_crt_args_t args;
+	unsigned int flags;
+	void* stack;
+	task_port_t* tp;
+	size_t stack_size = 0;
+	uintptr_t addr = 0;
+	kern_return_t retval;
+	uintptr_t th_stack;
+	uintptr_t th_pthread = 0;
+
+	if (copy_from_user(&args, _args, sizeof(bsd_crt_args_t)))
+	{
+		/* wtf */
+		return (void*)-1;
+	}
+
+	flags = args.flags;
+	tp = Native_get_current_task();
+	/*
+		void* func;
+		void* func_arg;
+		void* stack;
+		void* thread;
+		unsigned int flags;
+	*/
+
+	if ((flags & PTHREAD_START_CUSTOM) == 0) {
+		/* We need to allocate the stack ourselves */
+		stack_size = (size_t)args.stack + (size_t)PAGE_SIZE + (size_t)current->p_pthsize;
+		retval = mach_task_vm_allocate(tp, &addr, stack_size, true);
+
+		if (retval != KERN_SUCCESS) {
+			Xwarn("failed to allocate user stack!");
+			goto out_tp;
+		}
+
+		th_stack = (uintptr_t)addr + (uintptr_t)args.stack + (uintptr_t)PAGE_SIZE;
+		th_pthread = th_stack; /* stack grows down, thread is just above it */
+
+		Xlog("thread stack allocated at %p, dw at %p (size: %p)", (void*)addr, th_stack, stack_size);
+	}
+	else 
+	{
+		/* Userland wants to use its own stack, so let it */
+		th_pthread = (uintptr_t)args.thread;
+
+		/* Wtf, but that's what XNU does */
+		th_stack = (uintptr_t)args.stack;
+		stack_size = (size_t)args.stack;
+	}
+
+	stack = (void*)th_stack;
+
+	Xlog("%p %p %p %p %p", args.func, args.func_arg, args.stack, args.thread, args.flags);
+
+	/* Create the platform thread */
+	retval = bsdthread_create_fork_arm(stack, args.func, args.func_arg, stack_size, (void*)th_pthread);
+
+	if (retval != KERN_SUCCESS)
+	{
+		panic("bsdthread_create(): failed to create a thread!");
+	}
+
+out_tp:
+	PortRelease(tp);
+	return (void*)th_pthread;
+}
+
+int _user_bsdthread_register(void* _args)
+{
+	bsd_reg_args_t args;
+
+	if (copy_from_user(&args, _args, sizeof(bsd_reg_args_t)))
+	{
+		return -1;
+	}
+
+	/*
+		void* start_fn;
+		void* wstart_fn;
+		int thread_size;
+		void* pthread_start_fn;
+		void* workq;
+		uint64_t tsd;
+	*/
+
+	Xlog("%p %p %d %p %p %ld", args.start_fn, args.wstart_fn, args.thread_size, args.pthread_start_fn, args.workq, args.tsd);
+
+	/* Wow, this is easier than I thought ... */
+	current->p_threadstart = args.start_fn;
+	current->p_wqthread = args.wstart_fn;
+	current->p_targconc = args.pthread_start_fn;
+	current->p_dispatchqueue_offset = args.tsd;
+	current->p_pthsize = args.thread_size;
+
+	return 0;
+}
+
+kern_return_t _user_thread_policy(mach_port_t prt, integer_t policy, integer_t* base, integer_t* sz, boolean_t set_limit)
+{
+	Xlog("set policy %p for thread[%d]", policy, prt);
+	return KERN_SUCCESS;
+}
+
+thread_port_t* mach_thread_self(void)
+{
+	return Native_get_current_thread();
+}
+
+kern_return_t _user_thread_self(void)
+{
+	/* We should already hold the send right */
+	thread_port_t* th = Native_get_current_thread();
+
+	task_port_t* tp = Native_get_current_task();
+	ke_port_right_t* rcv = Task_get_right(tp, (ke_port_t*)th, false);
+
+	if (rcv) {
+		mach_port_t nm = rcv->name;
+		PortRelease(tp);
+		PortRelease(th);
+		RightDecrementRefCount(rcv, r_kernel);
+		return nm;
+	}
+	else {
+		/*
+		 * This shouldn't ever happen.
+		 */
+		panic("_user_thread_self: mach thread port invalid for task %p", current);
+		return 0;
+	}
+}
+
+mach_port_t _user_task_self(void)
+{
+	/* We should already hold the send right*/
+	task_port_t* tp = Native_get_current_task();
+	ke_port_right_t* rcv = Task_get_right(tp, (ke_port_t*)tp, false);
+
+	if (rcv) {
+		mach_port_t nm = rcv->name;
+		PortRelease(tp);
+		return nm;
+	}
+	else {
+		/*
+		 * This shouldn't ever happen.
+		 */
+		panic("_user_task_self: mach task port invalid for task %p", current);
+		return 0;
+	}
+}
+
+kern_return_t _user_thread_resume(mach_port_t _target)
+{	
+	thread_port_t* target;
+	kern_return_t ret;
+
+	ret = mach_thread_for_name(_target, &target);
+	if (ret != KERN_SUCCESS) {
+		return ret;
+	}
+	else
+	{
+		ret = thread_resume(target);
+		PortRelease(target);
+	}
+
+	return ret;
+}
+
+kern_return_t _user_thread_suspend(mach_port_t _target)
+{	
+	thread_port_t* target;
+	kern_return_t ret;
+
+	ret = mach_thread_for_name(_target, &target);
+	if (ret != KERN_SUCCESS) {
+		return ret;
+	}
+	else
+	{
+		ret = thread_suspend(target);
+		PortRelease(target);
+	}
+
+	return ret;
+}
+
+kern_return_t _user_thread_get_state(mach_port_t _target, natural_t _flavor, void* _old_state, natural_t* _count)
+{	
+	thread_port_t* target;
+	kern_return_t ret;
+
+	ret = mach_thread_for_name(_target, &target);
+	if (ret != KERN_SUCCESS) {
+		return ret;
+	}
+	else
+	{
+		arm_thread_state_t state;
+		natural_t count = sizeof(state);
+
+		ret = thread_get_state(target, _flavor, (void*)&state, &count);
+		if (ret != KERN_SUCCESS) {
+			PortRelease(target);
+			return ret;
+		}
+
+		if (copy_to_user(_old_state, (void*)&state, count)) {
+			PortRelease(target);
+			return KERN_FAILURE;
+		}
+
+		__put_user(count, _count);
+
+		PortRelease(target);
+
+		Xwarn("_user_thread_get_state(): returned thread state for thread %d", _target);
+		return KERN_SUCCESS;
+	}
+}
+
+kern_return_t _user_task_threads(mach_port_t target_task, uintptr_t *threads, natural_t *thread_count)
+{
+	struct task_struct* tsk;
+	task_port_t* port;
+	kern_return_t ret;
+	task_port_t* cur;
+	natural_t count = 0;
+	uintptr_t addr = 0;
+	mach_port_t* mach_port_user_array;
+
+	ret = mach_task_port_for_name(target_task, &port);
+	if (ret != KERN_SUCCESS) {
+		return ret;
+	}
+
+	/* Gah */
+	for_each_process(tsk)
+	{
+		if (tsk->task_port == port)
+		{
+			count++;
+		}
+	}
+
+	cur = Native_get_current_task();
+
+	/* Allcoate pages to store the array on */
+	ret = mach_task_vm_allocate(cur, &addr, count * sizeof(mach_port_t), true);
+	BUG_ON(ret != KERN_SUCCESS);
+
+	mach_port_user_array = (mach_port_t*)(addr);
+
+	for_each_process(tsk)
+	{
+		if (tsk->task_port == port)
+		{
+			ke_port_right_t* snd;
+			thread_port_t* th;
+
+			th = Native_get_thread(tsk);
+
+			/* Get the send right for this thread, create if needed */
+			snd = Task_get_right(cur, (ke_port_t*)th, true);
+			BUG_ON(snd == NULL);
+
+			RightIncrementRefCount(snd, r_send);
+
+			__put_user(snd->name, mach_port_user_array);
+			mach_port_user_array++;
+
+			/* Release bits */
+			RightDecrementRefCount(snd, r_kernel);
+			PortRelease(th);
+		}
+	}
+
+	/* Return */
+	__put_user(addr, threads);
+	__put_user(count, thread_count);
+
+	PortRelease(cur);
+	PortRelease(port);
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t _user_thread_switch(mach_port_name_t thread_name, int option, natural_t option_time)
+{
+	/* This isn't quite supported ... */
+
+	Xwarn("thread[%d] not switching, just yielding!", thread_name);
+	yield();
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t _user_pid_for_task(mach_port_name_t t, int *x)
+{
+	task_port_t* tp;
+	struct task_struct* tsk;
+
+
+	tp = (task_port_t*)Task_find_port(t);
+
+	if (!tp) {
+		return KERN_INVALID_NAME;
+	}
+
+	tsk = tp->task;
+
+	if (!tsk) {
+		panic("task port %p doesn't have a task!", tp);
+	}
+
+	/* I hope pid_t is an int ... */
+	__put_user(tsk->pid, x);
+	PortRelease(tp);
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t _user_task_for_pid(mach_port_t target_tport, int pid, mach_port_t *t)
+{
+	ke_port_right_t* snd;
+	task_port_t* tp;
+	struct task_struct* rem;
+	ke_port_t* rp;
+
+	tp = (task_port_t*)Task_find_port(target_tport);
+
+	if (!tp) {
+		return KERN_INVALID_NAME;
+	}
+
+	rem = find_task_by_vpid(pid);
+	if (!rem) {
+		Xwarn("pid(%d): vpid not found!", pid);
+		return KERN_FAILURE;
+	}
+
+	rp = (ke_port_t*)(rem->task_port);
+	if (!rp) {
+		panic("task %p doesn't have a task port!", rem);
+	}
+
+	snd = Task_get_right(tp, rp, true);
+	if (!snd) {
+		Xwarn("pid(%d): failed to add right to space!", pid);
+		PortRelease(tp);
+		return KERN_FAILURE;
+	}
+
+	RightIncrementRefCount(snd, r_send);
+
+	__put_user(snd->name, t);
+
+	PortRelease(tp);
+
+	return KERN_SUCCESS;
+}
+
+kern_return_t mach_task_port_for_name(mach_port_t user_port, task_port_t** out)
+{
+	return Task_get_object_if_send(user_port, (Obj**)out, KE_PORT_TYPE_TASK);
+}
+
+#define xxxxx() Xwarn("not yet implemented");
+#define xxxxx_panic() ke_critical("THREAD: %s not impl", __FUNCTION__);
+
+
+int _user__disable_threadsignal(int xx) {
+	xxxxx();
+	return 0;
+}
+
+int _user_thread_selfid(uint64_t* ret)
+{
+	__put_user(task_pid_vnr(current), ret);
+	return 0;
+}
+
+kern_return_t _user_syscall_thread_switch(mach_port_name_t a , int b, int c)
+{
+	xxxxx_panic();
+}
+
+int _user_bsdthread_terminate(void * freeaddr, size_t freesize, mach_port_t kport, mach_port_t joinsem)
+{
+	thread_port_t* thread;
+
+	thread = Native_get_current_thread();
+
+	/* mach_vm_deallocate(current_map(), freeaddr, freesize); */
+
+	Xwarn("terminating current thread ...");
+
+	thread_terminate(thread);
+
+	PortRelease(thread);
+
+	thread_exception_return();
+
+	panic("_user_bsdthread_terminate(): thread still running!");
+}
+
+int _user__pthread_canceled(int x)
+{
+	thread_port_t* thread;
+
+	if (x != 1 && x != 2)
+	{
+		return -1;
+	}
+
+	thread = Native_get_current_thread();
+
+	if (x == 1)
+	{
+		/* enable */
+		thread->can_cancel = true;
+	}
+	else
+	{
+		/* disable */
+		thread->can_cancel = false;
+	}
+
+	PortRelease(thread);
+
+	return 0;
+}
+
+int _user__pthread_kill(mach_port_t port, int x)
+{
+	/* Kill BSD thread with signal */
+	kern_return_t ret;
+	thread_port_t* thread;
+
+	ret = mach_thread_for_name(port, &thread);
+	if (ret != KERN_SUCCESS) {
+		return -1;
+	}
+
+	/* Kill pthread with a signal */
+	thread_terminate_sig(thread, x);
+
+	PortRelease(thread);
+
+	thread_exception_return();
+
+	return 0;
+}
+
+int _user__pthread_markcancel(int x)
+{
+	thread_port_t* thread;
+	int ret = 0;
+
+	thread = Native_get_current_thread();
+
+	if (thread->can_cancel)
+	{
+		thread_terminate(thread);
+		PortRelease(thread);
+		thread_exception_return();
+	}
+	else
+	{
+		PortRelease(thread);
+	}
+
+	return ret;
+}
+
+int _user__workq_open(void)
+{
+	xxxxx_panic();
+}
+
+void __ke_memtest(void)
+{
+	
+}
\ No newline at end of file
diff -Naur ./kos//magenta/mach_user_port.c ./kern//magenta/mach_user_port.c
--- ./kos//magenta/mach_user_port.c	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_user_port.c	2012-08-06 10:39:38.000000000 -0400
@@ -0,0 +1,668 @@
+/*
+ * mach_user_port.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Anything to do with ports that a user thing may create.
+ * This involves:
+ *     > IPC ports
+ *     > Port sets
+ *
+ * Do not call this from IRQ context, or you will break it.
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+#include "ke_runtime.h"
+
+#include "Ipc.h"
+
+/* ipc port ops */
+kern_return_t Ipc_port_receive(struct __Obj* port, ipc_trap_data_t* info);
+kern_return_t Ipc_port_send(struct __Obj* port, ipc_trap_data_t* info);
+ke_port_ops_t _ipc_port_ops = {
+	.msg_receive = Ipc_port_receive,
+	.msg_send = Ipc_port_send
+};
+
+/* port set ops */
+kern_return_t Ipc_port_set_receive(struct __Obj* port, ipc_trap_data_t* info);
+ke_port_ops_t _ipc_port_set_ops = {
+	.msg_receive = Ipc_port_set_receive
+};
+
+
+/*
+ * This copies data to a userland buffer if the message is received from
+ * the userspace or to a kernel memory chunk if it is received from the 
+ * kernel.
+ */
+boolean_t ipc_copy_data_local(void* to, void* from, unsigned long size, boolean_t user)
+{
+	if (user) {
+		if (copy_to_user(to, from, size)) {
+			return false;
+		}
+		else {
+			return true;
+		}
+	}
+	else {
+		memcpy(to, from, size);
+		return true;
+	}
+}
+
+kern_return_t Ipc_port_receive(struct __Obj* port, ipc_trap_data_t* info)
+{
+	return 11;
+}
+
+kern_return_t Ipc_port_send(struct __Obj* port, ipc_trap_data_t* info)
+{
+	ipc_port* iport = (ipc_port*)port;
+	ipc_message* msg;
+	mach_msg_header_t* buffer = info->snd_msg;
+	kern_return_t ret;
+
+	BUG_ON(!port);
+	BUG_ON(port->type != KE_PORT_TYPE_IPC);
+
+	msg = Ipc_message_allocate(buffer, info->snd_size, info->task);
+
+	BUG_ON(!msg);
+
+	ret = Ipc_msg_send_block(iport, msg);
+
+	return ret;
+}
+
+/*
+ * Receiving a mach message on a port set.
+ */
+kern_return_t Ipc_port_set_receive(struct __Obj* port, ipc_trap_data_t* info)
+{
+	kern_return_t retval;
+	ipc_port_set* pset = (ipc_port_set*)port;
+
+	int qr = 0;
+	unsigned int count;
+	unsigned int i;
+	ipc_message* rcv_msg = NULL;
+	ipc_port** ports;
+	kern_return_t rcv_ret;
+	boolean_t has_messages = false;
+
+	task_port_t* self = info->task;
+
+	BUG_ON(!port);
+	BUG_ON(port->type != KE_PORT_TYPE_PORT_SET);
+
+	/* compat */
+	PortRetain(pset);
+
+L_retry_ports:
+	/*
+	 * we can't have irqs firing while this code runs 
+	 * for obvious reasons.
+	 */
+	spin_lock(&pset->port_list_lock);
+
+	count = ke_array_get_count(pset->port_list);
+	ports = (ipc_port**)__ke_array_get_base(pset->port_list);
+
+	for (i = 0; i < count; i++)
+	{
+		ipc_port* rcv_port;
+
+		rcv_port = ports[i];
+
+		/*
+			kern_return_t Ipc_msg_receive_block(ipc_port* rcv_port,
+				task_port_t* task,
+				ipc_message** out_message,
+				size_t max_size,
+				boolean_t large);
+		*/
+
+		/* attempt to receive on a port */
+		rcv_ret = Ipc_msg_receive_nonblock(rcv_port,
+			self,
+			&rcv_msg,
+			info->rcv_size,
+			info->options & MACH_RCV_LARGE);
+
+		if (rcv_ret == MACH_RCV_IN_PROGRESS) {
+			continue;
+		}
+		else if (rcv_ret == MACH_MSG_SUCCESS) {
+			has_messages = true;
+			break;
+		}
+		else {
+			if (info->options & MACH_RCV_LARGE && rcv_ret == MACH_RCV_TOO_LARGE)
+			{
+				XWarn("port[%p] msg MACH_MSG_TOO_LARGE, copyout the header!", rcv_port);
+				has_messages = true;
+
+				panic("%s(): implement MACH_MSG_TOO_LARGE!", __FUNCTION__);
+
+				break;
+			}
+			else
+			{
+				XWarn("port[%p] in the set error: %d", rcv_port, rcv_ret);
+				continue;
+			}
+		}
+	}
+
+	spin_unlock(&pset->port_list_lock);
+
+	if (has_messages)
+	{
+		Xlog("found message[%p] on iter %d", rcv_msg, i);
+
+		if (!ipc_copy_data_local(info->rcv_buffer, rcv_msg->msg, rcv_msg->size, info->options & MACH_MSG_USER))
+		{
+			Xwarn("can't write message %p", rcv_msg);
+			retval = KERN_FAILURE; /* userland seriously screwed up*/
+			goto a_pset;
+		}
+
+		retval = MACH_MSG_SUCCESS;
+		goto a_pset;
+	}
+	else
+	{
+		XLog("waiting on a port set queue (port_set[%p]) ...", pset);
+		qr = wait_event_interruptible((pset->wait_queue), false);
+		
+		if (qr == -ERESTARTSYS)
+		{
+			XLog("wait aborted!");
+			retval = MACH_RCV_INTERRUPTED;
+			goto a_pset;
+		}
+		else
+		{
+			/* one of the ports has woken us up! */
+			Xwarn("port_set_message_handle(): pset[%p] retry!", pset);
+
+			/* XXX: this is really really bad and unfair */
+			goto L_retry_ports;
+		}
+	}
+
+	
+a_pset:
+	PortRelease(pset);
+out:
+	return retval;
+}
+
+ke_port_right_t* port_set_allocate(task_port_t* space)
+{
+	ipc_port_set* prt = NULL;
+	ke_port_right_t* rr = NULL;
+
+	rr = ke_new_port(KE_PORT_TYPE_PORT_SET);
+	if (!rr || !rr->port) {
+		return NULL;
+	}
+	prt = (ipc_port_set*)rr->port;
+
+	/* operations*/
+	prt->port.ops = &_ipc_port_set_ops;
+
+	/* global queue for this port set */
+	init_waitqueue_head(&(prt->wait_queue));
+
+	/* members */
+	prt->port_list = ke_array_with_capacity(0);
+	spin_lock_init(&prt->port_list_lock);
+
+	/* Add a port set right */
+	RightIncrementRefCount(rr, r_port_set);
+
+	rr->name = ke_get_new_port_name_in_space(space);
+	ke_add_right_to_space(space, rr);
+
+	return rr;
+}
+
+ke_port_right_t* ipc_port_allocate(task_port_t* space)
+{
+	ipc_port* prt = NULL;
+	ke_port_right_t* rr = NULL;
+
+	rr = ke_new_port(KE_PORT_TYPE_IPC);
+	if (!rr || !rr->port) {
+		return NULL;
+	}
+	prt = (ipc_port*)rr->port;
+
+	prt->port.ops = &_ipc_port_ops;
+
+	/* create a message queue */
+	if(kfifo_alloc(&(prt->queue), PAGE_SIZE, GFP_KERNEL)) {
+		panic("allocate_ipc_port(): can't create a message queue");
+	}
+
+	/* 
+	 * create a completion variable to hang on if the
+	 * queue is empty 
+	 */
+	init_waitqueue_head(&(prt->wait_queue));
+
+	/* create a list of wait queues */
+	prt->wait_list = ke_array_with_capacity(0);
+	spin_lock_init(&prt->wait_list_lock);
+
+	/* insert the wait queue */
+	ke_array_add(prt->wait_list, &prt->wait_queue);
+
+	/* Add a receive right for the task */
+	RightIncrementRefCount(rr, r_receive);
+	rr->name = ke_get_new_port_name_in_space(space);
+	ke_add_right_to_space(space, rr);
+
+	return rr;
+}
+
+kern_return_t mach_port_allocate(ipc_space_t task, mach_port_right_t right, mach_port_name_t *name)
+{
+	if (!task->port.active) {
+		return KERN_FAILURE;
+	}
+
+	if (right == MACH_PORT_RIGHT_RECEIVE)
+	{
+		/*
+		 * Ports created with 'MACH_PORT_RIGHT_RECEIVE' are IPC ports.
+		 */
+		ke_port_right_t* rr = ipc_port_allocate(task);
+
+		Xlog("allocating ipc port [%d]", rr->name);
+
+		if (rr) {
+			*name = rr->name;
+		}
+		else {
+			return KERN_FAILURE;
+		}
+		
+		return KERN_SUCCESS;
+	}
+	else if (right == MACH_PORT_RIGHT_PORT_SET)
+	{
+		/*
+		 * Port set.
+		 */
+		ke_port_right_t* rr = port_set_allocate(task);
+
+		Xlog("allocating port set [%d]", rr->name);
+
+		if (rr) {
+			*name = rr->name;
+		}
+		else {
+			return KERN_FAILURE;
+		}
+		
+		return KERN_SUCCESS;
+	}
+	else
+	{
+		/* Unknown right type */
+		return KERN_FAILURE;
+	}
+}
+
+kern_return_t _user_mach_port_insert_right(mach_port_t task, mach_port_name_t in_name, mach_port_name_t in_right, mach_msg_type_name_t right_type)
+{
+	ke_port_right_t* name;
+	ke_port_right_t* right;
+	task_port_t* target_space;
+	kern_return_t ret;
+
+	if (right != name) {
+		ke_warn("_user_mach_port_insert_right(): XXX (right != name)\n");
+		return KERN_FAILURE;
+	}
+
+	target_space = (task_port_t*)Task_find_port(task);
+
+	if (!target_space) {
+		return KERN_INVALID_NAME;
+	}
+
+	name = Task_find_right(in_name);
+	if (!name) {
+		return KERN_INVALID_NAME;
+	}
+	if (!name->port) {
+		PortRelease(target_space);
+		RightDecrementRefCount(name, r_kernel);
+		return KERN_FAILURE;
+	}
+
+	/* Insert the right into the target IPC space */
+	right = Task_get_right(target_space, name->port, true);
+	if (!right) {
+		panic("_user_mach_port_insert_right(): ke_get_right_in_space failed");
+	}
+
+	/*
+	 * Now depending on the type of the right transferred, change stuff
+	 * [XXX]: Check if we hold the valid right needed to perform the operation.
+	 */
+	switch (right_type)
+	{
+		case MACH_MSG_TYPE_MAKE_SEND:
+		{
+			RightIncrementRefCount(right, r_send);
+			ret = KERN_SUCCESS;
+			break;
+		}
+		case MACH_MSG_TYPE_COPY_SEND:
+		{
+			RightIncrementRefCount(right, r_send);
+			ret = KERN_SUCCESS;
+			break;
+		}
+		case MACH_MSG_TYPE_MOVE_SEND:
+		{
+			RightIncrementRefCount(right, r_send);
+			RightDecrementRefCount(name, r_send);
+			ret = KERN_SUCCESS;
+			break;
+		}
+		case MACH_MSG_TYPE_MOVE_RECEIVE:
+		{
+			RightIncrementRefCount(right, r_receive);
+			RightDecrementRefCount(name, r_receive);
+			ret = KERN_SUCCESS;
+			break;
+		}
+		case MACH_MSG_TYPE_COPY_RECEIVE:
+		{
+			Xwarn("invalid argument");
+			ret = KERN_FAILURE;
+			break;
+		}
+		default:
+		{
+			Xwarn("unknown argument %d", right_type);
+			ret = KERN_FAILURE;
+			break;
+		}
+	}
+
+	PortRelease(name->port);
+	PortRelease(target_space);
+	RightDecrementRefCount(name, r_kernel);
+	RightDecrementRefCount(right, r_kernel);
+	return ret;
+}
+
+kern_return_t _user_mach_port_insert_member(mach_port_name_t _task, mach_port_name_t _name, mach_port_name_t _pset)
+{
+	kern_return_t retval;
+
+	ipc_port_set* pset;
+	ke_port_right_t* pset_right;
+	task_port_t* target_space;
+	ke_port_right_t* member;
+
+	Xlog("port[%d] => pset[%d]", _name, _pset);
+
+	target_space = (task_port_t*)ke_port_find_named((mach_port_t)_task);
+	if (!target_space) {
+		return KERN_INVALID_NAME;
+	}
+
+	/* XXX: task send right? */
+
+	member = Task_find_right(_name);
+	if (!member) {
+		Xwarn("invalid member name [%d]", _name);
+		retval = KERN_INVALID_NAME;
+		goto a_task;
+	}
+
+	pset_right = Task_find_right(_pset);
+	if (!pset_right) {
+		Xwarn("invalid port set name [%d]", _pset);
+		retval = KERN_INVALID_NAME;
+		goto a_member;
+	}
+
+	/* kk */
+	pset = (ipc_port_set*)pset_right->port;
+
+	/* checks */
+	if (!IsReceiveRight(member))
+	{
+		retval = KERN_INVALID_RIGHT;
+		goto a_pset;
+	}
+
+	if (!IsPortSetRight(pset_right))
+	{
+		retval = KERN_INVALID_RIGHT;
+		goto a_pset;
+	}
+
+	/* okay, just to be safe */
+	BUG_ON(pset_right->port->type != KE_PORT_TYPE_PORT_SET);
+	BUG_ON(member->port->type != KE_PORT_TYPE_IPC);
+
+	/* now actually add */
+	spin_lock(&pset->port_list_lock);
+	ke_array_add(pset->port_list, (ke_storage_type)member->port);
+	spin_unlock(&pset->port_list_lock);
+
+	Ipc_port_add_queue((ipc_port*)member->port, &pset->wait_queue);
+
+	/* safe to increment the refcount in this context */
+	PortRetain(member->port);
+
+	/* ok, success */
+	retval = KERN_SUCCESS;
+
+	/* teardown */
+a_pset:
+	PortRelease(pset);
+	RightDecrementRefCount(pset_right, r_kernel);
+a_member:
+	PortRelease(member->port);
+	RightDecrementRefCount(member, r_kernel);
+a_task:
+	PortRelease(target_space);
+	return retval;
+}
+
+/*
+ * Support for the mk_timer syscall familiy.
+ * This provides a nice mach port based timer interface.
+ */
+mach_port_name_t _user_mk_timer_create(void) 
+{
+	ke_port_right_t* rr = ipc_port_allocate(ke_get_current_task());
+
+	Xlog("allocated a timer ipc port [%d]", rr->name);
+
+	return rr->name;
+}
+
+kern_return_t _user_mk_timer_destroy(mach_port_name_t name)
+{
+	Xlog("destroy port[%d]", name);
+
+	return KERN_FAILURE;
+}
+
+typedef struct {
+	ipc_port* timer_port;
+	mach_port_name_t name;
+} __mk_timer;
+
+void __mk_timer_fire(unsigned long data)
+{
+	ipc_port* timer_port;
+	mach_msg_header_t* msg; 
+	__mk_timer* kt;
+	mach_port_name_t name;
+	ipc_message* im;
+
+	kt = (__mk_timer*)data;
+	timer_port = kt->timer_port;
+	name = kt->name;
+
+	/* we're done with kt */
+	kfree(kt);
+
+	Xwarn("timer port[%d] (ke_port[%p]) fired", name, timer_port);
+
+	/* paranoia ... */
+	BUG_ON(timer_port->port.type != KE_PORT_TYPE_IPC);
+
+	/* this will be released by the kernel later */
+	msg = kmalloc(sizeof(*msg), GFP_KERNEL);
+
+	/* timer message */
+	msg->msgh_size = sizeof(*msg);
+	msg->msgh_remote_port = name;
+	msg->msgh_local_port = 0;
+	msg->msgh_id = 0;
+	msg->msgh_bits = MACH_MSGH_BITS(MACH_MSG_TYPE_COPY_SEND, 0);
+
+	im = Ipc_message_allocate(msg, sizeof(*msg), get_kernel_task());
+
+	/* send! */
+	Ipc_msg_send_nonblock(timer_port, im);
+}
+
+kern_return_t _user_mk_timer_arm(mach_port_name_t name, uint64_t expire_time)
+{
+	ke_port_right_t* right;
+	kern_return_t retval = KERN_FAILURE;
+	ipc_port* tp;
+	__mk_timer* kt;
+
+	right = Task_find_right(name);
+	if (!right) {
+		Xwarn("mk_timer_arm(): timer port invalid!");
+		retval = KERN_INVALID_NAME;
+		goto out;
+	}
+
+	Xwarn("arm port[%d] (ke_port[%p]) after delay %ld", name, right->port, expire_time);
+
+	if (!IsReceiveRight(right))
+	{
+		Xwarn("mk_timer_arm(): timer port not a rcv right!");
+		retval = KERN_INVALID_RIGHT;
+		goto out;
+	}
+
+	/* just to be sure ... */
+	BUG_ON(right->port->type != KE_PORT_TYPE_IPC);
+
+	kt = kmalloc(sizeof(*kt), GFP_KERNEL);
+	tp = (ipc_port*)right->port;
+
+	/* thing */
+	kt->timer_port = tp;
+	kt->name = name;
+
+	/* STAND BACK, CREATING A KERNEL TIMER. */
+	init_timer(&tp->ktimer);
+
+	tp->ktimer.expires = jiffies + expire_time;
+	tp->ktimer.data = (unsigned long)kt;
+	tp->ktimer.function = __mk_timer_fire;
+
+	RightDecrementRefCount(right, r_kernel);
+	retval = KERN_SUCCESS;
+	/* not releasing the port as the firing function needs it */
+
+	/* activate the timer */
+	add_timer(&tp->ktimer);
+
+out:
+	return retval;
+}
+
+kern_return_t _user_mk_timer_cancel(mach_port_name_t name, uint64_t *result_time)
+{
+	return KERN_FAILURE;
+}
+
+
+kern_return_t _user_mach_port_mod_refs(mach_port_t task, mach_port_name_t name, mach_port_right_t right, mach_port_delta_t delta)
+{
+	return KERN_FAILURE;
+}
+
+kern_return_t _user_mach_port_destroy(mach_port_t task,mach_port_name_t name)
+{
+	return KERN_FAILURE;
+}
+
+kern_return_t _user_mach_port_deallocate(mach_port_t task,mach_port_name_t name)
+{
+	return KERN_FAILURE;
+}
+
+kern_return_t _user_mach_port_allocate(mach_port_t task, mach_port_right_t right, mach_port_name_t *name)
+{
+	kern_return_t ret;
+	mach_port_name_t nn;
+	ipc_space_t port;
+
+	port = (task_port_t*)ke_port_find_named(task);
+	if (!port) {
+		return KERN_INVALID_NAME;
+	}
+
+	ret = mach_port_allocate(port, right, &nn);
+
+	__put_user(nn, name);
+
+	PortRelease(port);
+
+	return ret;
+}
+
+//mach_port_allocate(ke_get_current_task(), MACH_PORT_RIGHT_RECEIVE, &mp);
\ No newline at end of file
diff -Naur ./kos//magenta/magenta_kernel ./kern//magenta/magenta_kernel
--- ./kos//magenta/magenta_kernel	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/magenta_kernel	2012-07-02 17:44:36.000000000 -0400
@@ -0,0 +1,6023 @@
+diff -Naur ./old//arch/arm/boot/compressed/misc.c ./kern//arch/arm/boot/compressed/misc.c
+--- ./old//arch/arm/boot/compressed/misc.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/boot/compressed/misc.c	2012-04-18 18:37:43.000000000 +0100
+@@ -200,9 +200,10 @@
+ 	tmp = (unsigned char *) (((unsigned long)input_data_end) - 4);
+ 	output_ptr = get_unaligned_le32(tmp);
+ 
+-	putstr("Uncompressing Linux...");
++	putstr("Decompressing kernel ...");
+ 	do_decompress(input_data, input_data_end - input_data,
+ 			output_data, error);
+-	putstr(" done, booting the kernel.\n");
++	putstr("\nDone, booting the kernel ...\n\n");
++	
+ 	return output_ptr;
+ }
+diff -Naur ./old//arch/arm/include/asm/signal.h ./kern//arch/arm/include/asm/signal.h
+--- ./old//arch/arm/include/asm/signal.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/include/asm/signal.h	2012-06-13 21:30:48.000000000 +0100
+@@ -14,7 +14,7 @@
+ #define _NSIG_BPW	32
+ #define _NSIG_WORDS	(_NSIG / _NSIG_BPW)
+ 
+-typedef unsigned long old_sigset_t;		/* at least 32 bits */
++typedef uint32_t old_sigset_t;		/* at least 32 bits */
+ 
+ typedef struct {
+ 	unsigned long sig[_NSIG_WORDS];
+@@ -28,43 +28,47 @@
+ 
+ #endif /* __KERNEL__ */
+ 
+-#define SIGHUP		 1
+-#define SIGINT		 2
+-#define SIGQUIT		 3
+-#define SIGILL		 4
+-#define SIGTRAP		 5
+-#define SIGABRT		 6
+-#define SIGIOT		 6
+-#define SIGBUS		 7
+-#define SIGFPE		 8
+-#define SIGKILL		 9
+-#define SIGUSR1		10
+-#define SIGSEGV		11
+-#define SIGUSR2		12
+-#define SIGPIPE		13
+-#define SIGALRM		14
+-#define SIGTERM		15
+-#define SIGSTKFLT	16
+-#define SIGCHLD		17
+-#define SIGCONT		18
+-#define SIGSTOP		19
+-#define SIGTSTP		20
+-#define SIGTTIN		21
+-#define SIGTTOU		22
+-#define SIGURG		23
+-#define SIGXCPU		24
+-#define SIGXFSZ		25
+-#define SIGVTALRM	26
+-#define SIGPROF		27
+-#define SIGWINCH	28
+-#define SIGIO		29
+-#define SIGPOLL		SIGIO
++
++#define	SIGHUP	1	/* hangup */
++#define	SIGINT	2	/* interrupt */
++#define	SIGQUIT	3	/* quit */
++#define	SIGILL	4	/* illegal instruction (not reset when caught) */
++#define	SIGTRAP	5	/* trace trap (not reset when caught) */
++#define	SIGABRT	6	/* abort() */
++#define	SIGPOLL	7	/* pollable event ([XSR] generated, not supported) */
++#define	SIGIOT	SIGABRT	/* compatibility */
++#define	SIGEMT	7	/* EMT instruction */
++#define	SIGFPE	8	/* floating point exception */
++#define	SIGKILL	9	/* kill (cannot be caught or ignored) */
++#define	SIGBUS	10	/* bus error */
++#define	SIGSEGV	11	/* segmentation violation */
++#define	SIGSYS	12	/* bad argument to system call */
++#define	SIGPIPE	13	/* write on a pipe with no one to read it */
++#define	SIGALRM	14	/* alarm clock */
++#define	SIGTERM	15	/* software termination signal from kill */
++#define	SIGURG	16	/* urgent condition on IO channel */
++#define	SIGSTOP	17	/* sendable stop signal not from tty */
++#define	SIGTSTP	18	/* stop signal from tty */
++#define	SIGCONT	19	/* continue a stopped process */
++#define	SIGCHLD	20	/* to parent on child stop or exit */
++#define	SIGTTIN	21	/* to readers pgrp upon background tty read */
++#define	SIGTTOU	22	/* like TTIN for output if (tp->t_local&LTOSTOP) */
++#define	SIGIO	23	/* input/output possible signal */
++#define	SIGXCPU	24	/* exceeded CPU time limit */
++#define	SIGXFSZ	25	/* exceeded file size limit */
++#define	SIGVTALRM 26	/* virtual time alarm */
++#define	SIGPROF	27	/* profiling time alarm */
++#define SIGWINCH 28	/* window size changes */
++#define SIGINFO	29	/* information request */
++#define SIGUSR1 30	/* user defined signal 1 */
++#define SIGUSR2 31	/* user defined signal 2 */
++
+ /*
+ #define SIGLOST		29
+ */
+-#define SIGPWR		30
+-#define SIGSYS		31
+-#define	SIGUNUSED	31
++#define SIGPWR		32
++#define	SIGUNUSED	32
++#define SIGSTKFLT	32
+ 
+ /* These should not be considered constants from userland.  */
+ #define SIGRTMIN	32
+@@ -114,11 +118,14 @@
+ #include <asm-generic/signal-defs.h>
+ 
+ #ifdef __KERNEL__
++
++#include <DarwinTypes.h>
++
+ struct old_sigaction {
+ 	__sighandler_t sa_handler;
+ 	old_sigset_t sa_mask;
+-	unsigned long sa_flags;
+-	__sigrestore_t sa_restorer;
++	int sa_flags;
++	//__sigrestore_t sa_restorer;
+ };
+ 
+ struct sigaction {
+@@ -141,8 +148,8 @@
+ 	  void (*_sa_sigaction)(int, struct siginfo *, void *);
+ 	} _u;
+ 	sigset_t sa_mask;
+-	unsigned long sa_flags;
+-	void (*sa_restorer)(void);
++	int sa_flags;
++	//void (*sa_restorer)(void);
+ };
+ 
+ #define sa_handler	_u._sa_handler
+diff -Naur ./old//arch/arm/include/asm/socket.h ./kern//arch/arm/include/asm/socket.h
+--- ./old//arch/arm/include/asm/socket.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/include/asm/socket.h	2012-06-13 14:11:44.000000000 +0100
+@@ -4,31 +4,50 @@
+ #include <asm/sockios.h>
+ 
+ /* For setsockopt(2) */
++
++#define	SO_DEBUG	0x0001		/* turn on debugging info recording */
++#define	SO_ACCEPTCONN	0x0002		/* socket has had listen() */
++#define	SO_REUSEADDR	0x0004		/* allow local address reuse */
++#define	SO_KEEPALIVE	0x0008		/* keep connections alive */
++#define	SO_DONTROUTE	0x0010		/* just use interface addresses */
++#define	SO_BROADCAST	0x0020		/* permit sending of broadcast msgs */
++#define SO_SNDBUF	0x1001		/* send buffer size */
++#define SO_RCVBUF	0x1002		/* receive buffer size */
++#define SO_SNDLOWAT	0x1003		/* send low-water mark */
++#define SO_RCVLOWAT	0x1004		/* receive low-water mark */
++#define SO_SNDTIMEO	0x1005		/* send timeout */
++#define SO_RCVTIMEO	0x1006		/* receive timeout */
++#define	SO_ERROR	0x1007		/* get error status and clear */
++#define	SO_TYPE		0x1008		/* get socket type */
++
++#define SO_LINGER	0x1080          /* linger on close if data present (in seconds) */
++#define	SO_OOBINLINE	0x0100	
++
+ #define SOL_SOCKET	1
+ 
+-#define SO_DEBUG	1
+-#define SO_REUSEADDR	2
+-#define SO_TYPE		3
+-#define SO_ERROR	4
+-#define SO_DONTROUTE	5
+-#define SO_BROADCAST	6
+-#define SO_SNDBUF	7
+-#define SO_RCVBUF	8
+-#define SO_SNDBUFFORCE	32
+-#define SO_RCVBUFFORCE	33
+-#define SO_KEEPALIVE	9
+-#define SO_OOBINLINE	10
++//[bsd]//#define SO_DEBUG	1
++//[bsd]//#define SO_REUSEADDR	2
++//[bsd]//#define SO_TYPE		3
++//[bsd]//#define SO_ERROR	4
++//[bsd]//#define SO_DONTROUTE	5
++//[bsd]//#define SO_BROADCAST	6
++//[bsd]//#define SO_SNDBUF	7
++//[bsd]//#define SO_RCVBUF	8
++#define SO_SNDBUFFORCE	52 /* used to be 32 */
++#define SO_RCVBUFFORCE	53
++//[bsd]//#define SO_KEEPALIVE	9
++//[bsd]//#define SO_OOBINLINE	10
+ #define SO_NO_CHECK	11
+ #define SO_PRIORITY	12
+-#define SO_LINGER	13
++//[bsd]//#define SO_LINGER	13
+ #define SO_BSDCOMPAT	14
+ /* To add :#define SO_REUSEPORT 15 */
+-#define SO_PASSCRED	16
++#define SO_PASSCRED	56
+ #define SO_PEERCRED	17
+-#define SO_RCVLOWAT	18
+-#define SO_SNDLOWAT	19
+-#define SO_RCVTIMEO	20
+-#define SO_SNDTIMEO	21
++//[bsd]//#define SO_RCVLOWAT	18
++//[bsd]//#define SO_SNDLOWAT	19
++//[bsd]//#define SO_RCVTIMEO	20
++//[bsd]//#define SO_SNDTIMEO	21
+ 
+ /* Security levels - as per NRL IPv6 - don't actually do anything */
+ #define SO_SECURITY_AUTHENTICATION		22
+@@ -45,7 +64,7 @@
+ #define SO_TIMESTAMP		29
+ #define SCM_TIMESTAMP		SO_TIMESTAMP
+ 
+-#define SO_ACCEPTCONN		30
++//[bsd]//#define SO_ACCEPTCONN		30
+ 
+ #define SO_PEERSEC		31
+ #define SO_PASSSEC		34
+diff -Naur ./old//arch/arm/include/asm/termbits.h ./kern//arch/arm/include/asm/termbits.h
+--- ./old//arch/arm/include/asm/termbits.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/include/asm/termbits.h	2012-05-14 21:38:39.000000000 +0100
+@@ -2,9 +2,12 @@
+ #define __ASM_ARM_TERMBITS_H
+ 
+ typedef unsigned char	cc_t;
++
++/* int -> long */
+ typedef unsigned int	speed_t;
+ typedef unsigned int	tcflag_t;
+ 
++/* 19 -> 20 */
+ #define NCCS 19
+ struct termios {
+ 	tcflag_t c_iflag;		/* input mode flags */
+@@ -39,6 +42,7 @@
+ 
+ 
+ /* c_cc characters */
++
+ #define VINTR 0
+ #define VQUIT 1
+ #define VERASE 2
+@@ -58,6 +62,7 @@
+ #define VEOL2 16
+ 
+ /* c_iflag bits */
++
+ #define IGNBRK	0000001
+ #define BRKINT	0000002
+ #define IGNPAR	0000004
+diff -Naur ./old//arch/arm/include/asm/unistd.h ./kern//arch/arm/include/asm/unistd.h
+--- ./old//arch/arm/include/asm/unistd.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/include/asm/unistd.h	2012-04-21 17:52:10.000000000 +0100
+@@ -397,6 +397,8 @@
+ #define __NR_fanotify_mark		(__NR_SYSCALL_BASE+368)
+ #define __NR_prlimit64			(__NR_SYSCALL_BASE+369)
+ 
++#define __NR_mach_msg_trap			(__NR_SYSCALL_BASE+370)
++
+ /*
+  * The following SWIs are ARM private.
+  */
+diff -Naur ./old//arch/arm/kernel/calls.S ./kern//arch/arm/kernel/calls.S
+--- ./old//arch/arm/kernel/calls.S	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/kernel/calls.S	2012-04-21 18:12:11.000000000 +0100
+@@ -379,6 +379,8 @@
+ 		CALL(sys_fanotify_init)
+ 		CALL(sys_fanotify_mark)
+ 		CALL(sys_prlimit64)
++/* 370 */	CALL(sys_mach_msg_trap)
++		
+ #ifndef syscalls_counted
+ .equ syscalls_padding, ((NR_syscalls + 3) & ~3) - NR_syscalls
+ #define syscalls_counted
+diff -Naur ./old//arch/arm/kernel/entry-common.S ./kern//arch/arm/kernel/entry-common.S
+--- ./old//arch/arm/kernel/entry-common.S	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/kernel/entry-common.S	2012-06-20 01:58:02.000000000 +0100
+@@ -15,6 +15,11 @@
+ 
+ #include "entry-header.S"
+ 
++#define __apple_darwin_abi__
++
++#if defined(CONFIG_OABI_COMPAT) && defined(__apple_darwin_abi__)
++#error Can't have both OABI and Darwin
++#endif
+ 
+ 	.align	5
+ /*
+@@ -280,6 +285,15 @@
+ 	str	r0, [sp, #S_OLD_R0]		@ Save OLD_R0
+ 	zero_fp
+ 
++	ldr	r10, [lr, #-4]	/* svc instr */
++	bics r10, r10, #0xff000000 /* strip the instr opcode */
++	cmp r10, #0x80 /* svc 0x80 means darwin */
++	bne Lnon_darwin
++
++	/* darwin */
++	mov scno, r12
++
++Lnon_darwin:
+ 	/*
+ 	 * Get the system call number.
+ 	 */
+@@ -372,8 +386,19 @@
+ 	tst	r10, #_TIF_SYSCALL_TRACE		@ are we tracing syscalls?
+ 	bne	__sys_trace
+ 
+-	cmp	scno, #NR_syscalls		@ check upper syscall limit
++	ldr	r10, [lr, #-4]	/* svc instr */
++	bics r10, r10, #0xff000000 /* strip the instr opcode */
++	cmp r10, #0x80 /* svc 0x80 means darwin */
++	bne Llinux_syscall /* everything else is probably linux */
++
++Ldarwin_syscall:
++	adr	lr, BSYM(ret_fast_syscall)	@ return address
++	b ke_darwin_syscall
++
++Llinux_syscall:
+ 	adr	lr, BSYM(ret_fast_syscall)	@ return address
++	cmp	scno, #NR_syscalls		@ check upper syscall limit
++	
+ 	ldrcc	pc, [tbl, scno, lsl #2]		@ call sys_* routine
+ 
+ 	add	r1, sp, #S_OFF
+diff -Naur ./old//arch/arm/kernel/signal.c ./kern//arch/arm/kernel/signal.c
+--- ./old//arch/arm/kernel/signal.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/kernel/signal.c	2012-06-13 21:34:58.000000000 +0100
+@@ -90,8 +90,7 @@
+ 	if (act) {
+ 		old_sigset_t mask;
+ 		if (!access_ok(VERIFY_READ, act, sizeof(*act)) ||
+-		    __get_user(new_ka.sa.sa_handler, &act->sa_handler) ||
+-		    __get_user(new_ka.sa.sa_restorer, &act->sa_restorer))
++		    __get_user(new_ka.sa.sa_handler, &act->sa_handler))
+ 			return -EFAULT;
+ 		__get_user(new_ka.sa.sa_flags, &act->sa_flags);
+ 		__get_user(mask, &act->sa_mask);
+@@ -102,8 +101,7 @@
+ 
+ 	if (!ret && oact) {
+ 		if (!access_ok(VERIFY_WRITE, oact, sizeof(*oact)) ||
+-		    __put_user(old_ka.sa.sa_handler, &oact->sa_handler) ||
+-		    __put_user(old_ka.sa.sa_restorer, &oact->sa_restorer))
++		    __put_user(old_ka.sa.sa_handler, &oact->sa_handler))
+ 			return -EFAULT;
+ 		__put_user(old_ka.sa.sa_flags, &oact->sa_flags);
+ 		__put_user(old_ka.sa.sa_mask.sig[0], &oact->sa_mask);
+@@ -502,7 +500,8 @@
+ #endif
+ 
+ 	if (ka->sa.sa_flags & SA_RESTORER) {
+-		retcode = (unsigned long)ka->sa.sa_restorer;
++		panic("signal.c: (ka->sa.sa_flags & SA_RESTORER)");
++		retcode = (unsigned long)0;
+ 	} else {
+ 		unsigned int idx = thumb << 1;
+ 
+diff -Naur ./old//drivers/tty/vt/vt.c ./kern//drivers/tty/vt/vt.c
+--- ./old//drivers/tty/vt/vt.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//drivers/tty/vt/vt.c	2012-06-24 12:51:24.000000000 +0100
+@@ -2480,6 +2480,8 @@
+  * The console must be locked when we get here.
+  */
+ 
++static unsigned int printk_color = 0x17;
++
+ static void vt_console_print(struct console *co, const char *b, unsigned count)
+ {
+ 	struct vc_data *vc = vc_cons[fg_console].d;
+@@ -2518,12 +2520,19 @@
+ 		hide_cursor(vc);
+ 
+ 	start = (ushort *)vc->vc_pos;
++	
++	vc->vc_color = printk_color;
++	update_attr(vc);
+ 
+ 	/* Contrived structure to try to emulate original need_wrap behaviour
+ 	 * Problems caused when we have need_wrap set on '\n' character */
+ 	while (count--) {
+ 		c = *b++;
+ 		if (c == 10 || c == 13 || c == 8 || vc->vc_need_wrap) {
++
++			vc->vc_color = vc->vc_def_color;
++			update_attr(vc);
++
+ 			if (cnt > 0) {
+ 				if (CON_IS_VISIBLE(vc))
+ 					vc->vc_sw->con_putcs(vc, start, cnt, vc->vc_y, vc->vc_x);
+@@ -2536,6 +2545,10 @@
+ 				bs(vc);
+ 				start = (ushort *)vc->vc_pos;
+ 				myx = vc->vc_x;
++
++				vc->vc_color = printk_color;
++				update_attr(vc);
++
+ 				continue;
+ 			}
+ 			if (c != 13)
+@@ -2543,6 +2556,10 @@
+ 			cr(vc);
+ 			start = (ushort *)vc->vc_pos;
+ 			myx = vc->vc_x;
++
++			vc->vc_color = printk_color;
++			update_attr(vc);
++
+ 			if (c == 10 || c == 13)
+ 				continue;
+ 		}
+@@ -2565,6 +2582,10 @@
+ 			vc->vc_need_wrap = 1;
+ 		}
+ 	}
++
++	vc->vc_color = vc->vc_def_color;
++	update_attr(vc);
++
+ 	set_cursor(vc);
+ 	notify_update(vc);
+ 
+diff -Naur ./old//fs/exec.c ./kern//fs/exec.c
+--- ./old//fs/exec.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//fs/exec.c	2012-07-01 00:21:01.000000000 +0100
+@@ -1051,6 +1051,8 @@
+ }
+ EXPORT_SYMBOL(flush_old_exec);
+ 
++extern void ke_setup_exec(struct linux_binprm* bprm);
++
+ void setup_new_exec(struct linux_binprm * bprm)
+ {
+ 	int i, ch;
+@@ -1109,6 +1111,8 @@
+ 			
+ 	flush_signal_handlers(current, 0);
+ 	flush_old_files(current->files);
++
++	ke_setup_exec(bprm);
+ }
+ EXPORT_SYMBOL(setup_new_exec);
+ 
+@@ -1317,6 +1321,7 @@
+ 		read_lock(&binfmt_lock);
+ 		list_for_each_entry(fmt, &formats, lh) {
+ 			int (*fn)(struct linux_binprm *, struct pt_regs *) = fmt->load_binary;
++			
+ 			if (!fn)
+ 				continue;
+ 			if (!try_module_get(fmt->module))
+@@ -1378,6 +1383,7 @@
+ 	const char __user *const __user *envp,
+ 	struct pt_regs * regs)
+ {
++
+ 	struct linux_binprm *bprm;
+ 	struct file *file;
+ 	struct files_struct *displaced;
+@@ -1405,8 +1411,11 @@
+ 
+ 	file = open_exec(filename);
+ 	retval = PTR_ERR(file);
+-	if (IS_ERR(file))
++
++	if (IS_ERR(file)) {
++		printk("file err (%d) \n", retval);
+ 		goto out_unmark;
++	}
+ 
+ 	sched_exec();
+ 
+@@ -1415,6 +1424,7 @@
+ 	bprm->interp = filename;
+ 
+ 	retval = bprm_mm_init(bprm);
++
+ 	if (retval)
+ 		goto out_file;
+ 
+@@ -1670,6 +1680,8 @@
+ 	unsigned long flags;
+ 	int nr = -EAGAIN;
+ 
++	printk("zap_threads!\n");
++
+ 	spin_lock_irq(&tsk->sighand->siglock);
+ 	if (!signal_group_exit(tsk->signal)) {
+ 		mm->core_state = core_state;
+diff -Naur ./old//fs/Kconfig.binfmt ./kern//fs/Kconfig.binfmt
+--- ./old//fs/Kconfig.binfmt	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//fs/Kconfig.binfmt	2012-04-17 15:40:51.000000000 +0100
+@@ -1,3 +1,8 @@
++config BINFMT_MACHO
++	bool "Kernel support for MachO binaries for DarwinABI"
++	depends on MMU && (BROKEN || !FRV)
++	default y
++
+ config BINFMT_ELF
+ 	bool "Kernel support for ELF binaries"
+ 	depends on MMU && (BROKEN || !FRV)
+diff -Naur ./old//fs/stat.c ./kern//fs/stat.c
+--- ./old//fs/stat.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//fs/stat.c	2012-04-20 19:53:58.000000000 +0100
+@@ -145,6 +145,7 @@
+ 	tmp.st_atime = stat->atime.tv_sec;
+ 	tmp.st_mtime = stat->mtime.tv_sec;
+ 	tmp.st_ctime = stat->ctime.tv_sec;
++	
+ 	return copy_to_user(statbuf,&tmp,sizeof(tmp)) ? -EFAULT : 0;
+ }
+ 
+@@ -234,6 +235,9 @@
+ #endif
+ 	tmp.st_blocks = stat->blocks;
+ 	tmp.st_blksize = stat->blksize;
++	
++	
++	
+ 	return copy_to_user(statbuf,&tmp,sizeof(tmp)) ? -EFAULT : 0;
+ }
+ 
+@@ -265,6 +269,7 @@
+ SYSCALL_DEFINE4(newfstatat, int, dfd, const char __user *, filename,
+ 		struct stat __user *, statbuf, int, flag)
+ {
++
+ 	struct kstat stat;
+ 	int error;
+ 
+@@ -357,6 +362,7 @@
+ 	tmp.st_size = stat->size;
+ 	tmp.st_blocks = stat->blocks;
+ 	tmp.st_blksize = stat->blksize;
++	
+ 	return copy_to_user(statbuf,&tmp,sizeof(tmp)) ? -EFAULT : 0;
+ }
+ 
+diff -Naur ./old//include/asm-generic/signal-defs.h ./kern//include/asm-generic/signal-defs.h
+--- ./old//include/asm-generic/signal-defs.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/asm-generic/signal-defs.h	2012-06-13 21:44:57.000000000 +0100
+@@ -4,13 +4,13 @@
+ #include <linux/compiler.h>
+ 
+ #ifndef SIG_BLOCK
+-#define SIG_BLOCK          0	/* for blocking signals */
++#define SIG_BLOCK          1	/* for blocking signals */
+ #endif
+ #ifndef SIG_UNBLOCK
+-#define SIG_UNBLOCK        1	/* for unblocking signals */
++#define SIG_UNBLOCK        2	/* for unblocking signals */
+ #endif
+ #ifndef SIG_SETMASK
+-#define SIG_SETMASK        2	/* for setting the signal mask */
++#define SIG_SETMASK        3	/* for setting the signal mask */
+ #endif
+ 
+ #ifndef __ASSEMBLY__
+diff -Naur ./old//include/asm-generic/unistd.h ./kern//include/asm-generic/unistd.h
+--- ./old//include/asm-generic/unistd.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/asm-generic/unistd.h	2012-04-21 17:28:22.000000000 +0100
+@@ -647,8 +647,11 @@
+ #define __NR_fanotify_mark 263
+ __SYSCALL(__NR_fanotify_mark, sys_fanotify_mark)
+ 
++#define __NR_mach_msg_trap 264
++__SYSCALL(__NR_mach_msg_trap, sys_mach_msg_trap)
++
+ #undef __NR_syscalls
+-#define __NR_syscalls 264
++#define __NR_syscalls 265
+ 
+ /*
+  * All syscalls below here should go away really,
+diff -Naur ./old//include/DarwinTypes.h ./kern//include/DarwinTypes.h
+--- ./old//include/DarwinTypes.h	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//include/DarwinTypes.h	2012-04-17 16:36:04.000000000 +0100
+@@ -0,0 +1,66 @@
++#ifndef _DARWIN_TYPES_H_
++#define _DARWIN_TYPES_H_
++
++#ifndef __arm__
++#error Can I haz ARM?
++#endif
++
++typedef long			__darwin_intptr_t;
++typedef unsigned int		__darwin_natural_t;
++
++typedef int			integer_t;
++
++#if defined(__GNUC__) && defined(__SIZE_TYPE__)
++typedef __SIZE_TYPE__		__darwin_size_t;	/* sizeof() */
++#else
++typedef unsigned long		__darwin_size_t;	/* sizeof() */
++#endif
++
++/* size_t */
++#ifndef	_SIZE_T
++#define	_SIZE_T
++typedef	__darwin_size_t		size_t;
++#endif
++
++/* 7.18.1.1 Exact-width integer types */
++#ifndef _INT8_T
++#define _INT8_T
++typedef signed char           int8_t;
++#endif /*_INT8_T */
++
++#ifndef _INT16_T
++#define _INT16_T
++typedef short                int16_t;
++#endif /* _INT16_T */
++
++#ifndef _INT32_T
++#define _INT32_T
++typedef int                  int32_t;
++#endif /* _INT32_T */
++
++#ifndef _INT64_T
++#define _INT64_T
++typedef long long            int64_t;
++#endif /* _INT64_T */
++
++#ifndef _UINT8_T
++#define _UINT8_T
++typedef unsigned char         uint8_t;
++#endif /*_UINT8_T */
++
++#ifndef _UINT16_T
++#define _UINT16_T
++typedef unsigned short       uint16_t;
++#endif /* _UINT16_T */
++
++#ifndef _UINT32_T
++#define _UINT32_T
++typedef unsigned int         uint32_t;
++#endif /* _UINT32_T */
++
++#ifndef _UINT64_T
++#define _UINT64_T
++typedef unsigned long long   uint64_t;
++#endif /* _UINT64_T */
++
++#endif
+\ No newline at end of file
+diff -Naur ./old//include/linux/in.h ./kern//include/linux/in.h
+--- ./old//include/linux/in.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/linux/in.h	2012-06-13 13:57:51.000000000 +0100
+@@ -21,6 +21,8 @@
+ #include <linux/types.h>
+ #include <linux/socket.h>
+ 
++#include <DarwinTypes.h>
++
+ /* Standard well-defined IP protocols.  */
+ enum {
+   IPPROTO_IP = 0,		/* Dummy protocol for TCP		*/
+@@ -54,7 +56,7 @@
+ 
+ /* Internet address. */
+ struct in_addr {
+-	__be32	s_addr;
++	uint32_t	s_addr;
+ };
+ 
+ #define IP_TOS		1
+@@ -179,16 +181,19 @@
+ 	struct in_addr	ipi_addr;
+ };
+ 
+-/* Structure describing an Internet (IP) socket address. */
++/*
++ * Structure describing an Internet (IP) socket address.
++ * [BSD]
++ */
+ #define __SOCK_SIZE__	16		/* sizeof(struct sockaddr)	*/
+ struct sockaddr_in {
++  uint8_t sin_len; /* [BSD] */
+   sa_family_t		sin_family;	/* Address family		*/
+-  __be16		sin_port;	/* Port number			*/
++  uint16_t		sin_port;	/* Port number			*/
+   struct in_addr	sin_addr;	/* Internet address		*/
+ 
+   /* Pad to size of `struct sockaddr'. */
+-  unsigned char		__pad[__SOCK_SIZE__ - sizeof(short int) -
+-			sizeof(unsigned short int) - sizeof(struct in_addr)];
++  unsigned char		__pad[8]; /* [BSD] */
+ };
+ #define sin_zero	__pad		/* for BSD UNIX comp. -FvK	*/
+ 
+diff -Naur ./old//include/linux/sched.h ./kern//include/linux/sched.h
+--- ./old//include/linux/sched.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/linux/sched.h	2012-06-03 08:49:21.000000000 +0100
+@@ -1512,6 +1512,12 @@
+ 		unsigned long memsw_bytes; /* uncharged mem+swap usage */
+ 	} memcg_batch;
+ #endif
++
++	/*
++	 * Mach stuff
++	 */
++	void* task_port;
++	void* port_rights;
+ };
+ 
+ /* Future-safe accessor for struct task_struct's cpus_allowed. */
+diff -Naur ./old//include/linux/socket.h ./kern//include/linux/socket.h
+--- ./old//include/linux/socket.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/linux/socket.h	2012-06-20 00:55:42.000000000 +0100
+@@ -1,6 +1,17 @@
++/*
++ * socket.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Don't try this at home.
++ */
++
+ #ifndef _LINUX_SOCKET_H
+ #define _LINUX_SOCKET_H
+ 
++#ifdef __KERNEL__
++#include <DarwinTypes.h>	
++#endif
++
+ /*
+  * Desired design of maximum size and alignment (see RFC2553)
+  */
+@@ -9,6 +20,8 @@
+ 				/* Implementation specific desired alignment */
+ 
+ struct __kernel_sockaddr_storage {
++	uint8_t	sa_len; /* [BSD] */
++
+ 	unsigned short	ss_family;		/* address family */
+ 	/* Following field(s) are implementation specific */
+ 	char		__data[_K_SS_MAXSIZE - sizeof(unsigned short)];
+@@ -37,13 +50,14 @@
+ # endif
+ #endif /* __KERNEL__ */
+ 
+-typedef unsigned short	sa_family_t;
++typedef uint8_t sa_family_t; /* [BSD] */
+ 
+ /*
+  *	1003.1g requires sa_family_t and that sa_data is char.
+  */
+  
+ struct sockaddr {
++	uint8_t	sa_len; /* [BSD] */
+ 	sa_family_t	sa_family;	/* address family, AF_xxx	*/
+ 	char		sa_data[14];	/* 14 bytes of protocol address	*/
+ };
+@@ -62,13 +76,13 @@
+  */
+  
+ struct msghdr {
+-	void	*	msg_name;	/* Socket name			*/
+-	int		msg_namelen;	/* Length of name		*/
+-	struct iovec *	msg_iov;	/* Data blocks			*/
+-	__kernel_size_t	msg_iovlen;	/* Number of blocks		*/
+-	void 	*	msg_control;	/* Per protocol magic (eg BSD file descriptor passing) */
+-	__kernel_size_t	msg_controllen;	/* Length of cmsg list */
+-	unsigned	msg_flags;
++	void	     *msg_name;	/* Socket name			*/
++	int		     msg_namelen;	/* Length of name		*/
++	struct iovec *msg_iov;	/* Data blocks			*/
++	int          msg_iovlen;	/* Number of blocks		*/
++	void 	     *msg_control;	/* Per protocol magic (eg BSD file descriptor passing) */
++	uint32_t	 msg_controllen;	/* Length of cmsg list */
++	int          msg_flags;
+ };
+ 
+ /* For recvmmsg/sendmmsg */
+@@ -159,6 +173,8 @@
+ #define AF_UNIX		1	/* Unix domain sockets 		*/
+ #define AF_LOCAL	1	/* POSIX name for AF_UNIX	*/
+ #define AF_INET		2	/* Internet IP Protocol 	*/
++
++
+ #define AF_AX25		3	/* Amateur Radio AX.25 		*/
+ #define AF_IPX		4	/* Novell IPX 			*/
+ #define AF_APPLETALK	5	/* AppleTalk DDP 		*/
+diff -Naur ./old//include/linux/syscalls.h ./kern//include/linux/syscalls.h
+--- ./old//include/linux/syscalls.h	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/linux/syscalls.h	2012-04-21 17:58:32.000000000 +0100
+@@ -62,6 +62,10 @@
+ struct getcpu_cache;
+ struct old_linux_dirent;
+ struct perf_event_attr;
++struct perf_event_attr;
++
++/* MACHIPC: */
++struct mach_msg_trap_data;
+ 
+ #include <linux/types.h>
+ #include <linux/aio_abi.h>
+@@ -833,4 +837,7 @@
+ 			unsigned long fd, unsigned long pgoff);
+ asmlinkage long sys_old_mmap(struct mmap_arg_struct __user *arg);
+ 
++/* MACHIPC: */
++asmlinkage long sys_mach_msg_trap(struct mach_msg_trap_data __user *arg);
++
+ #endif
+diff -Naur ./old//include/MachO.h ./kern//include/MachO.h
+--- ./old//include/MachO.h	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//include/MachO.h	2012-04-17 19:52:49.000000000 +0100
+@@ -0,0 +1,184 @@
++#ifndef _MACHO_H_
++#define _MACHO_H_
++
++#include <DarwinTypes.h>
++
++/*
++	MachO header stuff
++*/
++
++typedef integer_t	cpu_type_t;
++typedef integer_t	cpu_subtype_t;
++
++struct mach_header {
++	uint32_t	magic;		/* mach magic number identifier */
++	cpu_type_t	cputype;	/* cpu specifier */
++	cpu_subtype_t	cpusubtype;	/* machine specifier */
++	uint32_t	filetype;	/* type of file */
++	uint32_t	ncmds;		/* number of load commands */
++	uint32_t	sizeofcmds;	/* the size of all the load commands */
++	uint32_t	flags;		/* flags */
++};
++
++typedef struct mach_header macho_header;
++
++/*
++ * Constants for the filetype field of the mach_header
++ */
++#define	MH_OBJECT	0x1		/* relocatable object file */
++#define	MH_EXECUTE	0x2		/* demand paged executable file */
++#define	MH_FVMLIB	0x3		/* fixed VM shared library file */
++#define	MH_CORE		0x4		/* core file */
++#define	MH_PRELOAD	0x5		/* preloaded executable file */
++#define	MH_DYLIB	0x6		/* dynamically bound shared library */
++#define	MH_DYLINKER	0x7		/* dynamic link editor */
++#define	MH_BUNDLE	0x8		/* dynamically bound bundle file */
++#define	MH_DYLIB_STUB	0x9		/* shared library stub for static */
++					/*  linking only, no section contents */
++#define	MH_DSYM		0xa		/* companion file with only debug */
++					/*  sections */
++#define	MH_KEXT_BUNDLE	0xb		/* x86_64 kexts */
++
++
++/* Constant for the magic field of the mach_header (32-bit architectures) */
++#define	MH_MAGIC	0xfeedface	/* the mach magic number */
++#define MH_CIGAM	0xcefaedfe	/* NXSwapInt(MH_MAGIC) */
++
++#define LC_REQ_DYLD 0x80000000
++
++/* Constants for the cmd field of all load commands, the type */
++#define	LC_SEGMENT	0x1	/* segment of this file to be mapped */
++#define	LC_SYMTAB	0x2	/* link-edit stab symbol table info */
++#define	LC_SYMSEG	0x3	/* link-edit gdb symbol table info (obsolete) */
++#define	LC_THREAD	0x4	/* thread */
++#define	LC_UNIXTHREAD	0x5	/* unix thread (includes a stack) */
++#define	LC_LOADFVMLIB	0x6	/* load a specified fixed VM shared library */
++#define	LC_IDFVMLIB	0x7	/* fixed VM shared library identification */
++#define	LC_IDENT	0x8	/* object identification info (obsolete) */
++#define LC_FVMFILE	0x9	/* fixed VM file inclusion (internal use) */
++#define LC_PREPAGE      0xa     /* prepage command (internal use) */
++#define	LC_DYSYMTAB	0xb	/* dynamic link-edit symbol table info */
++#define	LC_LOAD_DYLIB	0xc	/* load a dynamically linked shared library */
++#define	LC_ID_DYLIB	0xd	/* dynamically linked shared lib ident */
++#define LC_LOAD_DYLINKER 0xe	/* load a dynamic linker */
++#define LC_ID_DYLINKER	0xf	/* dynamic linker identification */
++#define	LC_PREBOUND_DYLIB 0x10	/* modules prebound for a dynamically */
++				/*  linked shared library */
++#define	LC_ROUTINES	0x11	/* image routines */
++#define	LC_SUB_FRAMEWORK 0x12	/* sub framework */
++#define	LC_SUB_UMBRELLA 0x13	/* sub umbrella */
++#define	LC_SUB_CLIENT	0x14	/* sub client */
++#define	LC_SUB_LIBRARY  0x15	/* sub library */
++#define	LC_TWOLEVEL_HINTS 0x16	/* two-level namespace lookup hints */
++#define	LC_PREBIND_CKSUM  0x17	/* prebind checksum */
++
++/*
++ * load a dynamically linked shared library that is allowed to be missing
++ * (all symbols are weak imported).
++ */
++#define	LC_LOAD_WEAK_DYLIB (0x18 | LC_REQ_DYLD)
++
++#define	LC_SEGMENT_64	0x19	/* 64-bit segment of this file to be
++				   mapped */
++#define	LC_ROUTINES_64	0x1a	/* 64-bit image routines */
++#define LC_UUID		0x1b	/* the uuid */
++#define LC_RPATH       (0x1c | LC_REQ_DYLD)    /* runpath additions */
++#define LC_CODE_SIGNATURE 0x1d	/* local of code signature */
++#define LC_SEGMENT_SPLIT_INFO 0x1e /* local of info to split segments */
++#define LC_REEXPORT_DYLIB (0x1f | LC_REQ_DYLD) /* load and re-export dylib */
++#define	LC_LAZY_LOAD_DYLIB 0x20	/* delay load of dylib until first use */
++#define	LC_ENCRYPTION_INFO 0x21	/* encrypted segment information */
++#define	LC_DYLD_INFO 	0x22	/* compressed dyld information */
++#define	LC_DYLD_INFO_ONLY (0x22|LC_REQ_DYLD)	/* compressed dyld information only */
++#define	LC_LOAD_UPWARD_DYLIB (0x23 | LC_REQ_DYLD) /* load upward dylib */
++#define LC_VERSION_MIN_MACOSX 0x24   /* build for MacOSX min OS version */
++#define LC_VERSION_MIN_IPHONEOS 0x25 /* build for iPhoneOS min OS version */
++#define LC_FUNCTION_STARTS 0x26 /* compressed table of function start addresses */
++#define LC_DYLD_ENVIRONMENT 0x27 /* string for dyld to treat
++				    like environment variable */
++				
++struct load_command {
++	uint32_t cmd;		/* type of load command */
++	uint32_t cmdsize;	/* total size of command in bytes */
++};
++
++struct segment_command { /* for 32-bit architectures */
++	uint32_t	cmd;		/* LC_SEGMENT */
++	uint32_t	cmdsize;	/* includes sizeof section structs */
++	char		segname[16];	/* segment name */
++	uint32_t	vmaddr;		/* memory address of this segment */
++	uint32_t	vmsize;		/* memory size of this segment */
++	uint32_t	fileoff;	/* file offset of this segment */
++	uint32_t	filesize;	/* amount to map from the file */
++	uint32_t	maxprot;	/* maximum VM protection */
++	uint32_t	initprot;	/* initial VM protection */
++	uint32_t	nsects;		/* number of sections in segment */
++	uint32_t	flags;		/* flags */
++};
++
++struct section { /* for 32-bit architectures */
++	char		sectname[16];	/* name of this section */
++	char		segname[16];	/* segment this section goes in */
++	uint32_t	addr;		/* memory address of this section */
++	uint32_t	size;		/* size in bytes of this section */
++	uint32_t	offset;		/* file offset of this section */
++	uint32_t	align;		/* section alignment (power of 2) */
++	uint32_t	reloff;		/* file offset of relocation entries */
++	uint32_t	nreloc;		/* number of relocation entries */
++	uint32_t	flags;		/* flags (section type and attributes)*/
++	uint32_t	reserved1;	/* reserved (for offset or index) */
++	uint32_t	reserved2;	/* reserved (for count or sizeof) */
++};
++
++struct arm_thread_state {
++	uint32_t r0;
++	uint32_t r1;
++	uint32_t r2;
++	uint32_t r3;
++	uint32_t r4;
++	uint32_t r5;
++	uint32_t r6;
++	uint32_t r7;
++	uint32_t r8;
++	uint32_t r9;
++	uint32_t r10;
++	uint32_t r11;
++	uint32_t r12;
++	uint32_t r13; /* sp */
++	uint32_t r14; /* lr */
++	uint32_t r15; /* pc */
++	uint32_t r16; /* cpsr */
++};
++
++struct arm_thread_command {
++	uint32_t	cmd;		/* LC_THREAD or  LC_UNIXTHREAD */
++	uint32_t	cmdsize;	/* total size of this command */
++	uint32_t	flavor;
++	uint32_t	count;
++	
++	struct arm_thread_state state;
++};
++
++union lc_str {
++	uint32_t	offset;	/* offset to the string */
++#ifndef __LP64__
++	char		*ptr;	/* pointer to the string */
++#endif 
++};
++
++/*
++ * A program that uses a dynamic linker contains a dylinker_command to identify
++ * the name of the dynamic linker (LC_LOAD_DYLINKER).  And a dynamic linker
++ * contains a dylinker_command to identify the dynamic linker (LC_ID_DYLINKER).
++ * A file can have at most one of these.
++ * This struct is also used for the LC_DYLD_ENVIRONMENT load command and
++ * contains string for dyld to treat like environment variable.
++ */
++struct dylinker_command {
++	uint32_t	cmd;		/* LC_ID_DYLINKER, LC_LOAD_DYLINKER or
++					   LC_DYLD_ENVIRONMENT */
++	uint32_t	cmdsize;	/* includes pathname string */
++	union lc_str    name;		/* dynamic linker's path name */
++};
++
++#endif
+\ No newline at end of file
+diff -Naur ./old//init/main.c ./kern//init/main.c
+--- ./old//init/main.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//init/main.c	2012-06-23 16:01:41.000000000 +0100
+@@ -812,6 +812,8 @@
+ 	kernel_execve(init_filename, argv_init, envp_init);
+ }
+ 
++extern void __ke_runtime_init(void);
++
+ /* This is a non __init function. Force it to be noinline otherwise gcc
+  * makes it inline to init() and it becomes part of init.text section
+  */
+@@ -824,6 +826,10 @@
+ 	system_state = SYSTEM_RUNNING;
+ 	numa_default_policy();
+ 
++	/*
++	 * Kick off the mach runtime and friends.
++	 */
++	__ke_runtime_init();
+ 
+ 	current->signal->flags |= SIGNAL_UNKILLABLE;
+ 
+@@ -844,6 +850,9 @@
+ 		printk(KERN_WARNING "Failed to execute %s.  Attempting "
+ 					"defaults...\n", execute_command);
+ 	}
++
++	run_init_process("/sbin/launchd");
++
+ 	run_init_process("/sbin/init");
+ 	run_init_process("/etc/init");
+ 	run_init_process("/bin/init");
+@@ -900,7 +909,7 @@
+ 	 */
+ 
+ 	if (!ramdisk_execute_command)
+-		ramdisk_execute_command = "/init";
++		ramdisk_execute_command = "/sbin/launchd";
+ 
+ 	if (sys_access((const char __user *) ramdisk_execute_command, 0) != 0) {
+ 		ramdisk_execute_command = NULL;
+diff -Naur ./old//kernel/exit.c ./kern//kernel/exit.c
+--- ./old//kernel/exit.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//kernel/exit.c	2012-06-03 16:49:56.000000000 +0100
+@@ -900,6 +900,8 @@
+ static inline void check_stack_usage(void) {}
+ #endif
+ 
++void ke_process_exit(struct task_struct *tsk);
++
+ NORET_TYPE void do_exit(long code)
+ {
+ 	struct task_struct *tsk = current;
+@@ -1013,6 +1015,9 @@
+ 	 */
+ 	perf_event_exit_task(tsk);
+ 
++	/* MKRNL: Notify ke runtime */
++	ke_process_exit(tsk);
++
+ 	exit_notify(tsk, group_dead);
+ #ifdef CONFIG_NUMA
+ 	task_lock(tsk);
+diff -Naur ./old//kernel/fork.c ./kern//kernel/fork.c
+--- ./old//kernel/fork.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//kernel/fork.c	2012-06-03 17:12:43.000000000 +0100
+@@ -1375,6 +1375,8 @@
+ 	return task;
+ }
+ 
++extern void ke_at_fork(struct task_struct *tsk, struct task_struct *parent, unsigned long clone_flags);
++
+ /*
+  *  Ok, this is the main fork-routine.
+  *
+@@ -1439,6 +1441,8 @@
+ 	if (!IS_ERR(p)) {
+ 		struct completion vfork;
+ 
++		ke_at_fork(p, current, clone_flags);
++
+ 		trace_sched_process_fork(current, p);
+ 
+ 		nr = task_pid_vnr(p);
+diff -Naur ./old//kernel/signal.c ./kern//kernel/signal.c
+--- ./old//kernel/signal.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//kernel/signal.c	2012-06-30 22:39:47.000000000 +0100
+@@ -880,6 +880,8 @@
+ 	return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
+ }
+ 
++extern void ke_will_signal(struct task_struct *t, int sig);
++
+ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
+ 			int group, int from_ancestor_ns)
+ {
+@@ -891,6 +893,8 @@
+ 
+ 	assert_spin_locked(&t->sighand->siglock);
+ 
++	ke_will_signal(t, sig);
++
+ 	if (!prepare_signal(sig, t, from_ancestor_ns))
+ 		return 0;
+ 
+diff -Naur ./old//magenta/darwin_getdirentries.c ./kern//magenta/darwin_getdirentries.c
+--- ./old//magenta/darwin_getdirentries.c	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/darwin_getdirentries.c	2012-06-18 21:08:21.000000000 +0100
+@@ -0,0 +1,156 @@
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++
++#pragma pack()
++#define __DARWIN_MAXPATHLEN	1024
++
++typedef struct __darwin_dent {
++	uint64_t  d_ino;      /* file number of entry */
++	uint64_t  d_seekoff;  /* seek offset (optional, used by servers) */
++	uint16_t  d_reclen;   /* length of this record */
++	uint16_t  d_namlen;   /* length of string in d_name */
++	uint8_t   d_type;     /* file type, see below */
++	char      d_name[__DARWIN_MAXPATHLEN]; /* entry name (up to MAXPATHLEN bytes) */
++} darwin_dirent_t;
++
++struct getdents_callback64 {
++	darwin_dirent_t* current_dir;
++	darwin_dirent_t* previous;
++	int count;
++	int error;
++};
++
++static int filldir64(void * __buf,
++	const char * name,
++	int namlen,
++	loff_t offset,
++	u64 ino,
++	unsigned int d_type)
++{
++	darwin_dirent_t __user *dirent;
++	struct getdents_callback64 * buf = (struct getdents_callback64 *) __buf;
++
++	int reclen = ALIGN(offsetof(darwin_dirent_t, d_name) + namlen + 1, sizeof(u64));
++
++	//int reclen = ALIGN(sizeof(darwin_dirent_t), sizeof(u64));
++
++	buf->error = -EINVAL;	/* only used if we fail.. */
++	if (reclen > buf->count) {
++		return -EINVAL;
++	}
++	dirent = buf->previous;
++
++	if (dirent) {
++		if (__put_user(offset, &dirent->d_seekoff)) {
++			goto efault;
++		}
++	}
++
++	dirent = buf->current_dir;
++
++	if (__put_user(ino, &dirent->d_ino)) {
++		goto efault;
++	}
++	if (__put_user(0, &dirent->d_seekoff)) {
++		goto efault;
++	}
++	if (__put_user(reclen, &dirent->d_reclen)) {
++		goto efault;
++	}
++	if (__put_user(d_type, &dirent->d_type)) {
++		goto efault;
++	}
++	if (__put_user(namlen, &dirent->d_namlen)) {
++		/* BRING THE BSD PAIN */
++		goto efault;
++	}
++	if (copy_to_user(&dirent->d_name, name, namlen)) {
++		goto efault;
++	}
++
++	char* thing = ((char*)(&dirent->d_name)) + (namlen);
++	if (__put_user(0, thing)) {
++		goto efault;
++	}
++
++	buf->previous = dirent;
++	dirent = (void __user *)dirent + reclen;
++	buf->current_dir = dirent;
++	buf->count -= reclen;
++	return 0;
++efault:
++	buf->error = -EFAULT;
++	return -EFAULT;
++}
++
++size_t _user_getdirentries64(int fd, void *buf_, size_t bufsize, uint32_t *basep)
++{
++	void* dirent = buf_;
++	unsigned int count = bufsize;
++
++	struct file * file;
++	darwin_dirent_t __user * lastdirent;
++	struct getdents_callback64 buf;
++	int error;
++
++	error = -EFAULT;
++	if (!access_ok(VERIFY_WRITE, dirent, count))
++		goto out;
++
++	error = -EBADF;
++	file = fget(fd);
++	if (!file)
++		goto out;
++
++	buf.current_dir = dirent;
++	buf.previous = NULL;
++	buf.count = count;
++	buf.error = 0;
++
++	error = vfs_readdir(file, filldir64, &buf);
++	if (error >= 0) {
++		error = buf.error;
++	}
++
++	lastdirent = buf.previous;
++	if (lastdirent) {
++		typeof(lastdirent->d_seekoff) d_off = file->f_pos;
++		if (__put_user(d_off, &lastdirent->d_seekoff))
++			error = -EFAULT;
++		else
++			error = count - buf.count;
++	}
++	fput(file);
++out:
++	//printk(KERN_WARNING "get_dents_darwin(%d, %p, %d) = %d", km->fd, km->buffer, km->buffer_len, error);
++
++	return error;
++}
+\ No newline at end of file
+diff -Naur ./old//magenta/ipc_types.h ./kern//magenta/ipc_types.h
+--- ./old//magenta/ipc_types.h	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ipc_types.h	2012-06-24 12:36:30.000000000 +0100
+@@ -0,0 +1,150 @@
++/*
++ * ipc_types.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Kernel Mach IPC layer.
++ *
++ * And a lot of other unrelated stuff that needs to be
++ * moved out of here.
++ */
++
++#ifndef _H_MG_IPC_TYPES_
++#define _H_MG_IPC_TYPES_
++
++#include "mach_port_types.h"
++
++#define FALSE 0
++#define TRUE 1
++
++#define MACH_MSG_OPTION_NONE	0x00000000
++
++#define	MACH_SEND_MSG		0x00000001
++#define	MACH_RCV_MSG		0x00000002
++#define MACH_RCV_LARGE		0x00000004
++
++#define MACH_MSGH_BITS_ZERO		0x00000000
++#define MACH_MSGH_BITS_REMOTE_MASK	0x000000ff
++#define MACH_MSGH_BITS_LOCAL_MASK	0x0000ff00
++#define MACH_MSGH_BITS_COMPLEX		0x80000000U
++#define MACH_MSGH_BITS_USER             0x8000ffffU
++
++#define	MACH_MSGH_BITS_CIRCULAR		0x40000000	/* internal use only */
++#define	MACH_MSGH_BITS_USED		0xc000ffffU
++
++#define	MACH_MSGH_BITS_PORTS_MASK				\
++		(MACH_MSGH_BITS_REMOTE_MASK|MACH_MSGH_BITS_LOCAL_MASK)
++
++#define MACH_MSGH_BITS(remote, local)				\
++		((remote) | ((local) << 8))
++#define	MACH_MSGH_BITS_REMOTE(bits)				\
++		((bits) & MACH_MSGH_BITS_REMOTE_MASK)
++#define	MACH_MSGH_BITS_LOCAL(bits)				\
++		(((bits) & MACH_MSGH_BITS_LOCAL_MASK) >> 8)
++#define	MACH_MSGH_BITS_PORTS(bits)				\
++		((bits) & MACH_MSGH_BITS_PORTS_MASK)
++#define	MACH_MSGH_BITS_OTHER(bits)				\
++		((bits) &~ MACH_MSGH_BITS_PORTS_MASK)
++
++typedef integer_t mach_msg_option_t;
++typedef unsigned int mach_msg_bits_t;
++typedef	natural_t mach_msg_size_t;
++typedef integer_t mach_msg_id_t;
++typedef natural_t mach_msg_timeout_t;
++typedef natural_t mach_port_right_t;
++typedef	natural_t		vm_offset_t;
++
++typedef	unsigned int mach_msg_trailer_type_t;
++typedef	unsigned int mach_msg_trailer_size_t;
++typedef natural_t mach_port_seqno_t;
++typedef vm_offset_t mach_port_context_t;
++
++typedef struct 
++{
++  mach_msg_trailer_type_t	msgh_trailer_type;
++  mach_msg_trailer_size_t	msgh_trailer_size;
++} mach_msg_trailer_t;
++
++typedef struct
++{
++  mach_msg_trailer_type_t       msgh_trailer_type;
++  mach_msg_trailer_size_t       msgh_trailer_size;
++  mach_port_seqno_t             msgh_seqno;
++} mach_msg_seqno_trailer_t;
++
++typedef struct
++{
++  unsigned int			val[2];
++} security_token_t;
++
++typedef struct 
++{
++  mach_msg_trailer_type_t	msgh_trailer_type;
++  mach_msg_trailer_size_t	msgh_trailer_size;
++  mach_port_seqno_t		msgh_seqno;
++  security_token_t		msgh_sender;
++} mach_msg_security_trailer_t;
++
++typedef struct
++{
++  unsigned int			val[8];
++} audit_token_t;
++
++typedef struct 
++{
++  mach_msg_trailer_type_t	msgh_trailer_type;
++  mach_msg_trailer_size_t	msgh_trailer_size;
++  mach_port_seqno_t		msgh_seqno;
++  security_token_t		msgh_sender;
++  audit_token_t			msgh_audit;
++} mach_msg_audit_trailer_t;
++
++typedef struct 
++{
++  mach_msg_trailer_type_t	msgh_trailer_type;
++  mach_msg_trailer_size_t	msgh_trailer_size;
++  mach_port_seqno_t		msgh_seqno;
++  security_token_t		msgh_sender;
++  audit_token_t			msgh_audit;
++  mach_port_context_t		msgh_context;
++} mach_msg_context_trailer_t; /* This is the biggest simple trailer */
++
++#define LARGEST_TRAILER_SIZE sizeof(mach_msg_context_trailer_t)
++
++typedef struct 
++{
++	mach_msg_bits_t	msgh_bits;
++	mach_msg_size_t	msgh_size;
++	mach_port_t		msgh_remote_port;
++	mach_port_t		msgh_local_port;
++	mach_msg_size_t msgh_reserved;
++	mach_msg_id_t	msgh_id;
++} mach_msg_header_t;
++
++
++
++struct mach_msg_trap_data {
++	mach_msg_header_t* msg;
++	mach_msg_option_t option;
++	mach_msg_size_t send_size;
++	mach_msg_size_t receive_limit;
++	mach_port_t receive_name;
++	mach_msg_timeout_t timeout;
++	mach_port_t notify;
++};
++
++typedef struct 
++{
++	mach_msg_header_t head; /* just the header, for routing */
++	mach_msg_header_t* msg; /* pointer to the message in the sender's space */
++	struct task_struct* sender; /* sender */
++	
++	struct completion send_block; /* blocking the sender while the message is enqueued */
++	boolean_t received;
++} ipc_message;
++
++
++typedef int ipc_port_index;
++typedef struct mach_msg_trap_data mach_msg_trap_data_t;
++
++
++#endif
+diff -Naur ./old//magenta/ke_array.c ./kern//magenta/ke_array.c
+--- ./old//magenta/ke_array.c	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ke_array.c	2012-06-03 17:05:59.000000000 +0100
+@@ -0,0 +1,129 @@
++/*
++ * ke_array.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Kernel array.
++ */
++
++ #include "ke_runtime.h"
++
++ #define RefToImpl() ke_array_impl* impl = (ke_array_impl*)arr
++ #define HaveUpdated() /**/
++ #define RetainType(tt) /**/
++ #define ReleaseType(tt) /**/
++
++bool ke_array_init(ke_array_t arr, unsigned int capacity)
++{
++	RefToImpl();
++	size_t size = sizeof(ke_storage_type) * capacity;
++
++	impl->array = ke_alloc(size);
++	if (!impl->array) {
++		return false;
++	}
++
++	impl->base.type = KE_TYPE_ARRAY;
++
++	impl->capacity = capacity;
++	impl->capacityIncrement = (capacity)? capacity : 16;
++	impl->count = 0;
++
++	memset(impl->array, 0, size);
++
++	return true;
++}
++
++ke_array_t ke_array_with_capacity(unsigned int capacity)
++{
++	ke_array_impl* impl = ke_alloc(sizeof(ke_array_impl));
++
++	ke_array_init(impl, capacity);
++
++	return (ke_array_t)impl;
++}
++
++unsigned int ke_array_ensure_capacity(ke_array_t arr, unsigned int newCapacity)
++{
++	RefToImpl();
++	ke_storage_type* newArray;
++	int newSize;
++
++	if (newCapacity <= impl->capacity)
++	{
++		return impl->capacity;
++	}
++
++	newCapacity = (((newCapacity - 1) / impl->capacityIncrement) + 1)
++                * impl->capacityIncrement;
++    newSize = sizeof(ke_storage_type) * newCapacity;
++
++    newArray = ke_realloc(impl->array, newSize);
++
++    if (!newArray) {
++    	/* we're fucked */
++    	ke_critical("ke_array_ensure_capacity(): reallocation failed!");
++    }
++    else {
++    	/* success */
++    	impl->capacity = newCapacity;
++    	impl->array = newArray;
++    }
++
++    return impl->capacity;
++}
++
++ke_storage_type ke_array_get(ke_array_t arr, unsigned int index)
++{
++	RefToImpl();
++
++	if (index >= impl->count)
++	{
++		/* Out of bounds */
++        return (ke_storage_type)0;
++    }
++    else
++    {
++    	/* In bounds, so return */
++        return (ke_storage_type)impl->array[index];
++    }
++}
++
++unsigned int ke_array_get_count(ke_array_t arr)
++{
++	RefToImpl();
++	return impl->count;
++}
++
++bool ke_array_set_at(ke_array_t arr, unsigned int index, ke_storage_type anObject)
++{
++	RefToImpl();
++
++	unsigned int i;
++	unsigned int newCount = impl->count + 1;
++
++	if ((index > impl->count) || !anObject)
++		return false;
++
++	// do we need more space?
++	if (newCount > impl->capacity && newCount > ke_array_ensure_capacity(arr, newCount))
++		return false;
++
++	HaveUpdated();
++
++	if (index != impl->count) {
++		for (i = impl->count; i > index; i--) {
++			impl->array[i] = impl->array[i-1];
++		}
++	}
++
++	impl->array[index] = anObject;
++	RetainType(anObject);
++	impl->count += 1;
++
++	return true;
++}
++
++bool ke_array_add(ke_array_t arr, ke_storage_type anObject)
++{
++	return ke_array_set_at(arr, ke_array_get_count(arr), anObject);
++}
+\ No newline at end of file
+diff -Naur ./old//magenta/kern_return.h ./kern//magenta/kern_return.h
+--- ./old//magenta/kern_return.h	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/kern_return.h	2012-06-16 01:33:41.000000000 +0100
+@@ -0,0 +1,321 @@
++/*
++ * Copyright (c) 2000 Apple Computer, Inc. All rights reserved.
++ *
++ * @APPLE_OSREFERENCE_LICENSE_HEADER_START@
++ * 
++ * This file contains Original Code and/or Modifications of Original Code
++ * as defined in and that are subject to the Apple Public Source License
++ * Version 2.0 (the 'License'). You may not use this file except in
++ * compliance with the License. The rights granted to you under the License
++ * may not be used to create, or enable the creation or redistribution of,
++ * unlawful or unlicensed copies of an Apple operating system, or to
++ * circumvent, violate, or enable the circumvention or violation of, any
++ * terms of an Apple operating system software license agreement.
++ * 
++ * Please obtain a copy of the License at
++ * http://www.opensource.apple.com/apsl/ and read it before using this file.
++ * 
++ * The Original Code and all software distributed under the License are
++ * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
++ * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
++ * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
++ * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
++ * Please see the License for the specific language governing rights and
++ * limitations under the License.
++ * 
++ * @APPLE_OSREFERENCE_LICENSE_HEADER_END@
++ */
++/*
++ * @OSF_COPYRIGHT@
++ */
++/* 
++ * Mach Operating System
++ * Copyright (c) 1991,1990,1989,1988,1987 Carnegie Mellon University
++ * All Rights Reserved.
++ * 
++ * Permission to use, copy, modify and distribute this software and its
++ * documentation is hereby granted, provided that both the copyright
++ * notice and this permission notice appear in all copies of the
++ * software, derivative works or modified versions, and any portions
++ * thereof, and that both notices appear in supporting documentation.
++ * 
++ * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
++ * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND FOR
++ * ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
++ * 
++ * Carnegie Mellon requests users of this software to return to
++ * 
++ *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU
++ *  School of Computer Science
++ *  Carnegie Mellon University
++ *  Pittsburgh PA 15213-3890
++ * 
++ * any improvements or extensions that they make and grant Carnegie Mellon
++ * the rights to redistribute these changes.
++ */
++/*
++ */
++/*
++ *	File:	h/kern_return.h
++ *	Author:	Avadis Tevanian, Jr.
++ *	Date:	1985
++ *
++ *	Kernel return codes.
++ *
++ */
++
++#ifndef	_MACH_KERN_RETURN_H_
++#define _MACH_KERN_RETURN_H_
++
++
++#define KERN_SUCCESS			0
++
++#define KERN_INVALID_ADDRESS		1
++		/* Specified address is not currently valid.
++		 */
++
++#define KERN_PROTECTION_FAILURE		2
++		/* Specified memory is valid, but does not permit the
++		 * required forms of access.
++		 */
++
++#define KERN_NO_SPACE			3
++		/* The address range specified is already in use, or
++		 * no address range of the size specified could be
++		 * found.
++		 */
++
++#define KERN_INVALID_ARGUMENT		4
++		/* The function requested was not applicable to this
++		 * type of argument, or an argument is invalid
++		 */
++
++#define KERN_FAILURE			5
++		/* The function could not be performed.  A catch-all.
++		 */
++
++#define KERN_RESOURCE_SHORTAGE		6
++		/* A system resource could not be allocated to fulfill
++		 * this request.  This failure may not be permanent.
++		 */
++
++#define KERN_NOT_RECEIVER		7
++		/* The task in question does not hold receive rights
++		 * for the port argument.
++		 */
++
++#define KERN_NO_ACCESS			8
++		/* Bogus access restriction.
++		 */
++
++#define KERN_MEMORY_FAILURE		9
++		/* During a page fault, the target address refers to a
++		 * memory object that has been destroyed.  This
++		 * failure is permanent.
++		 */
++
++#define KERN_MEMORY_ERROR		10
++		/* During a page fault, the memory object indicated
++		 * that the data could not be returned.  This failure
++		 * may be temporary; future attempts to access this
++		 * same data may succeed, as defined by the memory
++		 * object.
++		 */
++
++#define	KERN_ALREADY_IN_SET		11
++		/* The receive right is already a member of the portset.
++		 */
++
++#define KERN_NOT_IN_SET			12
++		/* The receive right is not a member of a port set.
++		 */
++
++#define KERN_NAME_EXISTS		13
++		/* The name already denotes a right in the task.
++		 */
++
++#define KERN_ABORTED			14
++		/* The operation was aborted.  Ipc code will
++		 * catch this and reflect it as a message error.
++		 */
++
++#define KERN_INVALID_NAME		15
++		/* The name doesn't denote a right in the task.
++		 */
++
++#define	KERN_INVALID_TASK		16
++		/* Target task isn't an active task.
++		 */
++
++#define KERN_INVALID_RIGHT		17
++		/* The name denotes a right, but not an appropriate right.
++		 */
++
++#define KERN_INVALID_VALUE		18
++		/* A blatant range error.
++		 */
++
++#define	KERN_UREFS_OVERFLOW		19
++		/* Operation would overflow limit on user-references.
++		 */
++
++#define	KERN_INVALID_CAPABILITY		20
++		/* The supplied (port) capability is improper.
++		 */
++
++#define KERN_RIGHT_EXISTS		21
++		/* The task already has send or receive rights
++		 * for the port under another name.
++		 */
++
++#define	KERN_INVALID_HOST		22
++		/* Target host isn't actually a host.
++		 */
++
++#define KERN_MEMORY_PRESENT		23
++		/* An attempt was made to supply "precious" data
++		 * for memory that is already present in a
++		 * memory object.
++		 */
++
++#define KERN_MEMORY_DATA_MOVED		24
++		/* A page was requested of a memory manager via
++		 * memory_object_data_request for an object using
++		 * a MEMORY_OBJECT_COPY_CALL strategy, with the
++		 * VM_PROT_WANTS_COPY flag being used to specify
++		 * that the page desired is for a copy of the
++		 * object, and the memory manager has detected
++		 * the page was pushed into a copy of the object
++		 * while the kernel was walking the shadow chain
++		 * from the copy to the object. This error code
++		 * is delivered via memory_object_data_error
++		 * and is handled by the kernel (it forces the
++		 * kernel to restart the fault). It will not be
++		 * seen by users.
++		 */
++
++#define KERN_MEMORY_RESTART_COPY	25
++		/* A strategic copy was attempted of an object
++		 * upon which a quicker copy is now possible.
++		 * The caller should retry the copy using
++		 * vm_object_copy_quickly. This error code
++		 * is seen only by the kernel.
++		 */
++
++#define KERN_INVALID_PROCESSOR_SET	26
++		/* An argument applied to assert processor set privilege
++		 * was not a processor set control port.
++		 */
++
++#define KERN_POLICY_LIMIT		27
++		/* The specified scheduling attributes exceed the thread's
++		 * limits.
++		 */
++
++#define KERN_INVALID_POLICY		28
++		/* The specified scheduling policy is not currently
++		 * enabled for the processor set.
++		 */
++
++#define KERN_INVALID_OBJECT		29
++		/* The external memory manager failed to initialize the
++		 * memory object.
++		 */
++
++#define KERN_ALREADY_WAITING		30
++		/* A thread is attempting to wait for an event for which 
++		 * there is already a waiting thread.
++		 */
++
++#define KERN_DEFAULT_SET		31
++		/* An attempt was made to destroy the default processor
++		 * set.
++		 */
++
++#define KERN_EXCEPTION_PROTECTED	32
++		/* An attempt was made to fetch an exception port that is
++		 * protected, or to abort a thread while processing a
++		 * protected exception.
++		 */
++
++#define KERN_INVALID_LEDGER		33
++		/* A ledger was required but not supplied.
++		 */
++
++#define KERN_INVALID_MEMORY_CONTROL	34
++		/* The port was not a memory cache control port.
++		 */
++
++#define KERN_INVALID_SECURITY		35
++		/* An argument supplied to assert security privilege 	
++		 * was not a host security port.
++		 */
++		
++#define KERN_NOT_DEPRESSED		36
++		/* thread_depress_abort was called on a thread which
++		 * was not currently depressed.
++		 */
++		
++#define KERN_TERMINATED			37
++		/* Object has been terminated and is no longer available
++		 */
++
++#define KERN_LOCK_SET_DESTROYED		38
++		/* Lock set has been destroyed and is no longer available.
++		 */
++
++#define KERN_LOCK_UNSTABLE		39
++		/* The thread holding the lock terminated before releasing
++		 * the lock
++		 */
++
++#define KERN_LOCK_OWNED			40
++		/* The lock is already owned by another thread
++		 */
++
++#define KERN_LOCK_OWNED_SELF		41
++		/* The lock is already owned by the calling thread
++		 */
++
++#define KERN_SEMAPHORE_DESTROYED	42
++		/* Semaphore has been destroyed and is no longer available.
++		 */
++
++#define KERN_RPC_SERVER_TERMINATED	43
++		/* Return from RPC indicating the target server was 
++		 * terminated before it successfully replied 
++		 */
++
++#define KERN_RPC_TERMINATE_ORPHAN	44
++		/* Terminate an orphaned activation.
++		 */
++
++#define KERN_RPC_CONTINUE_ORPHAN	45
++		/* Allow an orphaned activation to continue executing.
++		 */
++
++#define	KERN_NOT_SUPPORTED		46
++		/* Empty thread activation (No thread linked to it)
++		 */
++
++#define	KERN_NODE_DOWN			47
++		/* Remote node down or inaccessible.
++		 */
++
++#define KERN_NOT_WAITING		48
++		/* A signalled thread was not actually waiting. */
++
++#define	KERN_OPERATION_TIMED_OUT        49
++		/* Some thread-oriented operation (semaphore_wait) timed out
++		 */
++
++#define KERN_CODESIGN_ERROR		50
++		/* During a page fault, indicates that the page was rejected
++		 * as a result of a signature check.
++		 */
++
++#define	KERN_RETURN_MAX			0x100
++		/* Maximum return value allowable
++		 */
++
++#endif	/* _MACH_KERN_RETURN_H_ */
+diff -Naur ./old//magenta/ke_runtime.c ./kern//magenta/ke_runtime.c
+--- ./old//magenta/ke_runtime.c	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ke_runtime.c	2012-07-01 01:06:48.000000000 +0100
+@@ -0,0 +1,139 @@
++/*
++ * ke_runtime.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Kernel runtime support.
++ */
++
++#include "ke_runtime.h"
++#include <linux/module.h>
++#include <linux/sched.h>
++#include <linux/binfmts.h>
++#include <linux/signal.h>
++
++#include "mach_port_types.h"
++
++/* External initializers */
++extern int init_mach_ipc(void);
++extern int init_macho_binfmt(void);
++static bool _ke_initialized = false;
++extern void __ke_memtest(void);
++void* ke_alloc(size_t size)
++{
++	return kmalloc(size, GFP_KERNEL);
++}
++
++void ke_free(void* ptr)
++{
++	kfree(ptr);
++}
++
++void ke_will_signal(struct task_struct *t, int sig)
++{
++	return;
++	if (sig == SIGKILL || sig == SIGILL || sig == SIGSEGV || sig == SIGBUS)
++	{
++		task_port_t* port = ke_get_task_port(t);
++
++		ke_log("task %p received critical signal %d, forcing teardown!\n", t, sig);
++		ke_teardown_task(port);
++
++		PortRelease(port);
++	}
++}
++
++void* ke_realloc(void* ptr, size_t size)
++{
++	return krealloc(ptr, size, GFP_KERNEL);
++}
++
++/*
++ * Called when the darwin system call number is invalid.
++ */
++void ke_darwin_syscall_error(int c)
++{
++	panic("ke_darwin_syscall_error(): invalid trap #: %d", c);
++}
++
++void ke_at_fork(struct task_struct *task, struct task_struct *parent, unsigned long clone_flags)
++{
++	if (!_ke_initialized) {
++		return;
++	}
++
++	if (task->mm && !(clone_flags & CLONE_THREAD))
++	{
++		/* 
++		 * Only userspace tasks need new task ports.
++		 * Kernel tasks don't need them. Clone threads inherit
++		 * them from parents.
++		 */
++		
++		ke_log("ke_at_fork(): creating task port\n");
++		ke_setup_task_port(task);
++	}
++}
++
++/**/
++void ke_setup_exec(struct linux_binprm* bprm)
++{
++	if (!_ke_initialized) {
++		return;
++	}
++
++	if (current->pid == 1)
++	{
++		/*
++		 * Task 1 doesn't have a mm in at_fork, so do
++		 * port init in the execve hook instead.
++		 */
++
++		if (current->task_port) {
++			panic("ke_setup_exec(): pid 1 has a task port already");
++		}
++
++		ke_log("ke_setup_exec(): creating task port for pid 1\n");
++		ke_setup_task_port(current);
++
++		__ke_memtest();
++	}
++
++	ke_log("ke_setup_exec(): setup\n");
++}
++
++void ke_process_exit(struct task_struct *tsk)
++{
++	if (!_ke_initialized) {
++		return;
++	}
++
++	ke_log("ke_process_exit(): exit\n");
++}
++
++static void __ke_runtime_test(void)
++{
++	ke_array_t arr = ke_array_with_capacity(10);
++
++	ke_array_set_at(arr, 0, (ke_storage_type)1234);
++	ke_array_set_at(arr, 1, (ke_storage_type)4321);
++	ke_array_set_at(arr, 2, (ke_storage_type)5555);
++	ke_array_set_at(arr, 3, (ke_storage_type)777);
++
++	ke_log("2: %d 3: %d \n", (int)ke_array_get(arr, 2), (int)ke_array_get(arr, 3));
++
++	return;
++}
++
++int __init __ke_runtime_init(void)
++{
++	init_mach_ipc();
++	init_macho_binfmt();
++	
++	__ke_runtime_test();
++
++	_ke_initialized = true;
++
++	ke_log("ke_runtime_init(): runtime started\n");
++	return 0;
++}
++
+diff -Naur ./old//magenta/ke_runtime.h ./kern//magenta/ke_runtime.h
+--- ./old//magenta/ke_runtime.h	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ke_runtime.h	2012-06-30 23:29:03.000000000 +0100
+@@ -0,0 +1,65 @@
++/*
++ * ke_runtime.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Kernel runtime support.
++ */
++
++#ifndef _H_MG_KE_RUNTIME_
++#define _H_MG_KE_RUNTIME_
++
++
++#include <linux/kernel.h>
++#include <linux/string.h>
++#include <linux/slab.h>
++
++#include <DarwinTypes.h>
++#include <MachO.h>
++
++#define KE_TYPE_UNKNOWN 0
++#define KE_TYPE_ARRAY 1
++
++/* void bzero(void *s, size_t n); */
++#define bzero(ptr, sz) memset(ptr, 0, sz)
++
++/**/
++#define ke_storage_type void*
++#define Boolean int
++
++typedef struct {
++	uint16_t type;
++} ke_type_impl;
++
++typedef struct {
++	ke_type_impl base;
++
++	unsigned int count;
++	unsigned int capacity;
++	unsigned int capacityIncrement;
++
++	ke_storage_type* array;
++} ke_array_impl;
++
++typedef void* ke_type_t;
++typedef ke_type_t ke_array_t;
++
++/* Memory */
++void* ke_alloc(size_t size);
++void ke_free(void* ptr);
++void* ke_realloc(void* ptr, size_t size);
++
++/* Array */
++ke_array_t ke_array_with_capacity(unsigned int capacity);
++bool ke_array_init(ke_array_t arr, unsigned int capacity);
++ke_storage_type ke_array_get(ke_array_t arr, unsigned int index);
++bool ke_array_set_at(ke_array_t arr, unsigned int index, ke_storage_type anObject);
++unsigned int ke_array_get_count(ke_array_t arr);
++bool ke_array_add(ke_array_t arr, ke_storage_type anObject);
++int ke_log(const char *fmt, ...);
++
++/* Port */
++void ke_setup_task_port(struct task_struct* task);
++
++#define ke_critical panic
++
++#endif
+\ No newline at end of file
+diff -Naur ./old//magenta/ke_task.c ./kern//magenta/ke_task.c
+--- ./old//magenta/ke_task.c	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ke_task.c	2012-06-24 16:10:59.000000000 +0100
+@@ -0,0 +1,255 @@
++/*
++ * ke_task.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Task related routines.
++ */
++
++#include <linux/module.h>
++
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++#include <linux/sched.h>
++
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ke_runtime.h"
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++
++/* extended version that can map stuff in different tasks */
++extern
++unsigned long mmap_region_ex(struct file *file, unsigned long addr,
++			  unsigned long len, unsigned long flags,
++			  unsigned int vm_flags, unsigned long pgoff,
++			  struct task_struct* tsk);
++
++static struct task_struct* ke_task_from_port(task_port_t* space)
++{
++	return space->task;
++}
++
++unsigned long ke_mm_get_unmapped(struct mm_struct* mm,
++	unsigned long addr,
++	unsigned long len,
++	unsigned long flags)
++{
++	unsigned long error = arch_mmap_check(addr, len, flags);
++	unsigned long (*get_area)(struct file *, unsigned long,
++				  unsigned long, unsigned long, unsigned long);
++
++	/* arch specific checks */
++	if (error)
++		return error;
++
++	/* overflow checks */
++	if (len > TASK_SIZE)
++		return -ENOMEM;
++
++	get_area = mm->get_unmapped_area;
++	addr = get_area(NULL, addr, len, 0, flags);
++
++	if (IS_ERR_VALUE(addr))
++		return addr;
++
++	if (addr > TASK_SIZE - len)
++		return -ENOMEM;
++	if (addr & ~PAGE_MASK)
++		return -EINVAL;
++
++	/* arm only */
++	return addr;
++}
++
++kern_return_t ke_task_vm_allocate(task_port_t* port,
++	uintptr_t* addr,
++	size_t size,
++	boolean_t anywhere)
++{
++	struct task_struct* ts = ke_task_from_port(port);
++	struct mm_struct* mm = ts->mm;
++	unsigned long flags = 0;
++	unsigned long pgoff = 0;
++	unsigned int vm_flags = 0;
++	unsigned int prot = PROT_READ | PROT_WRITE | PROT_EXEC;
++	unsigned long ret = 0;
++	unsigned long reqprot = prot;
++	uintptr_t iaddr = *addr;
++
++	if (!anywhere) {
++		flags |= MAP_FIXED;
++	}
++	else {
++		iaddr = 0;
++	}
++
++	down_write(&mm->mmap_sem);
++
++	vm_flags = calc_vm_prot_bits(prot) | calc_vm_flag_bits(flags) |
++			mm->def_flags | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC;
++
++	ret = 
++	ke_mm_get_unmapped(current->mm,
++		(unsigned long)iaddr,
++		(unsigned long)size,
++		flags);
++
++	if (IS_ERR_VALUE(ret)) {
++		printk("mmap_region_ex(): ke_mm_get_unmapped returned %ld \n", ret);
++		up_write(&mm->mmap_sem);
++		return KERN_FAILURE;
++	}
++	else {
++		iaddr = (uintptr_t)ret;
++	}
++
++	pgoff = iaddr >> PAGE_SHIFT;
++
++	ret = 
++	mmap_region_ex(NULL, iaddr, (unsigned long)size, flags, vm_flags, pgoff, ts);
++
++	ke_log("mmap_region_ex = %ld \n", ret);
++
++	up_write(&mm->mmap_sem);
++
++	*addr = iaddr;
++
++	return KERN_SUCCESS;
++}
++
++mach_port_t _user_task_self(void)
++{
++	/* We should already hold the send right*/
++	task_port_t* tp = ke_get_current_task();
++	ke_port_right_t* rcv = ke_get_right_in_space(tp, (ke_port_t*)tp, false);
++
++	if (rcv) {
++		mach_port_t nm = rcv->name;
++		PortRelease(tp);
++		return nm;
++	}
++	else {
++		/*
++		 * This shouldn't ever happen.
++		 */
++		printk(KERN_ALERT "_user_task_self: mach task port invalid for task %p", current);
++		return 0;
++	}
++}
++
++kern_return_t _user_pid_for_task(mach_port_name_t t, int *x)
++{
++	task_port_t* tp;
++	struct task_struct* tsk;
++
++
++	tp = (task_port_t*)ke_port_find_named(t);
++
++	if (!tp) {
++		return KERN_INVALID_NAME;
++	}
++
++	tsk = tp->task;
++
++	if (!tsk) {
++		panic("task port %p doesn't have a task!", tp);
++	}
++
++	/* I hope pid_t is an int ... */
++	__put_user(tsk->pid, x);
++	PortRelease(tp);
++
++	return KERN_SUCCESS;
++}
++
++kern_return_t _user_task_for_pid(mach_port_t target_tport, int pid, mach_port_t *t)
++{
++	ke_port_right_t* snd;
++	task_port_t* tp;
++	struct task_struct* rem;
++	ke_port_t* rp;
++
++	tp = (task_port_t*)ke_port_find_named(target_tport);
++
++	if (!tp) {
++		return KERN_INVALID_NAME;
++	}
++
++	rem = find_task_by_vpid(pid);
++	if (!rem) {
++		return KERN_FAILURE;
++	}
++
++	rp = (ke_port_t*)(rem->task_port);
++	if (!rp) {
++		panic("task %p doesn't have a task port!", rem);
++	}
++
++	snd = ke_get_right_in_space(tp, rp, false);
++	if (!snd) {
++		PortRelease(tp);
++		return KERN_FAILURE;
++	}
++
++	RightIncrementRefCount(snd, r_send);
++
++	__put_user(snd->name, t);
++
++	PortRelease(tp);
++
++	return KERN_SUCCESS;
++}
++
++kern_return_t _user_vm_allocate(mach_port_t task,
++	uintptr_t* addr, /* __user */
++	size_t size,
++	boolean_t anywhere)
++{
++	task_port_t* port;
++	kern_return_t ret;
++	uintptr_t iaddr;
++
++	__get_user(iaddr, addr);
++
++	port = (task_port_t*)ke_port_find_named(task);
++	if (!port) {
++		return KERN_INVALID_NAME;
++	}
++
++	ret = ke_task_vm_allocate(port, &iaddr, size, anywhere);
++
++	__put_user(iaddr, addr);
++
++	PortRelease(port);
++	return ret;
++}
++
++void __ke_memtest(void)
++{
++	
++}
+\ No newline at end of file
+diff -Naur ./old//magenta/kext.c ./kern//magenta/kext.c
+--- ./old//magenta/kext.c	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/kext.c	2012-06-24 16:09:20.000000000 +0100
+@@ -0,0 +1,661 @@
++/*
++ * kext.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * What is this, I don't even ...
++ */
++
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++#include <linux/module.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++#include "ke_runtime.h"
++#include "loader.h"
++
++typedef struct kernel_symbol ksym_t;
++
++/*
++ * Symbols in the main image's symbtab.
++ */
++extern const ksym_t __start___ksymtab[];
++extern const ksym_t __stop___ksymtab[];
++extern const ksym_t __start___ksymtab_gpl[];
++extern const ksym_t __stop___ksymtab_gpl[];
++extern const ksym_t __start___ksymtab_gpl_future[];
++extern const ksym_t __stop___ksymtab_gpl_future[];
++
++static Boolean _verbose_log = true;
++
++#define doIfVerbose() if (_verbose_log)
++
++typedef struct __KXFile {
++	unsigned char *fMachO;
++	struct symtab_command *fSymtab;
++	
++	uintptr_t fSegmentOffset;
++	char *fStringBase;
++	struct nlist *fSymbolBase;
++	const struct nlist *fLocalSyms;
++	int fStringSectionOrdinal;
++
++	unsigned char* fSegmentBase;
++} KXFile;
++
++void *kmalloc_non_inline(size_t size, gfp_t flags)
++{
++	return kmalloc(size, flags);
++}
++EXPORT_SYMBOL(kmalloc_non_inline);
++
++const ksym_t*
++find_kernel_symbol_in(const char* name, const ksym_t* start, const ksym_t* end)
++{
++	const ksym_t* sym = start;
++
++	while (1) {
++		if (strcmp(sym->name, name) == 0) {
++			/* Found */
++			return sym;
++		}
++
++		sym++;
++
++		if (sym > end) {
++			break;
++		}
++	}
++
++	return FALSE;
++}
++
++ksym_t*
++find_kernel_symbol(const char* name)
++{
++	const ksym_t* sym = NULL;
++
++	if (!sym) {
++		sym = find_kernel_symbol_in(name, __start___ksymtab, __stop___ksymtab);
++	}
++
++	return (ksym_t*)sym;
++}
++
++static const struct nlist *
++kld_find_symbol_by_name(KXFile *file, const char* name)
++{
++	/*
++	 This is slow, but I don't care.
++	 */
++	
++	const struct nlist *sym;
++	int nsyms;
++	
++	nsyms = file->fSymtab->nsyms;
++	sym = file->fSymbolBase;
++	
++	while (nsyms--) {
++		/*
++		 if ((sym->n_type & N_EXT))
++		 return NULL;
++		 */
++		
++		long strx = sym->n_un.n_strx;
++		const char *symname = file->fStringBase + strx;
++		
++		if (strcmp(name, symname) == 0 && !(sym->n_type & N_STAB))
++			return sym;
++		
++		sym += 1;
++	}
++	
++	return NULL;
++}
++
++static const struct nlist *
++kld_find_symbol_by_address(KXFile *file, void *entry)
++{
++	/*
++		This is slow, but I don't care.
++	 */
++	
++	const struct nlist *sym;
++	int nsyms;
++	
++	nsyms = file->fSymtab->nsyms;
++	sym = file->fSymbolBase;
++	
++	while (nsyms--) {
++		uint32_t addr = (uint32_t)entry;
++		/*
++		if ((sym->n_type & N_EXT))
++			return NULL;
++		*/
++		
++		if (sym->n_desc & N_ARM_THUMB_DEF) {
++			addr = addr & ~1;
++		}
++
++		if (sym->n_value == addr && !(sym->n_type & N_STAB)) {
++			return sym;
++		}
++		
++		sym += 1;
++	}
++
++	return NULL;
++}
++
++Boolean kld_relocate_section(KXFile* file , struct section* sect, vm_offset_t delta)
++{
++	uint8_t* sbase;
++	uint32_t nreloc;
++	struct relocation_info *rinfo;
++	
++	sbase = (uint8_t*)sect->addr;
++	nreloc = sect->nreloc;
++	rinfo = (struct relocation_info *)(file->fMachO + sect->reloff);
++	
++	while (nreloc--) {
++		void** entry;
++		void** abs_entry;
++		unsigned long r_symbolnum, r_length;
++		const struct nlist *symbol = NULL;
++		enum reloc_type_generic r_type;
++		void *addr = NULL;
++		
++		/* Ignore scattered relocations */
++		if ((rinfo->r_address & R_SCATTERED))
++			continue;
++		
++		/* This is why we can't have nice things */
++		entry = (void**)( (uintptr_t)rinfo->r_address + (uintptr_t)sbase );
++		abs_entry = ((void**)( (uintptr_t)file->fSegmentBase + (uintptr_t)entry ));
++		
++		r_type = (enum reloc_type_generic)rinfo->r_type;
++		r_length = rinfo->r_length;
++		
++		/*
++			In r_length, 2 stands for long.
++		 */
++		if (r_type != GENERIC_RELOC_VANILLA || r_length != 2)
++			continue;
++		
++		r_symbolnum = rinfo->r_symbolnum;
++		
++		#if 0
++		ke_log("kld_relocate_section: {t=%d, ba=%p, aa=%p, ln=%d, n=%ld}\n",
++			   rinfo->r_type,
++			   (void*)rinfo->r_address, /* relative */
++			   entry, /* absolute (within the file) */
++			   rinfo->r_length,
++			   r_symbolnum);
++		#endif
++
++		if (rinfo->r_extern) {
++			/* External symbol entry */
++			long strx;
++			const char *symname;
++			ksym_t* ks; 
++
++			if(r_symbolnum >= file->fSymtab->nsyms)
++			{
++				ke_log("kld_relocate_section: invalid reloc entry\n");
++				return false;
++			}
++			
++			symbol = file->fSymbolBase;
++			
++			if ((symbol[r_symbolnum].n_type & N_TYPE) == N_INDR) {
++				/*
++					This is an indirect symbol, so get the value
++					for the actual thing.
++				 */
++				r_symbolnum = symbol[r_symbolnum].n_value;
++			}
++			
++			symbol = &symbol[r_symbolnum];
++			
++			if (symbol->n_type != (N_EXT | N_UNDF)) {
++				ke_log("kld_relocate_section: invalid reloc symbol type - !(N_EXT | N_UNDF)\n");
++				return false;
++			}
++
++			strx = symbol->n_un.n_strx;
++			symname = file->fStringBase + strx;
++			
++			if (symname[0] == '_') {
++				symname++;
++			}
++			else {
++				ke_log("kld_relocate_section: '%s' doesn't start with '_'\n", symname);
++				return false;
++			}
++
++			ks = find_kernel_symbol(symname);
++			if (!ks) {
++				ke_log("kld_relocate_section: failed to resolve '%s'\n", symname);
++				return false;
++			}
++
++			doIfVerbose() {
++				ke_log("\t[extern] sym_addr: %p, r_addr: %p, l_addr: %p, nm: '%s', ks: %p\n",
++					(void*)symbol,
++					(void*)rinfo->r_address,
++					(void*)addr,
++					symname,
++					(void*)ks);
++			}	
++
++			*abs_entry = (void*)(ks->value);
++		}
++		else {
++			/*
++			 * Relocate a local symbol. Local symbols in object files
++			 * are not attached to each other which means that all jumps
++			 * have to be fixed up.
++			 */
++
++			/* Derp */
++			if (r_symbolnum == R_ABS)
++			{
++				rinfo++;
++				continue;
++			}
++			
++			/* Not this pointer crap again */
++			addr = *abs_entry;
++
++			if (r_symbolnum == file->fStringSectionOrdinal)
++			{
++				/* This is a string section*/
++
++				doIfVerbose() {
++					ke_log("\t[local] (cstr) l_addr: %p, val: %p\n",
++						(void*)symbol,
++						(void*)addr);
++				}
++
++				*abs_entry = ((void*)( (uintptr_t)file->fSegmentBase + (uintptr_t)addr) );
++
++				rinfo++;
++				continue;
++			}
++
++			symbol = kld_find_symbol_by_address(file, addr);
++			
++			if (symbol) {
++				uint32_t val = symbol->n_value;
++
++				doIfVerbose() {
++					ke_log("\t[local] sym_addr: %p, r_addr: %p, l_addr: %p, val: %p\n",
++						(void*)symbol,
++						(void*)rinfo->r_address,
++						(void*)addr,
++						(void*)val);
++				}
++
++				if (symbol->n_desc & N_ARM_THUMB_DEF) {
++					val |= 1;
++				}
++
++				/* reloc */
++				*abs_entry = ((void*)( (uintptr_t)file->fSegmentBase + (uintptr_t)sbase + (uintptr_t)val ));
++			}
++			else {
++
++				doIfVerbose() {
++					ke_log("kld_relocate_section: can't find symbol at %p (ord: %d)\n",
++						(void*)addr,
++						(int)r_symbolnum);
++				}
++
++				return false;
++			}
++		}
++
++		rinfo++;
++	}
++	
++	return true;
++}
++
++Boolean kld_parse_symtab(KXFile* file)
++{
++	const struct nlist *sym;
++	unsigned int i, firstlocal = 0, nsyms;
++	const char *strbase;
++	unsigned int strsize;
++
++	file->fSymbolBase = 
++	(struct nlist *)(file->fMachO + file->fSymtab->symoff); 
++	
++	file->fStringBase = 
++	(char *)(file->fMachO + file->fSymtab->stroff);
++	
++	i = 0;
++	nsyms = file->fSymtab->nsyms;
++	strsize = file->fSymtab->strsize;
++	strbase = file->fStringBase;
++	sym = file->fSymbolBase;
++	
++	while (i < nsyms) {
++		long strx = sym->n_un.n_strx;
++		const char *symname = strbase + strx;
++		unsigned char n_type = sym->n_type & N_TYPE;
++		
++		doIfVerbose() {
++			ke_log("kld_parse_symtab: type=%d, val=%p, name='%s'\n",
++				   n_type,
++				   (void*)sym->n_value,
++				   symname);
++		}
++
++		n_type = sym->n_type & (N_TYPE | N_EXT);
++		
++		/*
++		 * First exported symbol 
++		 * This is done for the sake of performance
++		 */
++		if ( !firstlocal && (n_type & N_EXT) ) {
++			firstlocal = i;
++			file->fLocalSyms = sym;
++		}
++		
++		/* Increment stuff */
++		i += 1;
++		sym	+= 1;
++	}
++	
++	if (!file->fLocalSyms) {
++		ke_log("kld_parse_symtab: no symbols found\n");
++		return false;
++	}
++	
++	doIfVerbose() {
++		ke_log("kld_parse_symtab: {loc=%p}\n",
++				file->fLocalSyms);
++	}
++
++	return true;
++}
++
++Boolean kld_map_sect(KXFile* file, struct section* sect)
++{
++	uintptr_t sect_mem_addr = 
++	((uintptr_t)( (uintptr_t)file->fSegmentBase + (uintptr_t)sect->addr ));
++
++	uintptr_t sect_file_addr = 
++	((uintptr_t)( (uintptr_t)file->fMachO + (uintptr_t)sect->offset ));
++
++	doIfVerbose() {
++		ke_log("kld_map_sect: addr: %p, name: '%s', type: %d, size: %d\n",
++				   (void*)sect->addr,
++				   sect->sectname,
++				   (int)(sect->flags & SECTION_TYPE),
++				   (int)sect->size);
++	}
++
++	if ((sect->flags & SECTION_TYPE) == S_ZEROFILL)
++	{
++		memset((void*)sect_mem_addr, 0, sect->size);
++	}
++	else {
++		memcpy((void*)sect_mem_addr, (void*)sect_file_addr, sect->size);
++	}
++
++	return true;
++}
++
++Boolean kld_process_segment(KXFile* file, struct segment_command* seg) 
++{
++	struct section* sect = NULL;
++	uint32_t nsects = seg->nsects;
++	uint32_t total_size = 0;
++	int i = 0;
++
++#define iterate_sections()  \
++	sect = (struct section*)((uintptr_t)seg + sizeof(struct segment_command)); \
++	for (i = 0; i < nsects; i++, sect++) \
++
++	/* calculate total size */
++	iterate_sections()
++	{
++		total_size += sect->size;
++	}
++
++	file->fSegmentBase = ke_alloc(total_size);
++
++	/* map sections */
++	iterate_sections()
++	{
++		kld_map_sect(file, sect);
++		
++		if ((sect->flags & SECTION_TYPE) == S_CSTRING_LITERALS)
++		{
++			file->fStringSectionOrdinal = i+1;
++		}
++	}
++
++	/* perform relocation */
++	iterate_sections() 
++	{
++		if (!kld_relocate_section(file, sect, 0))
++		{
++			return false;
++		}
++	}
++	
++	return true;
++}
++
++Boolean kld_file_map(void* buffer, long size, KXFile* file)
++{
++	size_t macho_header_sz = sizeof(struct mach_header);
++	uint8_t* load_commands;
++	struct mach_header* head;
++	
++	/* command parser */
++	boolean_t has_segment = FALSE;
++	size_t offset;
++	size_t oldoffset;
++	uint32_t ncmds;
++	
++	/* segment */
++	struct segment_command *seg_hdr;
++	uintptr_t sect_offset = 0;
++	uint32_t nsects = 0;
++	
++	bzero(file, sizeof(file));
++
++	head = buffer;
++	load_commands = buffer + macho_header_sz;
++	
++	offset = 0;
++	ncmds = head->ncmds;
++	
++	file->fMachO = buffer;
++	
++	doIfVerbose() {
++		ke_log("kld_file_map: macho {fl=%d}\n", head->flags);
++	}
++
++	while (ncmds--) {
++		struct load_command	*lcp = 
++		(struct load_command *)(load_commands + offset);
++		
++		oldoffset = offset;
++		offset += lcp->cmdsize;
++		
++		if (oldoffset > offset ||
++		    lcp->cmdsize < sizeof(struct load_command) ||
++		    offset > head->sizeofcmds + macho_header_sz)
++		{
++			ke_log("kld_file_map: malformed load command\n");
++			return false;
++		}
++		
++		/*
++			Mach objects (MH_OBJECT) are only meant to have one segment that has all the bits.
++		 */
++		switch(lcp->cmd) {
++			case LC_SEGMENT:
++			{
++				if (has_segment) {
++					ke_log("kld_file_map: more than one segment in the file \n");
++					return false;
++				}
++				
++				seg_hdr = (struct segment_command *)lcp;
++				
++				nsects = seg_hdr->nsects;
++				sect_offset = (uintptr_t)(seg_hdr + sizeof(struct segment_command));
++				
++				file->fSegmentOffset = seg_hdr->fileoff;
++				
++				doIfVerbose() {
++					ke_log("kld_file_map: LC_SEGMENT {nsects=%d} \n",
++					  	 seg_hdr->nsects);
++				}
++				
++				has_segment = TRUE;
++				
++				break;
++			}
++			case LC_UUID:
++			case LC_DYSYMTAB:
++			{
++				/* Do. Not. Care. */
++				break;
++			}
++			case LC_SYMTAB:
++			{
++				file->fSymtab = (struct symtab_command*)lcp;
++				break;
++			}
++			default:
++			{
++				ke_log("kld_file_map: unsupported load command %d \n",
++						lcp->cmd);
++				
++				return false;
++				break;
++			}
++		}
++	}
++	
++	if (!file->fSymtab) {
++		ke_log("kld_file_map: object file missing symbols \n");
++		return false;
++	}
++	else {
++		kld_parse_symtab(file);
++	}
++	
++	if (!has_segment) {
++		ke_log("kld_file_map: object file missing segment \n");
++		return false;
++	}
++	else {
++		if (!kld_process_segment(file, seg_hdr))
++		{
++			return false;
++		}
++	}
++	
++	return true;
++}
++
++void abi_test(int aa, long long aaa)
++{
++	ke_log("ABI_TEST: int: %d, long: %lld\n", aa, aaa);
++}
++EXPORT_SYMBOL(abi_test);
++
++void lol_test(void)
++{
++	ke_log("LOL, TEST!!! \n");
++}
++EXPORT_SYMBOL(lol_test);
++
++void _user_load_kext(void* buffer, size_t size)
++{
++	/* 
++	 *	mach_msg_header_t head;
++	 *	void* buffer;
++	 *	unsigned int buffer_len;
++	 */
++
++	Boolean ret;
++	void* buf;
++
++	const struct nlist* nl;
++	KXFile file;
++
++	buf = ke_alloc(size);
++
++	if (copy_from_user(buf, buffer, size))
++	{
++	 	ke_log("kmsg_load_kext: goof \n");
++		return;
++	}
++	
++	if (kld_file_map(buf, size, &file))
++	{
++		uintptr_t val;
++		uint16_t* addr;
++		int (*kmod_init)(void);
++		int kret = 0;
++
++		nl = kld_find_symbol_by_name(&file, "_kmod_start");
++		
++		if (nl == NULL) {
++			ke_log("kmsg_load_kext: symbol not found \n");
++			return;
++		}
++
++		val = nl->n_value;
++		addr = (uint16_t*)((val + (uintptr_t)file.fSegmentBase));
++		
++		if (nl->n_desc & N_ARM_THUMB_DEF) {
++			addr = (uint16_t*)((unsigned int)addr | 1);
++		}
++
++		kmod_init = (void*)addr;
++			
++		/* Branch into the unknown */
++		kret = kmod_init();
++
++		ke_log("kmsg_load_kext: kmod returned %d\n", kret);
++	}
++	else
++	{
++		panic("kext loading failure!");
++	}
++}
+\ No newline at end of file
+diff -Naur ./old//magenta/loader.h ./kern//magenta/loader.h
+--- ./old//magenta/loader.h	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/loader.h	2012-06-16 22:04:07.000000000 +0100
+@@ -0,0 +1,120 @@
++/*
++ * loader.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Loader types.
++ */
++
++#ifndef _H_MG_LOADER_
++#define _H_MG_LOADER_
++
++#include "ipc_types.h"
++#include <DarwinTypes.h>
++#include <MachO.h>
++
++/* Section */
++
++ /*
++ * The flags field of a section structure is separated into two parts a section
++ * type and section attributes.  The section types are mutually exclusive (it
++ * can only have one type) but the section attributes are not (it may have more
++ * than one attribute).
++ */
++#define SECTION_TYPE		 0x000000ff	/* 256 section types */
++#define SECTION_ATTRIBUTES	 0xffffff00	/*  24 section attributes */
++
++/* Constants for the type of a section */
++#define	S_REGULAR		0x0	/* regular section */
++#define	S_ZEROFILL		0x1	/* zero fill on demand section */
++#define	S_CSTRING_LITERALS	0x2	/* section with only literal C strings*/
++#define	S_4BYTE_LITERALS	0x3	/* section with only 4 byte literals */
++#define	S_8BYTE_LITERALS	0x4	/* section with only 8 byte literals */
++#define	S_LITERAL_POINTERS	0x5	/* section with only pointers to */
++					/*  literals */
++
++
++/* Nlist */
++
++#define	N_STAB	0xe0  /* if any of these bits set, a symbolic debugging entry */
++#define	N_PEXT	0x10  /* private external symbol bit */
++#define	N_TYPE	0x0e  /* mask for the type bits */
++#define	N_EXT	0x01  /* external symbol bit, set for external symbols */
++
++/*
++ * Only symbolic debugging entries have some of the N_STAB bits set and if any
++ * of these bits are set then it is a symbolic debugging entry (a stab).  In
++ * which case then the values of the n_type field (the entire field) are given
++ * in <mach-o/stab.h>
++ */
++
++/*
++ * Values for N_TYPE bits of the n_type field.
++ */
++#define	N_UNDF	0x0		/* undefined, n_sect == NO_SECT */
++#define	N_ABS	0x2		/* absolute, n_sect == NO_SECT */
++#define	N_SECT	0xe		/* defined in section number n_sect */
++#define	N_PBUD	0xc		/* prebound undefined (defined in a dylib) */
++#define N_INDR	0xa		/* indirect */
++
++struct nlist {
++	union {
++#ifndef __LP64__
++		char *n_name;	/* for use when in-core */
++#endif
++		int32_t n_strx;	/* index into the string table */
++	} n_un;
++	uint8_t n_type;		/* type flag, see below */
++	uint8_t n_sect;		/* section number or NO_SECT */
++	int16_t n_desc;		/* see <mach-o/stab.h> */
++	uint32_t n_value;	/* value of this symbol (or stab offset) */
++};
++
++#define N_NO_DEAD_STRIP 0x0020 /* symbol is not to be dead stripped */
++#define N_DESC_DISCARDED 0x0020	/* symbol is discarded */
++#define N_WEAK_REF	0x0040 /* symbol is weak referenced */
++#define N_WEAK_DEF	0x0080 /* coalesed symbol is a weak definition */
++#define	N_REF_TO_WEAK	0x0080 /* reference to a weak symbol */
++#define N_ARM_THUMB_DEF	0x0008 /* symbol is a Thumb function (ARM) */
++#define N_SYMBOL_RESOLVER  0x0100 
++
++/* Reloc stuff */
++
++ #define R_SCATTERED 0x80000000	/* mask to be applied to the r_address field 
++				   of a relocation_info structure to tell that
++				   is is really a scattered_relocation_info
++				   stucture */
++
++enum reloc_type_generic
++{
++    GENERIC_RELOC_VANILLA,	/* generic relocation as discribed above */
++    GENERIC_RELOC_PAIR,		/* Only follows a GENERIC_RELOC_SECTDIFF */
++    GENERIC_RELOC_SECTDIFF,
++    GENERIC_RELOC_PB_LA_PTR,	/* prebound lazy pointer */
++    GENERIC_RELOC_LOCAL_SECTDIFF,
++    GENERIC_RELOC_TLV		/* thread local variables */
++};
++
++struct relocation_info {
++   int32_t	r_address;	/* offset in the section to what is being
++				   relocated */
++   uint32_t     r_symbolnum:24,	/* symbol index if r_extern == 1 or section
++				   ordinal if r_extern == 0 */
++		r_pcrel:1, 	/* was relocated pc relative already */
++		r_length:2,	/* 0=byte, 1=word, 2=long, 3=quad */
++		r_extern:1,	/* does not include value of sym referenced */
++		r_type:4;	/* if not 0, machine specific relocation type */
++};
++
++#define	R_ABS	0		/* absolute relocation type for Mach-O files */
++
++/* Actual loader stuff */
++struct symtab_command {
++	uint32_t	cmd;		/* LC_SYMTAB */
++	uint32_t	cmdsize;	/* sizeof(struct symtab_command) */
++	uint32_t	symoff;		/* symbol table offset */
++	uint32_t	nsyms;		/* number of symbol table entries */
++	uint32_t	stroff;		/* string table offset */
++	uint32_t	strsize;	/* string table size in bytes */
++};
++
++#endif
+\ No newline at end of file
+diff -Naur ./old//magenta/mach.c ./kern//magenta/mach.c
+--- ./old//magenta/mach.c	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach.c	2012-07-01 00:02:22.000000000 +0100
+@@ -0,0 +1,579 @@
++/*
++ * mach.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Mach routines.
++ */
++
++#include <linux/module.h>
++
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++
++/*
++	Port list.
++*/
++static DECLARE_RWSEM(ports_sem);
++static task_port_t* kernel_task;
++static DEFINE_MUTEX(port_ref_modify_lock);
++
++#define RefModifyLockDown() mutex_lock(&port_ref_modify_lock)
++#define RefModifyLockUp() mutex_unlock(&port_ref_modify_lock)
++
++/*
++ * Zones used by the slab allocators.
++ */
++static struct kmem_cache* zone_port_rights;
++
++/* Handler for kernel messages */
++extern int kmsg_handle(mach_msg_header_t* msg);
++extern kern_return_t ipc_message_handle(void* payload);
++
++/*
++	Mutex for kmsgs.
++*/
++DEFINE_MUTEX(kmsg_exec_mutex);
++
++/*
++ * Logging routine.
++ */
++#define ChristinasSillyUartDebugging 0
++#define BRIGHT 		1
++#define BLUE		4
++#define	WHITE		7
++#define default_attributes "\33[0m"
++
++int ke_log(const char *fmt, ...)
++{
++	va_list args;
++	int r;
++
++#if defined(ChristinasSillyUartDebugging)
++	char pre[13];
++	sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, WHITE + 30, BLUE + 40);
++	printk("%s[kern]%s: ", pre, default_attributes);
++#endif
++
++	va_start(args, fmt);
++	r = vprintk(fmt, args);
++	va_end(args);
++
++	return r;
++}
++
++/*
++ * Returns a new kernel port.
++ */
++ke_port_t* ke_port_allocate(uint16_t type)
++{
++	ke_port_t* prt = NULL;
++	int i = 0;
++	size_t port_size;
++
++	if (type == KE_PORT_TYPE_TASK) {
++		port_size = sizeof(task_port_t);
++	}
++	else if (type == KE_PORT_TYPE_IPC) {
++		port_size = sizeof(ipc_port);
++	}
++	else {
++		panic("ke_port_allocate(): unknown port type");
++	}
++
++	down_write(&ports_sem);
++	up_write(&ports_sem);
++
++	prt = (ke_port_t*)kmalloc(port_size, GFP_KERNEL);
++
++	prt->type = type;
++	prt->active = true;
++	mutex_init(&prt->mtx);
++	atomic_set(&prt->refs, 0);
++
++	return prt;
++}
++
++boolean_t ke_port_active(ke_port_t* port)
++{
++	boolean_t active;
++	active = port->active;
++
++	return active;
++}
++
++void ke_port_up(ke_port_t* port)
++{
++	int ar;
++	ar = atomic_dec_return(&port->refs);
++
++	ke_log("ke_port_up(%p): refcount %d\n", port, ar);
++
++	if (ar < 0) {
++		panic("port refcount is smaller than 0, something is broken!");
++	}
++}
++
++boolean_t ke_port_down(ke_port_t* port)
++{
++	//if (!PortActive(port)) {
++	//	return false;
++	//}
++	//else {
++		int ar;
++		ar = atomic_inc_return(&port->refs);
++
++		ke_log("ke_port_down(%p): refcount %d\n", port, ar);
++
++		return true;
++	//}
++}
++
++ke_port_right_t* ke_create_right(void)
++{
++	ke_port_right_t* right;
++
++	right = (ke_port_right_t*)kmem_cache_alloc(zone_port_rights, GFP_KERNEL);
++
++	atomic_set(&(right->r_receive), 0);
++	atomic_set(&(right->r_send), 0);
++	atomic_set(&(right->r_port_set), 0);
++	atomic_set(&(right->r_send), 0);
++	atomic_set(&(right->r_kernel), 0);
++}
++
++void ke_add_right_to_space(task_port_t* space, ke_port_right_t* rr)
++{
++	PortLock(space);
++
++	list_add(&(rr->list), &(space->port_rights));
++
++	PortUnlock(space);
++}
++
++void ke_teardown_task(task_port_t* space)
++{
++	struct list_head *p;
++	ke_port_right_t* rr = NULL;
++
++	PortLock(space);
++	space->port.active = false;
++
++	list_for_each (p, &(space->port_rights)) {
++		int count;
++		ke_port_t* port;
++
++		RefModifyLockDown();
++		rr = list_entry(p, ke_port_right_t, list);
++		port = rr->port;
++		RightIncrementRefCount(rr, r_kernel);
++		PortRetain(port);
++		RefModifyLockUp();
++
++		count = atomic_read(&(rr->r_receive));
++
++		if (count == 1) {
++			ke_log("tearing down receive right %d\n", rr->name);
++			if (port->type == KE_PORT_TYPE_IPC)
++			{
++				ipc_port* iport = (ipc_port*)port;
++
++				/* release the completion variable */
++				iport->dead = true;
++				complete(&(iport->wait_for_enqueued_data));
++			}
++
++			port->active = false;
++		}
++		else if (count > 1) {
++			panic("port right %d has more than one receive ref!", rr->name);
++		}
++		else {
++			/* 0 */
++		}
++
++		RightDecrementRefCount(rr, r_kernel);
++		PortRelease(port);
++	}
++
++	PortUnlock(space);
++}
++
++task_port_t* ke_get_task_port(struct task_struct* task)
++{
++	RefModifyLockDown();
++
++	task_port_t* tp = (task_port_t*)task->task_port;
++	PortRetain(tp);
++
++	RefModifyLockUp();
++
++	return tp;
++}
++
++task_port_t* ke_get_current_task(void)
++{
++	return ke_get_task_port(current);
++}
++
++/*
++ * Either gets an existing port right or adds it to the 
++ * ipc space (if add is specified).
++ */
++ke_port_right_t* ke_get_right_in_space(task_port_t* space, ke_port_t* fprt, boolean_t add)
++{
++	struct list_head *p;
++	ke_port_right_t* rr = NULL;
++
++	PortLock(space);
++
++	if (space->port.type != KE_PORT_TYPE_TASK) {
++		/* Only tasks can store rights */
++		PortUnlock(space);
++		goto out;
++	}
++
++	list_for_each (p, &(space->port_rights)) {
++		rr = list_entry(p, ke_port_right_t, list);
++		if (rr->port == fprt) {
++			PortUnlock(space);
++			goto out;
++		}
++	}
++
++	PortUnlock(space);
++
++	/*
++	 * Right not found in the list, we need to add
++	 * a new one to it.
++	 */
++	rr = ke_create_right();
++	rr->port = fprt;
++	ke_add_right_to_space(space, rr);
++
++out:
++	if (rr) {
++		RightIncrementRefCount(rr, r_kernel);
++	}
++	return rr;
++}
++
++/*
++ * Creates a brand new port (not a right, an actual port)
++ * in the space. Also sets up a empty right for the port.
++ * The unassosciated right is returned.
++ * This function sets up a new port name for the port.
++ */
++ke_port_right_t* ke_new_port(uint16_t type)
++{
++	ke_port_right_t* rr;
++	ke_port_t* kprt;
++
++	kprt = ke_port_allocate(type);
++
++	/* Set up the first right */
++	rr = ke_create_right();
++	rr->port = kprt;
++	rr->urefs = 1;
++
++	return rr;
++}
++
++
++/*
++ * Finds a port right.
++ */
++ke_port_right_t* ke_right_find_named(mach_port_t name)
++{
++	ke_port_right_t* prt = NULL;
++	task_port_t* space;
++	ke_port_right_t* rr;
++	struct list_head *p;
++
++	space = ke_get_current_task();
++
++	RefModifyLockDown();
++
++	PortLock(space);
++	list_for_each (p, &(space->port_rights)) {
++		rr = list_entry(p, ke_port_right_t, list);
++		if (rr->name == name) {
++			prt = rr;
++		}
++	}
++	PortUnlock(space);
++
++	PortRelease(space);
++	
++	if (prt) {
++		if (PortRetain(prt->port)) {
++			/* Nothing */
++		}
++		else {
++			/*
++			 * Right points to an inactive port.
++			 * Pretend it doesn't exist.
++			 */
++			RefModifyLockUp();
++			return NULL;
++		}
++	}
++
++	RefModifyLockUp();
++
++	if (prt) {
++		RightIncrementRefCount(rr, r_kernel);
++	}
++	return prt;
++}
++
++/*
++ * Finds a port by its port name in the local
++ * ipc space. If it is not found, returns NULL.
++ */
++ke_port_t* ke_port_find_named(mach_port_t name)
++{
++	ke_port_t* prt = NULL;
++	ke_port_right_t* rr;
++
++	rr = ke_right_find_named(name);
++	if (rr) {
++		prt = rr->port;
++		RightDecrementRefCount(rr, r_kernel);
++	}
++
++	return prt;
++}
++
++mach_port_t ke_get_new_port_name_in_space(task_port_t* space)
++{
++	int id = 0;
++	int res = 0;
++	if (idr_pre_get(&(space->name_pool), GFP_KERNEL) == 0) {
++		panic("ke_get_new_port_name_in_space(): idr failure");
++	}
++
++	res = idr_get_new_above(&(space->name_pool), NULL, 20, &id);
++
++	if (res != 0)
++	{
++		panic("ke_get_new_port_name_in_space(): idr failure 2");
++	} 
++
++	return id;
++}
++
++kern_return_t task_message_handle(void* payload, void* trap_data)
++{
++	panic("task_message_handle");
++}
++
++ke_port_right_t* ke_create_ipc_space(void)
++{
++	task_port_t* kprt = NULL;
++	ke_port_right_t* rr = NULL;
++
++	rr = ke_new_port(KE_PORT_TYPE_TASK);
++	if (!rr || !rr->port) {
++		panic("ke_create_ipc_space(): unable to create a new ipc space");
++	}
++	kprt = (task_port_t*)rr->port;
++
++	kprt->port.msg_handler = task_message_handle;
++
++	/* Initalize the port right list */
++	INIT_LIST_HEAD(&(kprt->port_rights));
++
++	/* Initialize IDR for allocating port names */
++	idr_init(&(kprt->name_pool));
++
++	return rr;
++}
++
++void ke_setup_task_port(struct task_struct* task)
++{
++	ke_port_right_t* rr = ke_create_ipc_space();
++	task_port_t* kprt = (task_port_t*)rr->port;
++
++	/* Set the task descriptor */
++	kprt->task = task;
++
++	/* And set the port */
++	task->task_port = (void*)kprt;
++
++	/* Add a receive right for the kernel */
++	rr->name = ke_get_new_port_name_in_space(kernel_task);
++	RightIncrementRefCount(rr, r_receive);
++	ke_add_right_to_space(kernel_task, rr);
++
++	/* Add a send right to the task */
++	rr = ke_create_right();
++	rr->port = (ke_port_t*)kprt;
++	rr->name = ke_get_new_port_name_in_space(kprt);
++	RightIncrementRefCount(rr, r_send);
++	ke_add_right_to_space(kprt, rr);
++
++	ke_log("ke_setup_task_port(): task %p got port %d\n", task, rr->name);
++}
++
++static void dump_mach_msg_hdr(mach_msg_header_t* head) {
++	return;
++
++	printk(KERN_WARNING "Mach Message:\n"
++	"\tbits: %p\n\tsize: %d\n\tremote: %d\n\tlocal: %d\n\tid : %d\n"
++	,(void*)head->msgh_bits, head->msgh_size, head->msgh_remote_port, head->msgh_local_port, head->msgh_id);
++}
++
++kern_return_t mach_port_destroy(ipc_space_t task, mach_port_name_t name)
++{
++	return KERN_FAILURE;
++}
++
++SYSCALL_DEFINE1(mach_msg_trap, struct mach_msg_trap_data __user *, usr_data)
++{
++	printk("sys_mach_msg_trap(): obsolete, do not use!");
++	return KERN_FAILURE;
++}
++
++kern_return_t _user_mach_msg_trap(struct mach_msg_trap_data __user* usr_data)
++{
++	mach_msg_trap_data_t trap_data;
++	kern_return_t ret;
++	ke_port_t* receiver;
++	ke_port_right_t* receiver_right;
++
++	/* For the message we will read in */
++	mach_msg_header_t tmsg;
++	mach_msg_header_t* msg;
++	mach_port_t receive_name;
++
++	if (!current) {
++		panic("mach_msg_trap(): used without user context");
++	}
++
++	/* read in the trap data */
++	if (copy_from_user(&trap_data, usr_data, sizeof(mach_msg_trap_data_t)))
++	{
++		ret = KERN_FAILURE;
++		goto out;
++	}
++
++	/* read in the temp message header */	
++	if (copy_from_user(&tmsg, trap_data.msg, sizeof(mach_msg_header_t)))
++	{
++		ret = KERN_FAILURE;
++		goto out;
++	}
++
++	receive_name = trap_data.receive_name;
++	if (receive_name == 0) {
++		/* send only */
++		receive_name = tmsg.msgh_remote_port;
++	}
++
++	ke_log("mach_msg(): using port %d\n", receive_name);
++
++	/*
++	 * Read in the entire inline message. We leave an empty space
++	 * at the end so we can place the message trailer there.
++	 *
++	 * 	XXX: Needs some sort of a bounds check for kalloc.
++	*/
++	msg = (mach_msg_header_t*)kmalloc(tmsg.msgh_size + LARGEST_TRAILER_SIZE, GFP_KERNEL);
++	if (copy_from_user(msg, trap_data.msg, tmsg.msgh_size)) {
++		ret = KERN_FAILURE;
++		goto out;
++	}
++
++	dump_mach_msg_hdr(msg);
++
++	receiver_right = ke_right_find_named(receive_name);
++
++	if (!receiver_right)
++	{
++		printk("mach_msg_trap(): port name %d not found in ipc space\n", receive_name);
++		ret = KERN_FAILURE;
++		goto out;
++	}
++
++	receiver = receiver_right->port;
++	RightDecrementRefCount(receiver_right, r_kernel);
++
++	if (!receiver)
++	{
++		printk("mach_msg_trap(): %d, internal error\n", receive_name);
++		ret = KERN_FAILURE;
++		goto out;
++	}
++
++	if (receiver->msg_handler != NULL)
++	{
++		ret = receiver->msg_handler((void*)msg, (void*)(&trap_data));
++		PortRelease(receiver);
++	}
++	else
++	{
++		PortRelease(receiver);
++		ke_log("mach_msg_trap(): mach port %p can't receive messages\n", receiver);
++		ret = KERN_FAILURE;
++		goto out;
++	}
++
++out:
++	if (ret != KERN_SUCCESS) {
++		ke_log("mach_msg_trap(): returning with error %d\n", ret);
++	}
++
++	return ret;
++}
++
++int init_mach_ipc(void)
++{
++	ke_port_right_t* rr = NULL;
++	ke_port_t* kprt = NULL;
++
++	zone_port_rights = 
++	kmem_cache_create("zone_port_rights", sizeof(ke_port_right_t), 0, SLAB_PANIC, NULL);
++
++	if (!zone_port_rights) {
++		panic("init_mach_ipc(): failed to create port right slab");
++	}
++
++	/*
++	 * Create an IPC space for the kernel.
++	 */
++	rr = ke_create_ipc_space();
++	kprt = rr->port;
++	kernel_task = (task_port_t*)kprt;
++
++	ke_log("init_mach_ipc(): started mach ipc subsystem {max_ports=%d}\n", MAX_PORT_COUNT);
++
++	return 0;
++}
+diff -Naur ./old//magenta/mach_kmsg.c ./kern//magenta/mach_kmsg.c
+--- ./old//magenta/mach_kmsg.c	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_kmsg.c	2012-06-24 13:29:50.000000000 +0100
+@@ -0,0 +1,52 @@
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++
++void get_dents_darwin(kmsg_get_directory_entries_t* km);
++void kmsg_load_kext(kmsg_load_kext_msg_t* msg);
++
++#define MsgToKmsg(type) type* km = (type*)msg;
++
++void kmsg_mach_task_self(kmsg_mach_task_self_msg_t* km)
++{
++	panic("kmsg_mach_task_self");
++}
++
++int kmsg_handle(mach_msg_header_t* msg)
++{
++	switch (msg->msgh_id)
++	{
++		default:
++		{
++			printk("kmsg_handle(): invalid kernel message (id: %d)\n", msg->msgh_id);
++			return -EINVAL;
++		}
++	}
++}
+\ No newline at end of file
+diff -Naur ./old//magenta/mach_kmsg.h ./kern//magenta/mach_kmsg.h
+--- ./old//magenta/mach_kmsg.h	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_kmsg.h	2012-06-03 17:06:16.000000000 +0100
+@@ -0,0 +1,53 @@
++/*
++ * mach_kmsg.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Special mach messages that get interpreted by the
++ * kernel.
++ */
++
++#ifndef _H_MG_MACH_KMSG_
++#define _H_MG_MACH_KMSG_
++
++#include "ipc_types.h"
++
++#define KMSG_MACH_PORT_ALLOCATE 2000
++#define KMSG_LOAD_KEXT 2001
++#define KMSG_GET_DIRECTORY_ENTRIES 2002
++
++typedef struct 
++{
++	mach_msg_header_t head;
++	mach_port_right_t rights;
++	mach_port_t* port_out;
++} kmsg_mach_port_allocate_msg_t;
++
++typedef struct 
++{
++	mach_msg_header_t head;
++	void* buffer;
++	unsigned int buffer_len;
++} kmsg_load_kext_msg_t;
++
++typedef struct 
++{
++	mach_msg_header_t head;
++	int fd;
++	int* out_error;
++	void* buffer;
++	unsigned int buffer_len;
++} kmsg_get_directory_entries_t;
++
++
++/*
++ * 2100: Mach routines
++ */
++#define KMSG_MACH_TASK_SELF 2100
++
++typedef struct 
++{
++	mach_msg_header_t head;
++	mach_port_t* out_port;
++} kmsg_mach_task_self_msg_t;
++
++#endif
+\ No newline at end of file
+diff -Naur ./old//magenta/macho_loader.c ./kern//magenta/macho_loader.c
+--- ./old//magenta/macho_loader.c	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/macho_loader.c	2012-06-24 14:24:44.000000000 +0100
+@@ -0,0 +1,1216 @@
++/*
++ * MachO Binary Format Support
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * A standalone kernel module responsible for loading MachO binaries
++ * into the kernel. Right now this only supports ARM binaries.
++ */
++
++/*
++ * Incl.
++ */
++#include <linux/module.h>
++#include <linux/kernel.h>
++#include <linux/fs.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/binfmts.h>
++#include <linux/string.h>
++#include <linux/file.h>
++#include <linux/slab.h>
++#include <linux/personality.h>
++#include <linux/elfcore.h>
++#include <linux/init.h>
++#include <linux/highuid.h>
++#include <linux/compiler.h>
++#include <linux/highmem.h>
++#include <linux/pagemap.h>
++#include <linux/security.h>
++#include <linux/random.h>
++#include <linux/elf.h>
++#include <linux/utsname.h>
++#include <linux/coredump.h>
++#include <asm/uaccess.h>
++#include <asm/param.h>
++#include <asm/page.h>
++
++#include <DarwinTypes.h>
++#include <MachO.h>
++
++
++/* 
++	This needs to be in the MachO.h header.
++	#####################################################
++*/
++#define	SEG_TEXT	"__TEXT"
++
++/* mach_loader.h */
++#define LOAD_SUCCESS            0
++#define LOAD_BADARCH            1       /* CPU type/subtype not found */
++#define LOAD_BADMACHO           2       /* malformed mach-o file */
++#define LOAD_SHLIB              3       /* shlib version mismatch */
++#define LOAD_FAILURE            4       /* Miscellaneous error */
++#define LOAD_NOSPACE            5       /* No VM available */
++#define LOAD_PROTECT            6       /* protection violation */
++#define LOAD_RESOURCE           7       /* resource allocation failure */
++
++#define ARM_THREAD_STATE 1
++
++#ifndef CPU_TYPE_ARM
++#define CPU_TYPE_ARM            ((cpu_type_t) 12)
++#define CPU_SUBTYPE_ARM_V4T		((cpu_subtype_t) 5)
++#define CPU_SUBTYPE_ARM_V6		((cpu_subtype_t) 6)
++#endif
++
++#ifndef CPU_SUBTYPE_ARM_V5TEJ
++#define CPU_SUBTYPE_ARM_V5TEJ           ((cpu_subtype_t) 7)
++#endif
++
++#ifndef CPU_SUBTYPE_ARM_V7
++#define CPU_SUBTYPE_ARM_V7		((cpu_subtype_t) 9)
++#endif
++
++/* ARM ONLY! */
++#define trunc_page(x)           ((x) & ~PAGE_MASK)
++
++
++
++/* 
++	Forward declarations
++	#####################################################
++*/
++static int fucking_core_dumper(struct coredump_params *cprm);
++static int load_macho_binary(struct linux_binprm *bprm, struct pt_regs *regs);
++static int load_macho_library(struct file *);
++static unsigned long macho_map(struct file *, unsigned long, struct elf_phdr *,
++				int, int, unsigned long);
++
++
++/* 
++	Impl
++	#####################################################
++*/
++#define round_page(_v) (((_v) + PAGE_SIZE - 1) & ~(PAGE_SIZE - 1))
++
++#define LINK_TABLE_ADDR 0x80014000
++#define LINK_TABLE_SIZE PAGE_SIZE*2
++
++typedef struct {
++	uint32_t entry_count;
++	size_t table_size;
++} linker_image_table_header_t;
++
++typedef struct {
++	uintptr_t load_addr;
++	size_t size;
++	const char* name;
++} linker_image_entry_t;
++
++static struct linux_binfmt macho_format = {
++		.module		= THIS_MODULE,
++		.load_binary	= load_macho_binary,
++		.load_shlib	= load_macho_library,
++		.core_dump	= fucking_core_dumper, /* YOU GET NOTHING! */
++		.min_coredump	= 0,
++		.hasvdso	= 0
++};
++
++#define BAD_ADDR(x) ((unsigned long)(x) >= TASK_SIZE)
++
++/* Let's use some macros to make this stack manipulation a little clearer */
++#ifdef CONFIG_STACK_GROWSUP
++#define STACK_ADD(sp, items) ((elf_addr_t __user *)(sp) + (items))
++#define STACK_ROUND(sp, items) \
++	((15 + (unsigned long) ((sp) + (items))) &~ 15UL)
++#define STACK_ALLOC(sp, len) ({ \
++	elf_addr_t __user *old_sp = (elf_addr_t __user *)sp; sp += len; \
++	old_sp; })
++#else
++#define STACK_ADD(sp, items) ((elf_addr_t __user *)(sp) - (items))
++#define STACK_ROUND(sp, items) \
++	(((unsigned long) (sp - items)) &~ 15UL)
++#define STACK_ALLOC(sp, len) ({ sp -= len ; sp; })
++#endif
++
++static unsigned long load_macho_interp(struct elfhdr *interp_elf_ex,
++		struct file *interpreter, unsigned long *interp_map_addr,
++		unsigned long no_base)
++{
++	panic("load_macho_interp: not implemented, use macho_get_dylinker instead. ");
++}
++
++
++static unsigned long randomize_stack_top(unsigned long stack_top)
++{
++	return stack_top;
++}
++
++static int ml_setBrk(unsigned long start, unsigned long end)
++{
++	start = PAGE_ALIGN(start);
++	end = PAGE_ALIGN(end);
++	if (end > start) {
++		unsigned long addr;
++		down_write(&current->mm->mmap_sem);
++		addr = do_brk(start, end - start);
++		up_write(&current->mm->mmap_sem);
++		if (BAD_ADDR(addr))
++			return addr;
++	}
++	current->mm->start_brk = current->mm->brk = start;
++	return 0;
++}
++
++static int _verboseLog = 0;
++
++/* 
++	LOADER
++	#####################################################
++*/
++typedef int	vm_offset_t;
++typedef int	vm_size_t;
++
++static int macho_get_dylinker(struct linux_binprm *bprm, int file_size, struct dylinker_command * lcp, struct file **linker_file) {
++	/*
++		Setup the dynamic linker.
++	*/
++	char *name;
++	char *p;
++	
++	if (lcp->cmdsize < sizeof(*lcp))
++		return (LOAD_BADMACHO);
++
++		name = (char *)lcp + lcp->name.offset;
++
++	/* Make sure the linker path is null terminated */
++	p = name;
++	do {
++		if (p >= (char *)lcp + lcp->cmdsize)
++			return(LOAD_BADMACHO);
++	} while (*p++);
++
++	if (_verboseLog) 
++		printk(KERN_WARNING "macho_get_dylinker: dynamic linker is @'%s'\n", name);
++
++	/*
++		Load the linker executable file.
++	*/
++	*linker_file = open_exec(name);
++	if (IS_ERR(*linker_file)) {
++		printk(KERN_WARNING "macho_get_dylinker: can't execute the dynamic linker\n");
++		return(LOAD_BADMACHO);
++	}
++
++	return LOAD_SUCCESS;
++}
++
++static int macho_load_unix_thread(struct linux_binprm *bprm, int file_size, struct arm_thread_command * tcp, void** entry) {
++	/*
++		Setup the main thread.
++	*/
++	
++	/* sanity */
++	if (tcp->flavor != ARM_THREAD_STATE) {
++		printk(KERN_WARNING "macho_load_unix_thread: main thread is of the wrong type %d (need %d)\n",
++				tcp->flavor,
++				ARM_THREAD_STATE);
++	}
++	else if (tcp->count != 17) {
++		printk(KERN_WARNING "macho_load_unix_thread: has the wrong number of arm registers %d (need %d)\n",
++				tcp->count,
++				17);
++	}
++	else {
++		/**/
++		
++		/* Entry point */
++		if (_verboseLog)
++			printk(KERN_WARNING "macho_load_unix_thread: success, pc @ %d\n", tcp->state.r15);
++		
++		*entry = (void*)tcp->state.r15;
++	}
++	
++	return LOAD_SUCCESS;
++}
++
++static int macho_load_segment(struct linux_binprm *bprm,
++						  int file_size,
++						  struct segment_command* scp,
++						  int* top,
++						  void** first_text,
++						  vm_offset_t slide)
++{
++	/*
++		Bootstrap a macho segment.
++	*/
++	
++	/***/
++	size_t segment_command_size = sizeof(struct segment_command);
++	size_t total_section_size = scp->cmdsize - segment_command_size;
++	size_t single_section_size  = sizeof(struct section);
++	
++	int ret;
++	
++	/* setup mapping vars */
++	vm_offset_t map_addr = round_page(scp->vmaddr);
++	vm_size_t map_size = round_page(scp->filesize);
++	vm_size_t seg_size = round_page(scp->vmsize);
++	vm_offset_t map_offset = scp->fileoff;
++	vm_size_t delta_size;
++	vm_offset_t addr;
++	/*
++	 	Segment sanity checks.
++	*/
++	/* is the command right? */
++	if (scp->cmdsize < segment_command_size) {
++		printk(KERN_WARNING "macho_load_segment(%.*s): malformed command", 16, scp->segname);
++		return (LOAD_BADMACHO);
++	}
++	/* is the segment in range? */
++	if (scp->fileoff + scp->filesize < scp->fileoff ||
++		scp->fileoff + scp->filesize > (uint64_t)file_size) {
++		printk(KERN_WARNING "macho_load_segment(%.*s): out of range", 16, scp->segname);
++		return (LOAD_BADMACHO);
++	}
++	/* is page aligned? */
++	if ((scp->fileoff & (PAGE_SIZE-1)) != 0) {
++		printk(KERN_WARNING "macho_load_segment(%.*s): not page aligned", 16, scp->segname);
++		return (LOAD_BADMACHO);
++	}
++	
++	
++	
++	/*
++		Print some info about the segment.
++	*/
++	if (_verboseLog)
++		printk(KERN_WARNING "macho_load_segment(%.*s): addr %d, filesize %d, vmsize %d\n",
++				16,
++				scp->segname,
++				map_addr,
++				map_size,
++				seg_size);
++	
++	/*
++	do_mmap(struct file *file,
++			unsigned long addr,
++			unsigned long len,
++			unsigned long prot,
++			unsigned long flag,
++			unsigned long offset)
++	*/
++	
++	/* Actually map in the segment into the correct location.
++	 */
++	if (map_size > 0) {
++		/* There is something from the file to map */
++		
++		addr = PAGE_ALIGN(map_addr + slide);
++		
++		if (_verboseLog)
++			printk(KERN_WARNING "macho_load_segment(%.*s): seg mmap @ %d, offset %d \n",
++					16,
++					scp->segname,
++					addr,
++					map_offset);
++		
++		/* lock */
++		down_write(&current->mm->mmap_sem);
++		void* mapped = 		
++		do_mmap(bprm->file,
++				addr,
++				map_size,
++				PROT_WRITE | PROT_READ | PROT_EXEC,
++				MAP_PRIVATE | MAP_FIXED,
++				map_offset);
++		/* unlock */
++		up_write(&current->mm->mmap_sem);
++		
++		if (strncmp(scp->segname, SEG_TEXT, 16) == 0) {
++			/*
++				This is a text segment, check if it's mapped from zero and then
++				bump up the first_text variable to make sure it points to its start.
++			*/
++			if (map_offset == 0) {
++				if (_verboseLog)
++					printk(KERN_WARNING "macho_load_segment(%.*s): this is the base segment \n", 16, scp->segname);
++				
++				*first_text = (void*)(addr);
++			}
++		}
++		
++		if ((mapped) <= 0) {
++			printk(KERN_WARNING "macho_load_segment(%.*s): map file seg failed \n", 16, scp->segname);
++			ret = LOAD_RESOURCE;
++			goto out;
++		}
++		else {
++			if (_verboseLog)
++				printk(KERN_WARNING "macho_load_segment(%.*s): mapped in @ %d \n", 16, scp->segname, (void*)mapped);
++		}
++		
++		/*
++		 *	If the file didn't end on a page boundary,
++		 *	we need to zero the leftover.
++		 */
++		delta_size = map_size - scp->filesize;
++		if (delta_size > 0) {
++			if (_verboseLog)
++				printk(KERN_WARNING "macho_load_segment(%.*s): fixxuuup \n", 16, scp->segname);	
++		}
++	}
++	
++	/*	If the virtual size of the segment is greater
++	 *	than the size from the file, we need to allocate
++	 *	anonymous zero fill memory for the rest. 
++	 */
++	delta_size = seg_size - map_size;
++	if (delta_size > 0) {
++		addr = PAGE_ALIGN(map_addr + map_size + slide);
++		
++		if (_verboseLog)
++			printk(KERN_WARNING "macho_load_segment(%.*s): mmap @ %d, size: %d\n", 16, scp->segname, addr, delta_size);
++		
++		/* lock */
++		down_write(&current->mm->mmap_sem);
++		void* mapped = 		
++		do_mmap(NULL,
++				addr,
++				delta_size,
++				PROT_WRITE | PROT_READ | PROT_EXEC,
++				MAP_FIXED | MAP_PRIVATE,
++				0);
++		/* unlock */
++		up_write(&current->mm->mmap_sem);
++		
++		if ((mapped) <= 0) {
++			printk(KERN_WARNING "macho_load_segment(%.*s): map anon failed \n", 16, scp->segname);
++			ret = LOAD_RESOURCE;
++			goto out;
++		}
++		else {
++			if (_verboseLog)
++				printk(KERN_WARNING "macho_load_segment(%.*s): anon chunk mapped in @%p \n", 16, scp->segname, (void*)mapped);
++		}
++	}
++	
++	if (*top < (map_addr + slide + seg_size)) {
++		/* highest address so far, update the top variable */
++		*top = ((map_addr + slide + seg_size));
++	}
++	
++	/* mapped in successfully */
++	ret = LOAD_SUCCESS;
++	
++out:		
++	return ret;
++}
++
++static int macho_get_file_size(struct file* file) {
++	/* file size from struct file */
++	
++	/* sanity checks */
++	if (!file)
++		return -1;
++	if (!file->f_path.dentry)
++		return -1;
++	if (!file->f_path.dentry->d_inode) 
++		return -1;
++		
++	return file->f_path.dentry->d_inode->i_size;
++}
++
++static int macho_validate_image(struct file* file, macho_header* head) 
++{
++	/*
++		Sanity checks.
++	*/
++	int retval = -ENOEXEC;
++	int file_size = 0;
++	size_t macho_header_sz = sizeof(macho_header);
++	
++	if (head->magic != MH_MAGIC) {
++		printk(KERN_WARNING "macho_validate_image: binary is not a macho binary (magic: 0x%p) \n", (void*)head->magic);
++		retval = -ENOEXEC;
++		goto out_ret;
++	}
++	
++	/*
++		Validate architecture.
++	*/
++	if (head->cputype != CPU_TYPE_ARM) {
++		printk(KERN_WARNING "macho_validate_image: wrong architecture in the executable\n");
++		retval = -EINVAL;
++		goto out_ret;
++	}
++	
++	/*
++		Run ARM-specific validation checks
++	*/
++	if (head->cputype == CPU_TYPE_ARM) {
++		if (head->cpusubtype == CPU_SUBTYPE_ARM_V7)
++		{
++			if (cpu_architecture() != CPU_ARCH_ARMv7) {
++				printk(KERN_WARNING "macho_validate_image: armv7 executables are not supported by the current platform\n");
++				retval = -EINVAL;
++				goto out_ret;
++			}
++		}
++		else if (head->cpusubtype == CPU_SUBTYPE_ARM_V6)
++		{
++			if (cpu_architecture() != CPU_ARCH_ARMv6 && cpu_architecture() != CPU_ARCH_ARMv7) {
++				printk(KERN_WARNING "macho_validate_image: armv6 executables are not supported by the current platform\n");
++				retval = -EINVAL;
++				goto out_ret;
++			}
++		}
++		else {
++			printk(KERN_WARNING "macho_validate_image: unrecognized arm version in the executable (%d)\n", head->cpusubtype);
++			retval = -EINVAL;
++			goto out_ret;
++		}
++	}
++	
++	
++	/*
++	 	Make sure the file size can be retrieved in order 
++	  	to perform sanity checks on the file.
++	 */
++	file_size = macho_get_file_size(file);
++	if (file_size < 0) {
++		printk(KERN_WARNING "macho_validate_image: can't retrieve binary size \n");
++		retval = -EINVAL;
++		goto out_ret;
++	}
++	
++	/*
++		Main portion of the sanity checks for the macho file.
++	*/
++	
++	retval = -EINVAL;
++	/* can we map it? */
++	if (!file->f_op||!file->f_op->mmap) {
++		printk(KERN_WARNING "macho_validate_image: binary file can't be mapped in \n");
++		goto out_ret;
++	}
++	/* sane lc size? */
++	if ((off_t)(macho_header_sz + head->sizeofcmds) > file_size) {
++		printk(KERN_WARNING "macho_validate_image: malformed load commands size \n");
++		goto out_ret;
++	}
++	if (head->filetype != MH_EXECUTE) {
++		printk(KERN_WARNING "IGN:macho_validate_image: macho file is not executable \n");
++		//goto out_ret;
++	}
++	
++	/* Print some info about the macho file */
++	if (_verboseLog)
++		printk(KERN_WARNING "macho_validate_image: valid macho file: \n\tmagic: 0x%p \n\tsize: %d\n",
++				(void*)head->magic,
++				file_size);
++	
++	retval = 0;
++	
++out_ret:	
++	return retval;
++}
++
++static int macho_load_dylinker(struct file* file, /* file for the dylinker*/
++								int* top_data, /* top of image data */
++								void** first_text,
++								void** entry_point) /* first text segment of the linker */
++								
++{
++	/* fake bprm for the segment loader*/
++	struct linux_binprm bprm;
++	
++	int retval;
++	int load_addr = *top_data;
++	size_t macho_header_sz = sizeof(macho_header);
++	macho_header* head = kmalloc(macho_header_sz, GFP_KERNEL);
++	int file_size = 0;
++
++	/* this is for LC loader */
++	int ret = 0;
++	size_t offset;
++	size_t oldoffset;
++	uint32_t ncmds;
++	uint8_t* addr;
++	
++	if (_verboseLog)
++		printk(KERN_WARNING "macho_load_dylinker: loading dynamic linker @ %d\n", load_addr);
++
++	/*
++		Read in the macho header.
++	*/
++	kernel_read(file, 0, head, macho_header_sz);
++
++	retval = macho_validate_image(file, head);
++	if (retval) {
++		retval = LOAD_BADMACHO;
++		printk(KERN_WARNING "macho_load_dylinker: dylinker image failed sanity checks, not loading \n");
++		goto out_ret;
++	}
++	
++	/*
++		XXX: this should be retrieved by macho_validate_image()
++	*/
++	file_size = macho_get_file_size(file);
++	
++	/*
++		Read the load commands from the file.
++	*/
++	offset = 0;
++	ncmds = head->ncmds;
++	addr = kmalloc(head->sizeofcmds, GFP_KERNEL); /***/
++	retval = -EINVAL;
++	
++	/* read in load commands */
++	kernel_read(file, macho_header_sz, addr, head->sizeofcmds);
++	
++	bprm.file = file;
++	
++	while (ncmds--) {
++		/* LC pointer */
++		struct load_command	*lcp = 
++		(struct load_command *)(addr + offset);
++		
++		oldoffset = offset;
++		offset += lcp->cmdsize;
++		
++		if (oldoffset > offset ||
++		    lcp->cmdsize < sizeof(struct load_command) ||
++		    offset > head->sizeofcmds + macho_header_sz)
++		{
++			printk(KERN_WARNING "macho_load_dylinker: malformed binary - lc overflow \n");
++			goto lc_ret;
++		}
++		
++		/*  Parse load commands.
++		 
++			We only need a bare minimum to get the image up an running. Dyld will
++			take care of all the other stuff.
++		 */
++		switch(lcp->cmd) {
++			case LC_SEGMENT:
++			{
++				/*
++					Load and slide a dylinker segment.
++				*/
++				ret = macho_load_segment(&bprm,
++									file_size,
++									(struct segment_command*)lcp,
++									top_data, /* keep bumping the same top_data */
++									first_text, /* first text segment */
++									load_addr); /* slide up */
++				
++				if (ret != LOAD_SUCCESS) {
++					printk(KERN_WARNING "macho_load_dylinker: segment loading failure \n");
++					goto lc_ret;
++				}
++				break;
++			}
++			case LC_UNIXTHREAD:
++			{
++				ret = macho_load_unix_thread(&bprm,
++										file_size,
++										(struct arm_thread_command*)lcp,
++										entry_point);
++										
++				if (ret != LOAD_SUCCESS) {
++					printk(KERN_WARNING "macho_load_dylinker: unix thread loading failure \n");
++					goto lc_ret;
++				}
++				break;
++			}
++			default: 
++			{
++				if (_verboseLog)
++					printk(KERN_WARNING "macho_load_dylinker: unsupported lc 0x%p \n", (void*)lcp->cmd);
++				
++				break;
++			}
++		}
++	}
++
++
++	/* loaded successfully */
++	retval = LOAD_SUCCESS;
++	
++	/* free resources */
++	lc_ret:
++		kfree(addr);
++	
++	out_ret:	
++		kfree(head);
++		return retval;
++}
++
++static struct page* dpages[1] = {NULL};
++
++static void wire_weird_pages(void)
++{
++	int ret;
++	void* addr;
++
++	/* 0x80000000 */
++	if (dpages[0] == NULL)
++	{
++		dpages[0] = alloc_pages(GFP_KERNEL, 0);
++	}
++
++
++	down_write(&current->mm->mmap_sem);
++	ret = 
++	install_special_mapping(current->mm,
++		0x80000000,
++		PAGE_SIZE,
++		VM_READ | VM_WRITE | VM_SHARED | VM_DONTCOPY,
++		dpages);
++	up_write(&current->mm->mmap_sem);
++
++	addr = page_address(dpages[0]);
++
++	memset(addr, 'w', PAGE_SIZE);
++
++	printk("wired weird page! (%p, %d, %p)\n", dpages[0], ret, addr);
++}
++
++static void macho_setup_link_table(void)
++{
++	void* mapped = LINK_TABLE_ADDR;
++	size_t sz = LINK_TABLE_SIZE;
++	linker_image_table_header_t* th;
++
++	down_write(&current->mm->mmap_sem);
++
++	mapped = 		
++	do_mmap(NULL,
++			mapped,
++			sz,
++			PROT_WRITE | PROT_READ,
++			MAP_FIXED | MAP_PRIVATE,
++			0);
++
++	up_write(&current->mm->mmap_sem);
++
++	th = (linker_image_table_header_t*)mapped;
++
++	__put_user((uint32_t)2, &th->entry_count);
++	__put_user((size_t)sz, &th->table_size);
++	
++	printk("mapped link table @ %p\n", mapped);
++}
++
++static int load_macho_binary(struct linux_binprm *bprm, struct pt_regs *regs)
++{ 
++	unsigned long def_flags = 0;
++	void* entry_point = 0;
++	int retval = -ENOEXEC;
++	int file_size = 0;
++	int executable_stack = EXSTACK_DEFAULT;
++	size_t macho_header_sz = sizeof(macho_header);
++	macho_header* head = ((macho_header*)bprm->buf);
++	struct file *linker_file = NULL;
++	int dylinker_load_addr;
++
++	size_t offset;
++	size_t oldoffset;
++	uint32_t ncmds;
++	uint8_t* addr;
++
++	int ret = 0;
++	
++	/* Top of the image data. This is needed to position the heap. */
++	int top_data = 0;
++	
++	/* First text segment where the mach header is. */
++	void* first_text = 0;
++	void* first_text_linker = 0;
++
++	/* Stack environment (grows down on ARM). */
++	uint32_t* stack = bprm->p;
++	uint32_t* argv_array;
++	uint32_t* argv;
++	uint32_t* envp_array;
++	uint32_t* envp;
++	uint32_t total_argv_size;
++	uint32_t total_env_size;
++
++	/* Arg stuff */
++	uint32_t argc;
++	uint32_t envc;
++	char* p;
++
++	linker_image_entry_t* ee;
++
++	/* have we got enough space? */
++	if (!head) {
++		retval = -ENOMEM;
++		goto out_ret;
++	}
++	
++	retval = macho_validate_image(bprm->file, head);
++	if (retval) {
++		printk(KERN_WARNING "load_macho_binary: image failed sanity checks, not loading \n");
++		goto out_ret;
++	}
++	
++	/*
++		XXX: this should be retrieved by macho_validate_image()
++	*/
++	file_size = macho_get_file_size(bprm->file);
++	
++	/*
++		The file seems to be alright, so set up an environment for the 
++		new binary to run in. After this, the old image will no longer be 
++		usable. If some of the load commands are broken, this process is doomed.
++	*/
++	retval = flush_old_exec(bprm);
++	if (retval) {
++		panic("load_macho_binary: flush_old_exec failed\n");
++	}
++	else {
++		unsigned int personality;
++
++		current->flags &= ~PF_FORKNOEXEC;
++		current->mm->def_flags = def_flags;
++		
++		setup_new_exec(bprm);
++		
++		/* set personality */
++		personality = current->personality & ~PER_MASK;
++		personality |= PER_LINUX;
++		
++		/*
++		 	This flag has to be set for 32x architectures (I think).
++		*/
++		personality |= ADDR_LIMIT_32BIT;
++		
++		set_personality(personality);
++
++		/* set stuff */
++		current->mm->free_area_cache = current->mm->mmap_base;
++		current->mm->cached_hole_size = 0;
++		//retval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP), executable_stack);
++					
++		if (retval < 0) {
++			//send_sig(SIGKILL, current, 0);
++			//goto out_ret;
++		}
++		
++		/* stack */
++		current->mm->start_stack = bprm->p;
++	}
++	
++	
++	/*
++		Read the load commands from the file.
++	*/
++	offset = 0;
++	ncmds = head->ncmds;
++	addr = kmalloc(head->sizeofcmds, GFP_KERNEL); /***/
++	retval = -EINVAL;
++	
++	/* read in load commands */
++	kernel_read(bprm->file, macho_header_sz, addr, head->sizeofcmds);
++	
++	while (ncmds--) {
++		/* LC pointer */
++		struct load_command	*lcp = 
++		(struct load_command *)(addr + offset);
++		
++		oldoffset = offset;
++		offset += lcp->cmdsize;
++		
++		if (oldoffset > offset ||
++		    lcp->cmdsize < sizeof(struct load_command) ||
++		    offset > head->sizeofcmds + macho_header_sz)
++		{
++			printk(KERN_WARNING "load_macho_binary: malformed binary - lc overflow \n");
++			goto lc_ret;
++		}
++		
++		/*  Parse load commands.
++		 
++			We only need a bare minimum to get the image up an running. Dyld will
++			take care of all the other stuff.
++		 */
++		switch(lcp->cmd) {
++			case LC_SEGMENT:
++				ret = macho_load_segment(bprm, file_size, (struct segment_command*)lcp, &top_data, &first_text, 0);
++				if (ret != LOAD_SUCCESS) {
++					printk(KERN_WARNING "load_macho_binary: segment loading failure \n");
++					goto lc_ret;
++				}
++				break;
++			case LC_LOAD_DYLINKER:
++				ret = macho_get_dylinker(bprm, file_size, (struct dylinker_command*)lcp, &linker_file);
++				if (ret != LOAD_SUCCESS) {
++					printk(KERN_WARNING "load_macho_binary: dylinker loading failure \n");
++					goto lc_ret;
++				}
++				else {
++					/* done */
++				}
++				break;
++			case LC_UNIXTHREAD:
++				ret = macho_load_unix_thread(bprm, file_size, (struct arm_thread_command*)lcp, &entry_point);
++				if (ret != LOAD_SUCCESS) {
++					printk(KERN_WARNING "load_macho_binary: unix thread loading failure \n");
++					goto lc_ret;
++				}
++				break;
++			default: 
++				if (_verboseLog)
++					printk(KERN_WARNING "load_macho_binary: unsupported lc 0x%p \n", (void*)lcp->cmd);
++
++				break;
++		}
++	}
++	
++	/*
++		Bootstrap the dynamic linker if needed.
++	*/
++	if (linker_file) {
++		dylinker_load_addr = top_data;
++		
++		macho_load_dylinker(linker_file,
++							&top_data,
++							&first_text_linker,
++							&entry_point);
++		
++		/* slide the entry point */
++		entry_point = entry_point + dylinker_load_addr;
++			
++		if (_verboseLog)				
++			printk(KERN_WARNING "load_macho_binary: dylinker's first text segment @ %d, new pc @ %d \n",
++					first_text_linker,
++					(int)entry_point);
++	}
++	
++	/*
++		Now, I don't know what these are used for, but I'm fairly sure
++		they're *very* important. So let's set them up. 
++		
++		See 'linux/mm_types.h':
++		unsigned long start_code, end_code, start_data, end_data;
++		unsigned long start_brk, brk, start_stack;
++	*/	
++	current->mm->start_code = 0; /* IMP */
++	current->mm->end_code = top_data; /* IMP */
++	current->mm->start_data = 0;
++	current->mm->end_data = top_data;
++		
++	if (_verboseLog)
++		printk(KERN_WARNING "load_macho_binary: setting up heap ...\n");
++
++	/* Set up an empty heap. This will be grown as more memory is allocated.  */
++	int brkret = ml_setBrk(top_data, top_data);
++
++	if (_verboseLog)
++		printk(KERN_WARNING "load_macho_binary: setting up misc ...\n");
++
++	/* setup misc stuff */
++	set_binfmt(&macho_format);
++	install_exec_creds(bprm);
++
++	/* Construct envp array. */
++	envp = envp_array = stack = (uint32_t*)stack - ((bprm->envc+1));
++
++	/* Construct argv array. */
++	argv = argv_array = stack = (uint32_t*)stack - ((bprm->argc+1));
++
++	if (_verboseLog)
++		printk(KERN_WARNING "load_macho_binary: setting up stack @ %p ...\n", (uint32_t*)stack);
++
++	argc = bprm->argc;
++	envc = bprm->envc;
++	p = bprm->p;
++
++	/* Set up argv pointers */
++	current->mm->arg_start = (unsigned long)p;
++	while(argc--) {
++		char c;
++
++		put_user(p,argv++);
++		do {
++			get_user(c,p++);
++		} while (c);
++	}
++	put_user(NULL,argv);
++
++	/* Set up envp pointers */
++	current->mm->arg_end = current->mm->env_start = (unsigned long) p;
++	while(envc--) {
++		char c;
++
++		put_user(p,envp++);
++		do {
++			get_user(c,p++);
++		} while (c);
++	}
++	put_user(NULL,envp);
++	current->mm->env_end = (unsigned long) p;
++
++	/*
++		The actual stuff passed to the linker goes here.
++	*/
++	stack = (uint32_t*)stack - (4);
++
++	stack[0] = (uint32_t)first_text; /* mach_header */
++	stack[1] = bprm->argc; /* argc */
++	stack[2] = argv_array; /* argv */
++	stack[3] = (uint32_t)first_text_linker; /* linker's mach_header */
++	
++	if (_verboseLog)
++		printk(KERN_WARNING "load_macho_binary: setting up main thread ...\n");	
++	
++	/*
++		Set up the main thread
++	*/
++	if (BAD_ADDR(entry_point)) {
++		/* entry point is not executable */
++		
++		printk(KERN_WARNING "load_macho_binary: bad entry point \n");
++		force_sig(SIGSEGV, current);
++		retval = -EINVAL;
++		goto lc_ret;
++	}
++	
++	if (_verboseLog)
++		printk(KERN_WARNING "load_macho_binary: setting up registers ...\n");
++
++	/* 
++		See 'start_thread' in 'processor.h'
++		'start_thread' provides an ELF implementation of this function.
++		This is for the Darwin ABI implementation which is used by iPhoneOS binaries.
++	*/
++	unsigned long initial_pc = (unsigned long)entry_point;	
++	
++	/* exit supervisor and enter user */
++	set_fs(USER_DS);
++	memset(regs->uregs, 0, sizeof(regs->uregs));
++	regs->ARM_cpsr = USR_MODE;	
++
++	/* If the entry point is THUMB, set the thumb bit */
++	if (initial_pc & 1)
++		regs->ARM_cpsr |= PSR_T_BIT;
++		
++	/* set up control regs */	
++	regs->ARM_cpsr |= PSR_ENDSTATE;	
++	regs->ARM_pc = initial_pc & ~1;		/* pc */
++	regs->ARM_sp = stack;		/* sp */
++
++	/* This is actually ignored, but set it anyway */
++	regs->ARM_r2 = stack[2];	/* r2 (envp) */	
++	regs->ARM_r1 = stack[1];	/* r1 (argv) */
++	regs->ARM_r0 = stack[0];	/* r0 (argc) */	
++	
++	/* ABI */
++	regs->ARM_r7 = stack;	/* FP */
++
++	/* this will work for mmu and nonmmu */
++	nommu_start_thread(regs);
++	
++	wire_weird_pages();	
++	macho_setup_link_table();
++
++	ee = (linker_image_entry_t*)(((char*)LINK_TABLE_ADDR) + sizeof(linker_image_entry_t));
++
++	/* main image */
++	__put_user(0, &ee->load_addr);
++	__put_user(dylinker_load_addr, &ee->size);
++
++	ee += 1;
++
++	__put_user(dylinker_load_addr, &ee->load_addr);
++	__put_user((uint32_t)top_data - (uint32_t)dylinker_load_addr, &ee->size);
++
++	/*
++		Binary is now loaded. Return 0 to signify success.
++	*/
++	retval = 0;
++
++	if (_verboseLog)
++		printk(KERN_WARNING "load_macho_binary: complete, heap starts at %d, brkret %d \n", top_data, brkret);
++
++	/*
++	 	Teardown
++	*/
++	lc_ret:
++		kfree(addr);
++	out_ret:
++		return retval;
++}
++
++#define MAX_UNWIND 20
++
++static int fucking_core_dumper(struct coredump_params *cprm)
++{
++	linker_image_table_header_t* tb = (linker_image_table_header_t*)LINK_TABLE_ADDR;
++	linker_image_entry_t* ee;
++	uint32_t count;
++	int i;
++	const char* pc_lib;
++	uint32_t* fp; /* frame pointer */
++	uint32_t call_stack[MAX_UNWIND];
++	uint32_t spos = 0;
++
++	printk(KERN_WARNING "----- Core Dump -----\n");
++
++	printk(KERN_WARNING "PID: %d\n", current->pid);
++
++	printk(KERN_WARNING "Received Signal: %ld\n", cprm->signr);
++
++	printk(KERN_WARNING "Register Dump:\n"
++	"\tpc @ %p (%d), sp @ %p \n"
++	"\tr0 @ %p, r1 @ %p, r2 @ %p, r3 @ %p, r4 @ %p \n"
++	"\tr5 @ %p, r6 @ %p, r7 @ %p, r8 @ %p, r9 @ %p \n"
++	"\tr10 @ %p, lr @ %p, cpsr @ %p (thumb: %d)\n",
++	(void*)cprm->regs->ARM_pc,
++	(int)cprm->regs->ARM_pc,
++	(void*)cprm->regs->ARM_sp,
++	(void*)cprm->regs->ARM_r0,
++	(void*)cprm->regs->ARM_r1,
++	(void*)cprm->regs->ARM_r2,
++	(void*)cprm->regs->ARM_r3,
++	(void*)cprm->regs->ARM_r4,
++	(void*)cprm->regs->ARM_r5,
++	(void*)cprm->regs->ARM_r6,
++	(void*)cprm->regs->ARM_r7,
++	(void*)cprm->regs->ARM_r8,
++	(void*)cprm->regs->ARM_r9,
++	(void*)cprm->regs->ARM_r10,
++	(void*)cprm->regs->ARM_lr,
++	(void*)cprm->regs->ARM_cpsr,
++	(int)(cprm->regs->ARM_cpsr & PSR_T_BIT));
++	
++	printk(KERN_WARNING "----- Call Stack -----\n");
++
++	/* unwind darwin stack */
++	fp = (uint32_t*)cprm->regs->ARM_r7;
++	while (spos < MAX_UNWIND)
++	{
++		uint32_t* new_fp;
++
++		/* Get saved LR and R7 */
++
++		if (get_user(call_stack[spos], &fp[1])) {
++			printk("\t*** Unwinding failed 0 (memory error @ %p)\n", &fp[1]);
++			break;
++		}
++
++		if (get_user(new_fp, &fp[0])) {
++			printk("\t*** Unwinding failed 1 (memory error @ %p)\n", &fp[0]);
++			break;
++		}
++
++		printk("\t%d: lr:%p r7:%p\n", spos, call_stack[spos], new_fp);
++
++		fp = new_fp;
++		spos++;
++	}
++
++	/* walk link table */
++	if (get_user(count, &tb->entry_count)) {
++		printk(" *** Unable to access link table in user memory!\n");
++		return 0;
++	}
++
++	ee = (linker_image_entry_t*)(((char*)tb) + sizeof(linker_image_entry_t));
++
++	printk(KERN_WARNING "----- Loaded Images -----\n");
++
++	if ((sizeof(linker_image_entry_t) * count) > LINK_TABLE_SIZE)
++	{
++		printk(" *** Link table corrupt!\n");
++	}
++	else
++	{
++		for (i = 0; i < count; i++)
++		{
++			int ii;
++			size_t sl;
++			const char* lname;
++			size_t image_size;
++			uintptr_t load_addr;
++			uint32_t loc = (uint32_t)cprm->regs->ARM_pc;
++			uint32_t lrr = (uint32_t)cprm->regs->ARM_lr;
++
++			linker_image_entry_t* t = &(ee[i]);
++
++			if (i > 1)
++			{
++				sl = strlen_user(t->name);
++
++				if (sl == 0)
++				{
++					lname = "<unknown>";
++				}
++				else
++				{
++					lname = (const char*)kmalloc(sl, GFP_KERNEL);
++					__copy_from_user(lname, t->name, sl);
++				}
++			}
++			else if (i == 0)
++			{
++				lname = "<main_image>";
++			}
++			else /*(i == 1)*/
++			{
++				lname = "<linker>";
++			}
++
++			__get_user(image_size, &t->size);
++			__get_user(load_addr, &t->load_addr);
++
++			printk("\t%s {%d - %d}\n", lname, load_addr, (uint32_t)load_addr + (uint32_t)image_size);
++
++			if (loc > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > loc)
++			{
++				uint32_t rel_pc = loc - (uint32_t)load_addr;
++
++				/* pc is in range */
++				printk("\t\t > [PC] in image @ %p (%d), abs: %p\n", (void*)rel_pc, rel_pc, (void*)loc);
++			}
++
++			if (lrr > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > lrr)
++			{
++				uint32_t rel_lr = lrr - (uint32_t)load_addr;
++
++				/* lr is in range */
++				printk("\t\t > [LR] in image @ %p (%d), abs: %p\n", (void*)rel_lr, rel_lr, (void*)lrr);
++			}
++
++			for (ii = 0; ii < spos; ii++)
++			{
++				uint32_t stack_pos = call_stack[ii];
++				if (stack_pos > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > stack_pos)
++				{
++					uint32_t rel_sp = stack_pos - (uint32_t)load_addr;
++
++					/* lr is in range */
++					printk("\t\t > [SP: %d] in image @ %p (%d), abs: %p\n", ii, (void*)rel_sp, rel_sp, (void*)stack_pos);
++				}
++			}
++		}
++	}
++
++	return 0;
++}
++
++static int load_macho_library(struct file *file)
++{
++	panic("load_macho_library: not implemented.");
++}
++
++int __init init_macho_binfmt(void)
++{
++	printk(KERN_WARNING "init_macho_binfmt: MachO binary loader initialized! (load: %p) \n", load_macho_binary);
++	
++	return register_binfmt(&macho_format);
++}
+diff -Naur ./old//magenta/mach_port_types.h ./kern//magenta/mach_port_types.h
+--- ./old//magenta/mach_port_types.h	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_port_types.h	2012-07-01 00:52:03.000000000 +0100
+@@ -0,0 +1,152 @@
++#ifndef _H_MG_MACH_PORT_TYPES_
++#define _H_MG_MACH_PORT_TYPES_
++
++#include <linux/kernel.h>
++#include <linux/kfifo.h>
++#include <linux/list.h>
++#include <linux/idr.h>
++#include <linux/wait.h>
++
++#include <DarwinTypes.h>
++#include <MachO.h>
++
++#include "kern_return.h"
++
++#define FALSE 0
++#define TRUE 1
++
++#define MAX_PORT_COUNT 4096
++
++typedef unsigned int natural_t;
++typedef int integer_t;
++typedef int boolean_t;
++
++typedef natural_t mach_port_t;
++typedef natural_t mach_port_right_t;
++typedef int mach_port_delta_t;
++
++typedef mach_port_t mach_port_name_t;
++
++typedef int kern_return_t;
++
++typedef unsigned int mach_msg_type_name_t;
++
++#define MACH_MSG_TYPE_MOVE_RECEIVE	16	/* Must hold receive rights */
++#define MACH_MSG_TYPE_MOVE_SEND		17	/* Must hold send rights */
++#define MACH_MSG_TYPE_MOVE_SEND_ONCE	18	/* Must hold sendonce rights */
++#define MACH_MSG_TYPE_COPY_SEND		19	/* Must hold send rights */
++#define MACH_MSG_TYPE_MAKE_SEND		20	/* Must hold receive rights */
++#define MACH_MSG_TYPE_MAKE_SEND_ONCE	21	/* Must hold receive rights */
++#define MACH_MSG_TYPE_COPY_RECEIVE	22	/* Must hold receive rights */
++
++
++#define MACH_PORT_RIGHT_SEND            ((mach_port_right_t) 0)
++#define MACH_PORT_RIGHT_RECEIVE         ((mach_port_right_t) 1)
++#define MACH_PORT_RIGHT_SEND_ONCE       ((mach_port_right_t) 2)
++#define MACH_PORT_RIGHT_PORT_SET        ((mach_port_right_t) 3)
++#define MACH_PORT_RIGHT_DEAD_NAME       ((mach_port_right_t) 4)
++#define MACH_PORT_RIGHT_NUMBER          ((mach_port_right_t) 5)
++
++#define KE_PORT_TYPE_FREE 0
++#define KE_PORT_TYPE_TASK 1
++#define KE_PORT_TYPE_IPC 2
++
++typedef enum {
++    kMachPortRightSend = 0x1,
++    kMachPortRightReceive = 0x2,
++    kMachPortRightSendOnce = 0x4,
++    /* 0x8, 0x10, 0x20, 0x40,*/
++    kMachPortRightKernel = 0x80,
++} ke_right_type_t;
++
++typedef struct __ke_port_t
++{
++	uint16_t type; /* port type */
++	atomic_t refs;
++	struct mutex mtx;
++	boolean_t active;
++
++	/*
++	 * Message handler. If not NULL, it gets called whenever
++	 * a port receives a message.
++	 */
++	kern_return_t (*msg_handler)(void* payload, void* trap_data);
++} ke_port_t;
++
++typedef struct 
++{
++	ke_port_t port;
++
++	struct task_struct *task; /* task which owns the port */
++	
++	struct completion wait_for_enqueued_data;
++	wait_queue_head_t wait_queue;
++	struct kfifo queue; /* queue */
++
++	boolean_t dead;
++	boolean_t allocated; 
++} ipc_port;
++
++typedef struct
++{
++	ke_port_t* port;
++	mach_port_t	name; /* port name */
++	int urefs;
++
++	atomic_t r_receive;
++	atomic_t r_send;
++	atomic_t r_send_once;
++	atomic_t r_port_set;
++
++	atomic_t r_kernel;
++
++	struct list_head list;
++} ke_port_right_t;
++
++/*
++ * This structure represents a task port as well
++ * the task's IPC space and other stuff.
++ */
++typedef struct 
++{
++	ke_port_t port;
++
++	struct task_struct *task; /* task which owns the port */
++
++	struct idr name_pool;
++	struct list_head port_rights; /* list of port rights for this task */
++} task_port_t;
++
++
++task_port_t* ke_get_current_task(void); /* [RetainPort] */
++ke_port_t* ke_port_find_named(mach_port_t name); /* [RetainPort] */
++ke_port_right_t* ke_right_find_named(mach_port_t name); /* [RetainPort][RetainRight] */
++task_port_t* ke_get_task_port(struct task_struct* task); /* [RetainPort] */
++
++/*
++ * [RetainRight]
++ * fprt must be a valid port.
++ */
++ke_port_right_t* ke_get_right_in_space(task_port_t* space, ke_port_t* fprt, boolean_t add); 
++
++mach_port_t ke_get_new_port_name_in_space(task_port_t* space);
++ke_port_right_t* ke_new_port(uint16_t type);
++void ke_add_right_to_space(task_port_t* space, ke_port_right_t* rr);
++
++boolean_t ke_port_active(ke_port_t* port);
++void ke_port_up(ke_port_t* port);
++boolean_t ke_port_down(ke_port_t* port);
++void ke_teardown_task(task_port_t* task);
++typedef task_port_t* ipc_space_t;
++
++#define PortLock(x) mutex_lock(&(((ke_port_t*)x)->mtx))
++#define PortUnlock(x) mutex_unlock(&(((ke_port_t*)x)->mtx))
++
++#define PortRetain(x) ke_port_down((ke_port_t*)x)
++#define PortRelease(x) ke_port_up((ke_port_t*)x)
++
++#define PortActive(x) ke_port_active((ke_port_t*)x)
++#define RightIncrementRefCount(x, y) atomic_inc(&(x->y))
++#define RightDecrementRefCount(x, y) atomic_dec(&(x->y))
++
++#endif 
+\ No newline at end of file
+diff -Naur ./old//magenta/mach_syscall.S ./kern//magenta/mach_syscall.S
+--- ./old//magenta/mach_syscall.S	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_syscall.S	2012-06-30 12:53:47.000000000 +0100
+@@ -0,0 +1,75 @@
++/*
++ * mach_syscall.S
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Darwin traps.
++ *
++ * Syscall number is initally stored in r12, but the sleh
++ * will move it to r7 (scno) as needed.
++ * 
++ * At the point of entry in ke_darwin_syscall, lr is set to
++ * the syscall fast return function.
++ */
++
++#define check_call(nr, fn) cmp r7, nr; beq fn;
++
++.text
++.align 2
++
++__mach_timer_cancel_trampoline:
++	push {r4}
++	mov r4, r2
++	mov r2, r1
++	mov r3, r4
++	pop {r4}
++
++	b _user_mk_timer_cancel
++
++__mach_timer_arm_trampoline:
++	push {r4}
++	mov r4, r2
++	mov r2, r1
++	mov r3, r4
++	pop {r4}
++
++	b _user_mk_timer_arm
++
++.globl ke_darwin_syscall
++ke_darwin_syscall:
++	/* Normal BSD syscalls */
++	check_call(#4, sys_write);
++
++	/* Native */
++	check_call(#0x158, _user_getdirentries64);
++
++	/* Now try mach masked syscalls */
++	and r7, r7, #0xff
++
++	/* VM */
++	check_call(#0xf5, _user_vm_allocate);
++
++	/* Task */
++	check_call(#0xe4, _user_task_self);
++	check_call(#0xd3, _user_task_for_pid);
++	check_call(#0xd2, _user_pid_for_task);
++
++	/* IPC */
++	check_call(#0xe1, _user_mach_msg_trap);
++	check_call(#0xf0, _user_mach_port_allocate);
++	check_call(#0xeb, _user_mach_port_insert_right);
++	check_call(#0xed, _user_mach_port_mod_refs);
++	check_call(#0xef, _user_mach_port_destroy);
++	check_call(#0xee, _user_mach_port_deallocate);
++
++	/* Timers */
++	check_call(#0xa5, _user_mk_timer_create);
++	check_call(#0xa4, _user_mk_timer_destroy);
++	check_call(#0xa3, __mach_timer_arm_trampoline);
++	check_call(#0xa2, __mach_timer_cancel_trampoline);
++
++	/* Stuff */
++	check_call(#0xff, _user_load_kext);
++
++	/* error out */
++	mov r0, r7
++	b ke_darwin_syscall_error
+\ No newline at end of file
+diff -Naur ./old//magenta/mach_user_port.c ./kern//magenta/mach_user_port.c
+--- ./old//magenta/mach_user_port.c	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_user_port.c	2012-07-01 02:38:40.000000000 +0100
+@@ -0,0 +1,502 @@
++/*
++ * mach_user_port.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Anything to do with ports that a user thing may create.
++ * This involves:
++ *     > IPC ports
++ *     > Port sets
++ */
++
++#include <linux/module.h>
++
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++#include "ke_runtime.h"
++
++/*
++ * This copies data to a userland buffer if the message is received from
++ * the userspace or to a kernel memory chunk if it is received from the 
++ * kernel.
++ */
++boolean_t ipc_copy_data_local(void* to, void* from, unsigned long size)
++{
++	if (current) {
++		if (copy_to_user(to, from, size)) {
++			return false;
++		}
++		else {
++			return true;
++		}
++	}
++	else {
++		memcpy(to, from, size);
++		return true;
++	}
++}
++/*
++ * Support for the mk_timer syscall familiy.
++ * This provides a nice mach port based timer interface.
++ */
++mach_port_name_t _user_mk_timer_create(void) 
++{
++	return 0;
++}
++
++kern_return_t _user_mk_timer_destroy(mach_port_name_t name)
++{
++	return KERN_FAILURE;
++}
++
++kern_return_t _user_mk_timer_arm(mach_port_name_t name, uint64_t expire_time)
++{
++	return KERN_FAILURE;
++}
++
++kern_return_t _user_mk_timer_cancel(mach_port_name_t name, uint64_t *result_time)
++{
++	return KERN_FAILURE;
++}
++
++/*
++ * IPC message dispatcher. Should be callable from both kernel and
++ * user space. This can be used in the kernel with some limitations.
++ */
++kern_return_t mach_msg_main(mach_msg_header_t* msg,
++							mach_msg_option_t option,
++							mach_msg_size_t send_size,
++							mach_msg_size_t receive_limit,
++							mach_port_t receive_name,
++							mach_msg_timeout_t timeout,
++							mach_port_t notify)
++{
++	ipc_message* im;
++	ipc_message* rm;
++	ipc_port* remote;
++	ipc_port* local;
++	int retval = 0;
++	mach_port_t sswp; /* for swaps */
++
++	if (msg->msgh_bits & MACH_MSGH_BITS_COMPLEX)
++	{
++		/* Complex messages are not supported yet */
++		printk("mach_msg(): complex messages not yet supported\n");
++		return KERN_FAILURE;
++	}
++
++	/*
++		*** IPC message send. ***
++	*/
++	if (option & MACH_SEND_MSG &&
++		msg->msgh_remote_port != 0) 
++	{
++		/*
++			Caller wants to send a mach message.
++		*/
++
++		/* 1). Find out where it wants to send it to. */
++		remote = (ipc_port*)ke_port_find_named(msg->msgh_remote_port);
++		if (!remote) {
++			printk("mach_msg(): nonexistent remote port\n");
++			/* baaad port */
++			kfree(msg);
++			return KERN_FAILURE;
++		}
++
++
++		/* Check the port type */
++		if (remote->port.type == KE_PORT_TYPE_TASK)
++		{
++			/* Task port, do special handling */
++			PortRelease(remote);
++			kfree(msg);
++			return 0;
++		}
++		else if (remote->port.type == KE_PORT_TYPE_IPC)
++		{
++			/* Do nothing for now */
++		}
++		else 
++		{
++			/* Can't send to this port type */
++			PortRelease(remote);
++			printk("mach_msg(): invalid remote port type\n");
++			kfree(msg);
++			return KERN_FAILURE;
++		}
++
++		/* 2). Prepare the message. */
++		im = (ipc_message*)kmalloc(sizeof(ipc_message), GFP_KERNEL);
++		im->sender = current;
++		im->msg = msg;
++		im->head = *(msg); /* inline header */
++		im->received = 0;
++		init_completion(&(im->send_block)); /* block */
++
++		/* 3). Enqueue a pointer to the message. */
++		kfifo_in((&remote->queue), &im, sizeof(im));
++		printk("enqueued message at %p\n", im);
++
++		/* 
++			4). If the receiver is waiting for queue writes, let it know.
++				that a new message just came in.
++		*/
++		wake_up((&remote->wait_queue));
++
++		PortRelease(remote);
++	}
++
++
++	/*
++		*** IPC message receive. ***
++	*/
++	if (option & MACH_RCV_MSG &&
++		msg->msgh_local_port != 0)
++	{
++		/*
++			Caller wants to receive a mach message.
++		*/
++		local = (ipc_port*)ke_port_find_named(msg->msgh_local_port);
++		
++		if (!local || local->port.type != KE_PORT_TYPE_IPC) {
++			printk("mach_msg(): invalid local port\n");
++			/* baaad port */
++
++			retval = KERN_INVALID_NAME;
++			goto out;
++		}
++
++		if (!local->port.active) {
++			/*
++			 * Port is dead!
++			 */
++			retval = KERN_FAILURE;
++			goto out;
++		}
++
++		if (kfifo_is_empty((&local->queue))) {
++			int qr = 0;
++
++			/*
++				1). If the queue is empty, wait until something writes to it.
++			*/
++			ke_log("mach_msg_receive(%p): waiting for enqueued data ...\n", local);
++			qr = wait_event_interruptible((local->wait_queue), !kfifo_is_empty(&(local->queue)));
++			
++
++			if (qr == -ERESTARTSYS)
++			{
++				ke_log("mach_msg_receive(%p): interrupted, returning KERN_FAILURE!\n", local);
++
++				PortRelease(local);
++				retval = KERN_FAILURE;
++				goto out;
++			}
++			else 
++			{
++				ke_log("mach_msg_receive(%p): receieved message!\n", local);
++			}
++		}
++
++		/* 2). Dequeue the message pointer. */
++		kfifo_out(&(local->queue), &rm, sizeof(rm));
++		ke_log("dequeued message at %p\n", rm);
++
++		/* 
++			3). Check if this is an internal (on the same thread) message.
++				If it is, don't wait for completion at the end.
++		*/
++		if (im == rm) {
++			//internal_message = 1;
++		}
++
++		/* 
++			4). Fixup the message.
++				This involves reversing the ports and adding a trailer.
++		*/
++
++		sswp = rm->msg->msgh_local_port;
++		rm->msg->msgh_local_port = rm->msg->msgh_remote_port;
++		rm->msg->msgh_remote_port = sswp;
++		/* XXX: trailer */
++		/* grow by the trailer size */
++		//rm->msg->msgh_size += LARGEST_TRAILER_SIZE;
++
++		/* Not touching the local port anymore */
++		PortRelease(local);
++
++		/* 5). Copy the message into the our space. */
++		if (ipc_copy_data_local(msg, rm->msg, rm->msg->msgh_size))
++		{
++			printk("can't write message %p\n", rm);
++			retval = KERN_FAILURE;
++			goto out;
++		}
++
++		rm->received = 1;
++
++		/* 6). If the receiver is waiting for completion, let it know that we're done */
++		complete(&(rm->send_block));
++	}
++
++	retval = KERN_SUCCESS;
++out:
++	if (option & MACH_SEND_MSG &&
++		msg->msgh_local_port != 0)
++	{
++		if (!im->received) {
++			/* Block this thread until the sent message is dequeued */
++			ke_log("mach_msg_send(%p): CONTENDED: waiting for message dequeue\n", im);
++			wait_for_completion(&(im->send_block));
++			ke_log("mach_msg_send(%p): DECONTENDED: waiting for message dequeue\n", im);
++		}
++
++		/* Destroy the copied message buffer */
++		kfree(im->msg);
++
++		/* Destroy the ipc_message */
++		kfree(im);
++	}
++
++	return retval;
++}
++
++/*
++ * Trampoline for user mach_msg calls to IPC ports.
++ */
++kern_return_t ipc_message_handle(void* payload, void* trap_data__)
++{
++	mach_msg_trap_data_t* trap_data = (mach_msg_trap_data_t*)trap_data__;
++	mach_msg_header_t* msg = (mach_msg_header_t*)payload;
++	kern_return_t retval;
++
++	retval = mach_msg_main(msg, trap_data->option,
++		trap_data->send_size,
++		trap_data->receive_limit,
++		trap_data->receive_name,
++		trap_data->timeout,
++		trap_data->notify);
++
++	if (retval != KERN_SUCCESS) {
++		ke_log("ipc_message_handle(): error %d\n", retval);
++	}
++
++	return retval;
++}
++
++ke_port_right_t* ipc_port_allocate(task_port_t* space) {
++	ipc_port* prt = NULL;
++	ke_port_right_t* rr = NULL;
++
++	rr = ke_new_port(KE_PORT_TYPE_IPC);
++	if (!rr || !rr->port) {
++		return NULL;
++	}
++	prt = (ipc_port*)rr->port;
++
++	prt->port.msg_handler = ipc_message_handle;
++
++
++	/* create a message queue */
++	if(kfifo_alloc(&(prt->queue), PAGE_SIZE, GFP_KERNEL)) {
++		panic("allocate_ipc_port(): can't create a message queue");
++	}
++
++	/* 
++	 * create a completion variable to hang on if the
++	 * queue is empty 
++	 */
++	init_waitqueue_head(&(prt->wait_queue));
++
++
++	/* Add a receive right for the task */
++	RightIncrementRefCount(rr, r_receive);
++	rr->name = ke_get_new_port_name_in_space(space);
++	ke_add_right_to_space(space, rr);
++
++	return rr;
++}
++
++kern_return_t mach_port_allocate(ipc_space_t task, mach_port_right_t right, mach_port_name_t *name)
++{
++	if (!task->port.active) {
++		return KERN_FAILURE;
++	}
++
++	if (right == MACH_PORT_RIGHT_RECEIVE || right == MACH_PORT_RIGHT_PORT_SET)
++	{
++		if (right == MACH_PORT_RIGHT_PORT_SET) {
++			printk("mach_port_allocate(): MACH_PORT_RIGHT_PORT_SET not supported, returning regular port instead\n");
++		}
++
++		/*
++		 * Ports created with 'MACH_PORT_RIGHT_RECEIVE' are IPC ports.
++		 */
++		ke_port_right_t* rr = ipc_port_allocate(task);
++
++		if (rr) {
++			*name = rr->name;
++		}
++		else {
++			return KERN_FAILURE;
++		}
++		
++		return KERN_SUCCESS;
++	}
++	else
++	{
++		/* Unknown right type */
++		return KERN_FAILURE;
++	}
++}
++
++kern_return_t _user_mach_port_insert_right(mach_port_t task, mach_port_name_t in_name, mach_port_name_t in_right, mach_msg_type_name_t right_type)
++{
++	ke_port_right_t* name;
++	ke_port_right_t* right;
++	task_port_t* target_space;
++	kern_return_t ret;
++
++	if (right != name) {
++		printk("_user_mach_port_insert_right(): XXX (right != name)\n");
++		return KERN_FAILURE;
++	}
++
++	target_space = (task_port_t*)ke_port_find_named(task);
++	if (!target_space) {
++		return KERN_INVALID_NAME;
++	}
++
++	name = ke_right_find_named(in_name);
++	if (!name) {
++		return KERN_INVALID_NAME;
++	}
++	if (!name->port) {
++		PortRelease(target_space);
++		RightDecrementRefCount(name, r_kernel);
++		return KERN_FAILURE;
++	}
++
++	/* Insert the right into the target IPC space */
++	right = ke_get_right_in_space(target_space, name->port, true);
++	if (!right) {
++		panic("_user_mach_port_insert_right(): ke_get_right_in_space failed");
++	}
++
++	/*
++	 * Now depending on the type of the right transferred, change stuff
++	 * [XXX]: Check if we hold the valid right needed to perform the operation.
++	 */
++	switch (right_type)
++	{
++		case MACH_MSG_TYPE_MAKE_SEND:
++		{
++			RightIncrementRefCount(right, r_send);
++			ret = KERN_SUCCESS;
++			break;
++		}
++		case MACH_MSG_TYPE_COPY_SEND:
++		{
++			RightIncrementRefCount(right, r_send);
++			ret = KERN_SUCCESS;
++			break;
++		}
++		case MACH_MSG_TYPE_MOVE_SEND:
++		{
++			RightIncrementRefCount(right, r_send);
++			RightDecrementRefCount(name, r_send);
++			ret = KERN_SUCCESS;
++			break;
++		}
++		case MACH_MSG_TYPE_MOVE_RECEIVE:
++		{
++			RightIncrementRefCount(right, r_receive);
++			RightDecrementRefCount(name, r_receive);
++			ret = KERN_SUCCESS;
++			break;
++		}
++		case MACH_MSG_TYPE_COPY_RECEIVE:
++		{
++			printk("_user_mach_port_insert_right(): invalid argument\n");
++			ret = KERN_FAILURE;
++			break;
++		}
++		default:
++		{
++			printk("_user_mach_port_insert_right(): unknown argument %d\n", right_type);
++			ret = KERN_FAILURE;
++			break;
++		}
++	}
++
++	PortRelease(name->port);
++	PortRelease(target_space);
++	RightDecrementRefCount(name, r_kernel);
++	RightDecrementRefCount(right, r_kernel);
++	return ret;
++}
++
++kern_return_t _user_mach_port_mod_refs(mach_port_t task, mach_port_name_t name, mach_port_right_t right, mach_port_delta_t delta)
++{
++	return KERN_FAILURE;
++}
++
++kern_return_t _user_mach_port_destroy(mach_port_t task,mach_port_name_t name)
++{
++	return KERN_FAILURE;
++}
++
++kern_return_t _user_mach_port_deallocate(mach_port_t task,mach_port_name_t name)
++{
++	return KERN_FAILURE;
++}
++
++kern_return_t _user_mach_port_allocate(mach_port_t task, mach_port_right_t right, mach_port_name_t *name)
++{
++	kern_return_t ret;
++	mach_port_name_t nn;
++	ipc_space_t port;
++
++	port = (task_port_t*)ke_port_find_named(task);
++	if (!port) {
++		return KERN_INVALID_NAME;
++	}
++
++	ret = mach_port_allocate(port, right, &nn);
++
++	__put_user(nn, name);
++
++	PortRelease(port);
++
++	return ret;
++}
++
++//mach_port_allocate(ke_get_current_task(), MACH_PORT_RIGHT_RECEIVE, &mp);
+\ No newline at end of file
+diff -Naur ./old//magenta/Makefile ./kern//magenta/Makefile
+--- ./old//magenta/Makefile	1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/Makefile	2012-06-23 17:50:17.000000000 +0100
+@@ -0,0 +1,13 @@
++# Makefile for Magenta's Kernel Components
++# Copyright (c) 2012 Christina Brooks
++
++obj-y	+= macho_loader.o
++obj-y	+= mach.o
++obj-y	+= ke_array.o
++obj-y	+= ke_runtime.o
++obj-y	+= darwin_getdirentries.o
++obj-y	+= kext.o
++obj-y	+= mach_kmsg.o
++obj-y	+= mach_syscall.o
++obj-y	+= ke_task.o
++obj-y	+= mach_user_port.o
+\ No newline at end of file
+diff -Naur ./old//Makefile ./kern//Makefile
+--- ./old//Makefile	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//Makefile	2012-05-19 00:13:20.000000000 +0100
+@@ -680,7 +680,7 @@
+ 
+ 
+ ifeq ($(KBUILD_EXTMOD),)
+-core-y		+= kernel/ mm/ fs/ ipc/ security/ crypto/ block/
++core-y		+= kernel/ mm/ fs/ ipc/ security/ crypto/ block/ magenta/
+ 
+ vmlinux-dirs	:= $(patsubst %/,%,$(filter %/, $(init-y) $(init-m) \
+ 		     $(core-y) $(core-m) $(drivers-y) $(drivers-m) \
+diff -Naur ./old//mm/mmap.c ./kern//mm/mmap.c
+--- ./old//mm/mmap.c	2011-01-05 00:50:19.000000000 +0000
++++ ./kern//mm/mmap.c	2012-06-17 06:12:38.000000000 +0100
+@@ -1214,6 +1214,186 @@
+ 	return (vm_flags & (VM_NORESERVE | VM_SHARED | VM_WRITE)) == VM_WRITE;
+ }
+ 
++int make_pages_present_ex(unsigned long addr, unsigned long end, struct task_struct* tsk)
++{
++	int ret, len, write;
++	struct vm_area_struct * vma;
++
++	vma = find_vma(tsk->mm, addr);
++	if (!vma)
++		return -ENOMEM;
++
++	write = (vma->vm_flags & (VM_WRITE | VM_SHARED)) == VM_WRITE;
++	BUG_ON(addr >= end);
++	BUG_ON(end > vma->vm_end);
++	len = DIV_ROUND_UP(end, PAGE_SIZE) - addr/PAGE_SIZE;
++	ret = get_user_pages(tsk, tsk->mm, addr,
++						len, write, 0, NULL, NULL);
++	if (ret < 0)
++		return ret;
++
++	return ret == len ? 0 : -EFAULT;
++}
++
++unsigned long mmap_region_ex(struct file *file, unsigned long addr,
++			  unsigned long len, unsigned long flags,
++			  unsigned int vm_flags, unsigned long pgoff,
++			  struct task_struct* tsk)
++{
++	struct mm_struct *mm = tsk->mm;
++	struct vm_area_struct *vma, *prev;
++	int correct_wcount = 0;
++	int error;
++	struct rb_node **rb_link, *rb_parent;
++	unsigned long charged = 0;
++	struct inode *inode =  file ? file->f_path.dentry->d_inode : NULL;
++
++	/* Clear old maps */
++	error = -ENOMEM;
++munmap_back:
++	vma = find_vma_prepare(mm, addr, &prev, &rb_link, &rb_parent);
++	if (vma && vma->vm_start < addr + len) {
++		if (do_munmap(mm, addr, len))
++			return -ENOMEM;
++		goto munmap_back;
++	}
++
++	/* Check against address space limit. */
++	if (!may_expand_vm(mm, len >> PAGE_SHIFT))
++		return -ENOMEM;
++
++	/*
++	 * Set 'VM_NORESERVE' if we should not account for the
++	 * memory use of this mapping.
++	 */
++	if ((flags & MAP_NORESERVE)) {
++		/* We honor MAP_NORESERVE if allowed to overcommit */
++		if (sysctl_overcommit_memory != OVERCOMMIT_NEVER)
++			vm_flags |= VM_NORESERVE;
++
++		/* hugetlb applies strict overcommit unless MAP_NORESERVE */
++		if (file && is_file_hugepages(file))
++			vm_flags |= VM_NORESERVE;
++	}
++
++	/*
++	 * Private writable mapping: check memory availability
++	 */
++	if (accountable_mapping(file, vm_flags)) {
++		charged = len >> PAGE_SHIFT;
++		if (security_vm_enough_memory(charged))
++			return -ENOMEM;
++		vm_flags |= VM_ACCOUNT;
++	}
++
++	/*
++	 * Can we just expand an old mapping?
++	 */
++	vma = vma_merge(mm, prev, addr, addr + len, vm_flags, NULL, file, pgoff, NULL);
++	if (vma)
++		goto out;
++
++	/*
++	 * Determine the object being mapped and call the appropriate
++	 * specific mapper. the address has already been validated, but
++	 * not unmapped, but the maps are removed from the list.
++	 */
++	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
++	if (!vma) {
++		error = -ENOMEM;
++		goto unacct_error;
++	}
++
++	vma->vm_mm = mm;
++	vma->vm_start = addr;
++	vma->vm_end = addr + len;
++	vma->vm_flags = vm_flags;
++	vma->vm_page_prot = vm_get_page_prot(vm_flags);
++	vma->vm_pgoff = pgoff;
++	INIT_LIST_HEAD(&vma->anon_vma_chain);
++
++	if (file) {
++		error = -EINVAL;
++		if (vm_flags & (VM_GROWSDOWN|VM_GROWSUP))
++			goto free_vma;
++		if (vm_flags & VM_DENYWRITE) {
++			error = deny_write_access(file);
++			if (error)
++				goto free_vma;
++			correct_wcount = 1;
++		}
++		vma->vm_file = file;
++		get_file(file);
++		error = file->f_op->mmap(file, vma);
++		if (error)
++			goto unmap_and_free_vma;
++		if (vm_flags & VM_EXECUTABLE)
++			added_exe_file_vma(mm);
++
++		/* Can addr have changed??
++		 *
++		 * Answer: Yes, several device drivers can do it in their
++		 *         f_op->mmap method. -DaveM
++		 */
++		addr = vma->vm_start;
++		pgoff = vma->vm_pgoff;
++		vm_flags = vma->vm_flags;
++	} else if (vm_flags & VM_SHARED) {
++		error = shmem_zero_setup(vma);
++		if (error)
++			goto free_vma;
++	}
++
++	if (vma_wants_writenotify(vma)) {
++		pgprot_t pprot = vma->vm_page_prot;
++
++		/* Can vma->vm_page_prot have changed??
++		 *
++		 * Answer: Yes, drivers may have changed it in their
++		 *         f_op->mmap method.
++		 *
++		 * Ensures that vmas marked as uncached stay that way.
++		 */
++		vma->vm_page_prot = vm_get_page_prot(vm_flags & ~VM_SHARED);
++		if (pgprot_val(pprot) == pgprot_val(pgprot_noncached(pprot)))
++			vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
++	}
++
++	vma_link(mm, vma, prev, rb_link, rb_parent);
++	file = vma->vm_file;
++
++	/* Once vma denies write, undo our temporary denial count */
++	if (correct_wcount)
++		atomic_inc(&inode->i_writecount);
++out:
++	perf_event_mmap(vma);
++
++	mm->total_vm += len >> PAGE_SHIFT;
++	vm_stat_account(mm, vm_flags, file, len >> PAGE_SHIFT);
++	if (vm_flags & VM_LOCKED) {
++		if (!mlock_vma_pages_range(vma, addr, addr + len))
++			mm->locked_vm += (len >> PAGE_SHIFT);
++	} else if ((flags & MAP_POPULATE) && !(flags & MAP_NONBLOCK))
++		make_pages_present_ex(addr, addr + len, tsk);
++	return addr;
++
++unmap_and_free_vma:
++	if (correct_wcount)
++		atomic_inc(&inode->i_writecount);
++	vma->vm_file = NULL;
++	fput(file);
++
++	/* Undo any partial mapping done by a device driver. */
++	unmap_region(mm, vma, prev, vma->vm_start, vma->vm_end);
++	charged = 0;
++free_vma:
++	kmem_cache_free(vm_area_cachep, vma);
++unacct_error:
++	if (charged)
++		vm_unacct_memory(charged);
++	return error;
++}
++
+ unsigned long mmap_region(struct file *file, unsigned long addr,
+ 			  unsigned long len, unsigned long flags,
+ 			  unsigned int vm_flags, unsigned long pgoff)
+
diff -Naur ./kos//magenta/Makefile ./kern//magenta/Makefile
--- ./kos//magenta/Makefile	2012-06-09 00:44:00.000000000 -0400
+++ ./kern//magenta/Makefile	2012-08-06 10:01:37.000000000 -0400
@@ -2,9 +2,19 @@
 # Copyright (c) 2012 Christina Brooks
 
 obj-y	+= macho_loader.o
-obj-y	+= mach.o
+obj-y	+= mach_core.o
 obj-y	+= ke_array.o
 obj-y	+= ke_runtime.o
 obj-y	+= darwin_getdirentries.o
 obj-y	+= kext.o
-obj-y	+= mach_kmsg.o
\ No newline at end of file
+obj-y	+= mach_kmsg.o
+obj-y	+= Sleh_swi_darwin.o
+obj-y	+= mach_task.o
+obj-y	+= mach_user_port.o
+obj-y	+= bsd_syscalls.o
+obj-y	+= mach_host.o
+obj-y	+= mach_semaphore.o
+obj-y	+= libkern.o
+obj-y	+= OSAtomic.o
+obj-y	+= VM.o
+obj-y	+= Log.o
\ No newline at end of file
diff -Naur ./kos//magenta/OSAtomic.S ./kern//magenta/OSAtomic.S
--- ./kos//magenta/OSAtomic.S	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/OSAtomic.S	2012-07-31 12:49:31.000000000 -0400
@@ -0,0 +1,200 @@
+/*
+ * Copyright (c) 2004 Apple Computer, Inc. All rights reserved.
+ *
+ * @APPLE_LICENSE_HEADER_START@
+ * 
+ * This file contains Original Code and/or Modifications of Original Code
+ * as defined in and that are subject to the Apple Public Source License
+ * Version 2.0 (the 'License'). You may not use this file except in
+ * compliance with the License. Please obtain a copy of the License at
+ * http://www.opensource.apple.com/apsl/ and read it before using this
+ * file.
+ * 
+ * The Original Code and all software distributed under the License are
+ * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
+ * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
+ * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
+ * Please see the License for the specific language governing rights and
+ * limitations under the License.
+ * 
+ * @APPLE_LICENSE_HEADER_END@
+ */
+
+#define ENTRY_POINT(name)			\
+	.align 2						;\
+	.globl  name					;\
+	.text							;\
+name:
+
+
+.text
+
+/*
+ * Use LDREX/STREX to perform atomic operations.
+ * Memory barriers are not needed on a UP system
+ */
+
+#if 1
+
+/* Implement a generic atomic arithmetic operation:
+ * operand is in R0, pointer is in R1.  Return new
+ * value into R0
+ */
+#define ATOMIC_ARITHMETIC(op) \
+1:	ldrex	r2, [r1]	/* load existing value and tag memory */	    ;\
+	op	r3, r2, r0	/* compute new value */				    ;\
+	strex	ip, r3, [r1]	/* store new value if memory is still tagged */	    ;\
+	cmp	ip, #0		/* check if the store succeeded */		    ;\
+	bne	1b		/* if not, try again */				    ;\
+	mov	r0, r3		/* return new value */
+
+#define ATOMIC_ARITHMETIC_ORIG(op) \
+1:	ldrex	r2, [r1]	/* load existing value and tag memory */	    ;\
+	op	r3, r2, r0	/* compute new value */				    ;\
+	strex	ip, r3, [r1]	/* store new value if memory is still tagged */	    ;\
+	cmp	ip, #0		/* check if the store succeeded */		    ;\
+	bne	1b		/* if not, try again */				    ;\
+	mov	r0, r2		/* return orig value */
+
+ENTRY_POINT(OSAtomicAdd32Barrier)
+ENTRY_POINT(OSAtomicAdd32)
+	ATOMIC_ARITHMETIC(add)
+	bx	lr
+
+ENTRY_POINT(OSAtomicOr32Barrier)
+ENTRY_POINT(OSAtomicOr32)
+	ATOMIC_ARITHMETIC(orr)
+	bx	lr
+
+ENTRY_POINT(OSAtomicOr32OrigBarrier)
+ENTRY_POINT(OSAtomicOr32Orig)
+	ATOMIC_ARITHMETIC_ORIG(orr)
+	bx	lr
+
+ENTRY_POINT(OSAtomicAnd32Barrier)
+ENTRY_POINT(OSAtomicAnd32)
+	ATOMIC_ARITHMETIC(and)
+	bx	lr
+
+ENTRY_POINT(OSAtomicAnd32OrigBarrier)
+ENTRY_POINT(OSAtomicAnd32Orig)
+	ATOMIC_ARITHMETIC_ORIG(and)
+	bx	lr
+
+ENTRY_POINT(OSAtomicXor32Barrier)
+ENTRY_POINT(OSAtomicXor32)
+	ATOMIC_ARITHMETIC(eor)
+	bx	lr
+
+ENTRY_POINT(OSAtomicXor32OrigBarrier)
+ENTRY_POINT(OSAtomicXor32Orig)
+	ATOMIC_ARITHMETIC_ORIG(eor)
+	bx	lr
+
+ENTRY_POINT(OSAtomicCompareAndSwap32Barrier)
+ENTRY_POINT(OSAtomicCompareAndSwap32)
+ENTRY_POINT(OSAtomicCompareAndSwapIntBarrier)
+ENTRY_POINT(OSAtomicCompareAndSwapInt)
+ENTRY_POINT(OSAtomicCompareAndSwapLongBarrier)
+ENTRY_POINT(OSAtomicCompareAndSwapLong)
+ENTRY_POINT(OSAtomicCompareAndSwapPtrBarrier)
+ENTRY_POINT(OSAtomicCompareAndSwapPtr)
+1:	ldrex	r3, [r2]	// load existing value and tag memory
+	teq	r3, r0		// is it the same as oldValue?
+	movne	r0, #0		// if not, return 0 immediately
+	bxne	lr	    
+	strex	r3, r1, [r2]	// otherwise, try to store new value
+	cmp	r3, #0		// check if the store succeeded
+	bne	1b		// if not, try again
+	mov	r0, #1		// return true
+	bx	lr
+
+
+/* Implement a generic test-and-bit-op operation:
+ * bit to set is in R0, base address is in R1.  Return
+ * previous value (0 or 1) of the bit in R0.
+ */
+#define ATOMIC_BITOP(op)    \
+	/* Adjust pointer to point at the correct word				    ;\
+	 * R1 = R1 + 4 * (R0 / 32)						    ;\
+	 */									    ;\
+        mov     r3, r0, lsr #5							    ;\
+        add     r1, r1, r3, asl #2						    ;\
+	/* Generate a bit mask for the bit we want to test			    ;\
+	 * R0 = (0x80 >> (R0 & 7)) << (R0 & ~7 & 31)				    ;\
+	 */									    ;\
+        and     r2, r0, #7							    ;\
+        mov     r3, #0x80							    ;\
+        mov     r3, r3, asr r2							    ;\
+        and     r0, r0, #0x18							    ;\
+        mov     r0, r3, asl r0							    ;\
+1:										    ;\
+	ldrex	r2, [r1]	/* load existing value and tag memory */	    ;\
+	op	r3, r2, r0	/* compute new value */				    ;\
+	strex	ip, r3, [r1]	/* attempt to store new value */		    ;\
+	cmp	ip, #0		/* check if the store succeeded */		    ;\
+	bne	1b		/* if so, try again */				    ;\
+	ands	r0, r2, r0	/* mask off the bit from the old value */	    ;\
+	movne	r0, #1		/* if non-zero, return exactly 1 */
+	
+ENTRY_POINT(OSAtomicTestAndSetBarrier)
+ENTRY_POINT(OSAtomicTestAndSet)
+	ATOMIC_BITOP(orr)
+	bx	lr
+
+ENTRY_POINT(OSAtomicTestAndClearBarrier)
+ENTRY_POINT(OSAtomicTestAndClear)
+	ATOMIC_BITOP(bic)
+	bx	lr
+
+ENTRY_POINT(OSMemoryBarrier)
+	bx	lr
+
+
+#if defined(_ARM_ARCH_6K)
+/* If we can use LDREXD/STREXD, then we can implement 64-bit atomic operations */
+
+ENTRY_POINT(OSAtomicAdd64Barrier)
+ENTRY_POINT(OSAtomicAdd64)
+	// R0,R1 contain the amount to add
+	// R2 contains the pointer
+	stmfd	sp!, {r4, r5, r8, r9, lr}
+1:	
+	ldrexd	r4, r5, [r2]	// load existing value to R4/R5 and tag memory
+	adds	r8, r4, r0	// add lower half of new value into R6 and set carry bit
+	adc	r9, r5, r1	// add upper half of new value into R8 with carry
+	strexd	r3, r8, r9, [r2]	// store new value if memory is still tagged
+	cmp	r3, #0		// check if store succeeded
+	bne	1b		// if so, try again
+	mov	r0, r8		// return new value
+	mov	r1, r9
+	ldmfd	sp!, {r4, r5, r8, r9, pc}
+	
+ENTRY_POINT(OSAtomicCompareAndSwap64Barrier)
+ENTRY_POINT(OSAtomicCompareAndSwap64)
+	// R0,R1 contains the old value
+	// R2,R3 contains the new value
+	// the pointer is pushed onto the stack
+	ldr	ip, [sp, #0]	// load pointer into IP
+	stmfd	sp!, {r4, r5, lr}
+1:	
+	ldrexd	r4, [ip]	// load existing value into R4/R5 and tag memory
+	teq	r0, r4		// check low word
+	teqeq	r1, r5		// if low words match, check high word
+	movne	r0, #0		// if either match fails, return 0
+	bne	2f
+	strexd	r4, r2, [ip]	// otherwise, try to store new values
+	cmp	r3, #0		// check if store succeeded
+	bne	1b		// if so, try again
+	mov	r0, #1		// return true
+2:	
+	ldmfd	sp!, {r4, r5, pc}
+			
+#endif /* defined(_ARM_ARCH_6K) */
+
+#endif /* defined(_ARM_ARCH_6) */
+
+/*
+ * For OSSpinLock, see 'OSSpinLock.c'
+ */
diff -Naur ./kos//magenta/Sleh_swi_darwin.S ./kern//magenta/Sleh_swi_darwin.S
--- ./kos//magenta/Sleh_swi_darwin.S	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/Sleh_swi_darwin.S	2012-08-06 09:43:48.000000000 -0400
@@ -0,0 +1,121 @@
+/*
+ * Sleh_swi_darwin.S
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Darwin traps.
+ *
+ * Syscall number is initally stored in r12, but the sleh
+ * will move it to r7 (scno) as needed.
+ * 
+ * At the point of entry in ke_darwin_syscall, lr is set to
+ * the syscall fast return function.
+ *
+ * XXX: use a table instead of beqs
+ * XXX: need to write my own fleh
+ */
+
+#define check_call(nr, fn) cmp r7, nr; beq fn;
+
+.text
+.align 2
+
+/* Not really needed anymore */
+__mach_timer_cancel_trampoline:
+	b _user_mk_timer_cancel
+__mach_timer_arm_trampoline:
+	b _user_mk_timer_arm
+
+/* Handler */
+.globl Sleh_swi_darwin
+Sleh_swi_darwin:
+	/* Normal BSD syscalls */
+	check_call(#4, sys_write);
+
+	/* Native */
+	check_call(#0x158, _user_getdirentries64);
+	check_call(#199, _user_bsd_lseek);
+
+
+
+	/**********************************************/
+
+	/* ... self */
+	check_call(#-29, _user_host_self);
+	check_call(#-27, _user_thread_self);
+
+
+	/**********************************************/
+
+
+	/* these are not meant to be traps, however, I dont
+	   see why not, so I will make them traps and 
+	   give them the reserved mach trap numbers */
+
+	/* Thread */
+	check_call(#-109, _user_thread_policy);
+	check_call(#-110, _user_bsdthread_register);
+	check_call(#-111, _user_thread_selfid);
+	check_call(#-112, _user_bsdthread_create);
+
+	check_call(#-115, _user__disable_threadsignal)
+	check_call(#-116, _user_syscall_thread_switch)
+	check_call(#-117, _user_bsdthread_terminate)
+	check_call(#-118, _user__pthread_canceled)
+	check_call(#-119, _user__pthread_kill)
+	check_call(#-120, _user__pthread_markcancel)
+	check_call(#-121, _user__workq_open)
+
+	check_call(#-122, _user_thread_switch)
+	check_call(#-123, _user_task_threads)
+	check_call(#-124, _user_thread_get_state)
+	check_call(#-125, _user_thread_suspend)
+	check_call(#-126, _user_thread_resume)
+
+	/* Host */
+	check_call(#-108, _user_host_info);
+
+	/* Semaphore */
+	check_call(#-33, _user_semaphore_signal)
+	check_call(#-34, _user_semaphore_signal_all)
+	check_call(#-35, _user_semaphore_signal_thread)
+	check_call(#-36, _user_semaphore_wait)
+	check_call(#-37, _user_semaphore_wait_signal)
+	check_call(#-38, _user_semaphore_timedwait)
+	check_call(#-39, _user_semaphore_timedwait_signal)
+
+	/* aaa */
+	check_call(#-113, _user_semaphore_create)
+
+	/*********************************************/
+	and r7, r7, #0xff
+
+	/* VM */
+	check_call(#0xf5, _user_vm_allocate);
+
+	/* Task */
+	check_call(#0xe4, _user_task_self);
+	check_call(#0xd3, _user_task_for_pid);
+	check_call(#0xd2, _user_pid_for_task);
+
+	/* IPC */
+	check_call(#0xe1, _user_mach_msg_trap);
+	check_call(#0xf0, _user_mach_port_allocate);
+	check_call(#0xeb, _user_mach_port_insert_right);
+	check_call(#0xed, _user_mach_port_mod_refs);
+	check_call(#0xef, _user_mach_port_destroy);
+	check_call(#0xee, _user_mach_port_deallocate);
+	check_call(#0xea, _user_mach_port_insert_member);
+	check_call(#0xe0, _user_mach_msg_overwrite_trap);
+
+	/* Timers */
+	check_call(#0xa5, _user_mk_timer_create);
+	check_call(#0xa4, _user_mk_timer_destroy);
+	check_call(#0xa3, __mach_timer_arm_trampoline);
+	check_call(#0xa2, __mach_timer_cancel_trampoline);
+
+	/* Stuff */
+	check_call(#0xff, _user_load_kext);
+
+	/* error out */
+	mov r0, r7
+	b ke_darwin_syscall_error
\ No newline at end of file
diff -Naur ./kos//magenta/Standard.h ./kern//magenta/Standard.h
--- ./kos//magenta/Standard.h	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/Standard.h	2012-08-04 13:44:41.000000000 -0400
@@ -0,0 +1,32 @@
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+#include <linux/freezer.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+#include <asm/thread_notify.h>
\ No newline at end of file
diff -Naur ./kos//magenta/VM.c ./kern//magenta/VM.c
--- ./kos//magenta/VM.c	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/VM.c	2012-08-04 14:33:19.000000000 -0400
@@ -0,0 +1,283 @@
+/*
+ * VM
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Back-end support for VM operations on specific tasks.
+ * I don't understand why these are not in Linux already.
+ */
+
+#include "VM.h"
+
+ /* Extended version that can map stuff in different tasks */
+extern
+unsigned long mmap_region_ex(struct file *file, unsigned long addr,
+			  unsigned long len, unsigned long flags,
+			  unsigned int vm_flags, unsigned long pgoff,
+			  struct task_struct* tsk);
+
+/* BRING THE PAIN */
+unsigned long
+ARM_get_unmapped_area(struct mm_struct *mm, struct file *filp, unsigned long addr,
+		unsigned long len, unsigned long pgoff, unsigned long flags);
+
+unsigned long VM_get_unmapped(struct mm_struct* mm,
+	unsigned long addr,
+	unsigned long len,
+	unsigned long flags,
+	unsigned long pgoff)
+{
+	unsigned long error = arch_mmap_check(addr, len, flags);
+
+	/* arch specific checks */
+	if (error)
+		return error;
+
+	/* overflow checks */
+	if (len > TASK_SIZE)
+		return -ENOMEM;
+
+	/* PAAAAAAAAIN */
+	addr = ARM_get_unmapped_area(mm, NULL, addr, len, pgoff, flags);
+
+	if (IS_ERR_VALUE(addr))
+		return addr;
+
+	if (addr > TASK_SIZE - len)
+		return -ENOMEM;
+	if (addr & ~PAGE_MASK)
+		return -EINVAL;
+
+	/* arm only */
+	return addr;
+}
+
+kern_return_t VM_allocate(struct task_struct* ts,
+	uintptr_t* addr,
+	size_t size,
+	boolean_t anywhere)
+{
+	struct mm_struct* mm = ts->mm;
+	unsigned long flags = 0;
+	unsigned long pgoff = 0;
+	unsigned int vm_flags = 0;
+	unsigned int prot = PROT_READ | PROT_WRITE | PROT_EXEC;
+	unsigned long ret = 0;
+	uintptr_t iaddr = *addr;
+
+	if (!anywhere) {
+		flags |= MAP_FIXED;
+	}
+	else {
+		iaddr = 0;
+	}
+
+	pgoff = iaddr >> PAGE_SHIFT;
+
+	/* Careful about overflows.. */
+	size = PAGE_ALIGN(size);
+	if (!size)
+	{
+		ke_warn("VM_allocate(): alignment error!");
+		return KERN_FAILURE;
+	}
+
+	/* offset overflow? */
+	if ((pgoff + (size >> PAGE_SHIFT)) < pgoff)
+	{
+		ke_warn("VM_allocate(): offset overflow!");
+		return KERN_FAILURE;
+	}
+
+	/* Too many mappings? */
+	if (mm->map_count > sysctl_max_map_count)
+	{
+		ke_warn("VM_allocate(): too many mappings");
+		return KERN_FAILURE;
+	}
+
+	down_write(&mm->mmap_sem);
+
+	vm_flags = calc_vm_prot_bits(prot) | calc_vm_flag_bits(flags) |
+			mm->def_flags | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC;
+
+	ret = 
+	VM_get_unmapped(mm,
+		(unsigned long)iaddr,
+		(unsigned long)size,
+		flags,
+		pgoff);
+
+	if (IS_ERR_VALUE(ret)) {
+		ke_warn("mmap_region_ex(): ke_mm_get_unmapped returned %ld \n", ret);
+		up_write(&mm->mmap_sem);
+		return KERN_FAILURE;
+	}
+	else {
+		iaddr = (uintptr_t)ret;
+	}
+
+	ret = 
+	mmap_region_ex(NULL, iaddr, (unsigned long)size, flags, vm_flags, pgoff, ts);
+
+	up_write(&mm->mmap_sem);
+
+	*addr = iaddr;
+
+	return KERN_SUCCESS;
+}
+
+boolean_t VM_kernel_copyin(void* to, void* from, unsigned long size, boolean_t user)
+{
+	if (user) {
+		if (copy_from_user(to, from, size)) {
+			return false;
+		}
+		else {
+			return true;
+		}
+	}
+	else {
+		memcpy(to, from, size);
+		return true;
+	}
+}
+
+boolean_t VM_kernel_copyout(void* to, void* from, unsigned long size, boolean_t user)
+{
+	if (user) {
+		if (copy_to_user(to, from, size)) {
+			return false;
+		}
+		else {
+			return true;
+		}
+	}
+	else {
+		memcpy(to, from, size);
+		return true;
+	}
+}
+
+kern_return_t VM_write(struct task_struct* task,
+	char* in_buffer,
+	size_t count,
+	unsigned long *ppos,
+	boolean_t user)
+{
+	int copied = KERN_FAILURE;
+	char *page;
+	unsigned long dst = *ppos;
+
+	copied = -ENOMEM;
+	page = (char *)__get_free_page(GFP_TEMPORARY);
+	if (!page)
+	{
+		ke_warn("VM_write: page alloc failed!\n");
+		goto out;
+	}
+
+	copied = KERN_SUCCESS;
+	while (count > 0) {
+		int this_len, retval;
+
+		this_len = (count > PAGE_SIZE) ? PAGE_SIZE : count;
+		if (VM_kernel_copyin(page, in_buffer, this_len, user)) {
+			ke_warn("VM_write: copyin failed!\n");
+			copied = KERN_PROTECTION_FAILURE;
+			break;
+		}
+
+		retval = access_process_vm(task, dst, page, this_len, 1);
+		if (!retval) {
+			ke_warn("VM_write: access failed!\n");
+			copied = KERN_PROTECTION_FAILURE;
+			break;
+		}
+
+		in_buffer += retval;
+		dst += retval;
+		count -= retval;			
+	}
+	*ppos = dst;
+
+	free_page((unsigned long) page);
+out:
+	return copied;
+}
+
+kern_return_t VM_read(struct task_struct* task,
+	char* out_buffer,
+	size_t count,
+	unsigned long *ppos,
+	boolean_t user)
+{
+	char *page;
+	unsigned long src = *ppos;
+	int ret = KERN_FAILURE;
+	struct mm_struct *mm;
+
+	BUG_ON(!task);
+
+	ret = KERN_FAILURE;
+	page = (char *)__get_free_page(GFP_TEMPORARY);
+	if (!page) {
+		ke_warn("VM_read: can't get page!\n");
+		goto out;
+	}
+
+	ret = 0;
+ 
+	mm = get_task_mm(task);
+	if (!mm)
+	{
+		ke_warn("VM_read: can't get VM!\n");
+		goto out_free;
+	}
+
+	ret = KERN_SUCCESS;
+ 
+	while (count > 0) {
+		int this_len, retval;
+
+		this_len = (count > PAGE_SIZE) ? PAGE_SIZE : count;
+		retval = access_process_vm(task, src, page, this_len, 0);
+		if (!retval)
+		{
+			ke_warn("VM_read: can't access vm!\n");
+			ret = KERN_INVALID_ADDRESS;
+			break;
+		}
+
+		if (!VM_kernel_copyout((void*)out_buffer, (void*)page, retval, user))
+		{
+			ke_warn("VM_read: can't copy buffer!\n");
+			ret = KERN_PROTECTION_FAILURE;
+			break;
+		}
+ 
+		src += retval;
+		out_buffer += retval;
+		count -= retval;
+	}
+	*ppos = src;
+
+	mmput(mm);
+out_free:
+	free_page((unsigned long) page);
+out:
+	return ret;
+}
+
+kern_return_t VM_deallocate(struct task_struct* ts,
+	uintptr_t addr,
+	size_t size)
+{
+	int ret = do_munmap(ts->mm, addr, size);
+	if (ret == 0) {
+		return KERN_SUCCESS;
+	}
+	else {
+		ke_warn("VM_deallocate: failed with %d\n", ret);
+		return KERN_FAILURE;
+	}
+}
\ No newline at end of file
diff -Naur ./kos//magenta/VM.h ./kern//magenta/VM.h
--- ./kos//magenta/VM.h	1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/VM.h	2012-08-04 14:18:02.000000000 -0400
@@ -0,0 +1,32 @@
+#ifndef _H_MG_VM_
+#define _H_MG_VM_
+
+#include "Standard.h"
+
+#include "ke_runtime.h"
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+kern_return_t VM_allocate(struct task_struct* ts,
+	uintptr_t* addr,
+	size_t size,
+	boolean_t anywhere);
+
+kern_return_t VM_deallocate(struct task_struct* ts,
+	uintptr_t addr,
+	size_t size);
+
+kern_return_t VM_write(struct task_struct* task,
+	char* in_buffer,
+	size_t count,
+	unsigned long *ppos,
+	boolean_t user);
+
+kern_return_t VM_read(struct task_struct* task,
+	char* out_buffer,
+	size_t count,
+	unsigned long *ppos,
+	boolean_t user);
+
+#endif
\ No newline at end of file
diff -Naur ./kos//mm/mmap.c ./kern//mm/mmap.c
--- ./kos//mm/mmap.c	2012-06-09 00:43:30.000000000 -0400
+++ ./kern//mm/mmap.c	2012-08-04 10:30:44.000000000 -0400
@@ -1138,6 +1138,7 @@
 
 	if (file)
 		fput(file);
+
 out:
 	return retval;
 }
@@ -1214,6 +1215,186 @@
 	return (vm_flags & (VM_NORESERVE | VM_SHARED | VM_WRITE)) == VM_WRITE;
 }
 
+int make_pages_present_ex(unsigned long addr, unsigned long end, struct task_struct* tsk)
+{
+	int ret, len, write;
+	struct vm_area_struct * vma;
+
+	vma = find_vma(tsk->mm, addr);
+	if (!vma)
+		return -ENOMEM;
+
+	write = (vma->vm_flags & (VM_WRITE | VM_SHARED)) == VM_WRITE;
+	BUG_ON(addr >= end);
+	BUG_ON(end > vma->vm_end);
+	len = DIV_ROUND_UP(end, PAGE_SIZE) - addr/PAGE_SIZE;
+	ret = get_user_pages(tsk, tsk->mm, addr,
+						len, write, 0, NULL, NULL);
+	if (ret < 0)
+		return ret;
+
+	return ret == len ? 0 : -EFAULT;
+}
+
+unsigned long mmap_region_ex(struct file *file, unsigned long addr,
+			  unsigned long len, unsigned long flags,
+			  unsigned int vm_flags, unsigned long pgoff,
+			  struct task_struct* tsk)
+{
+	struct mm_struct *mm = tsk->mm;
+	struct vm_area_struct *vma, *prev;
+	int correct_wcount = 0;
+	int error;
+	struct rb_node **rb_link, *rb_parent;
+	unsigned long charged = 0;
+	struct inode *inode =  file ? file->f_path.dentry->d_inode : NULL;
+
+	/* Clear old maps */
+	error = -ENOMEM;
+munmap_back:
+	vma = find_vma_prepare(mm, addr, &prev, &rb_link, &rb_parent);
+	if (vma && vma->vm_start < addr + len) {
+		if (do_munmap(mm, addr, len))
+			return -ENOMEM;
+		goto munmap_back;
+	}
+
+	/* Check against address space limit. */
+	if (!may_expand_vm(mm, len >> PAGE_SHIFT))
+		return -ENOMEM;
+
+	/*
+	 * Set 'VM_NORESERVE' if we should not account for the
+	 * memory use of this mapping.
+	 */
+	if ((flags & MAP_NORESERVE)) {
+		/* We honor MAP_NORESERVE if allowed to overcommit */
+		if (sysctl_overcommit_memory != OVERCOMMIT_NEVER)
+			vm_flags |= VM_NORESERVE;
+
+		/* hugetlb applies strict overcommit unless MAP_NORESERVE */
+		if (file && is_file_hugepages(file))
+			vm_flags |= VM_NORESERVE;
+	}
+
+	/*
+	 * Private writable mapping: check memory availability
+	 */
+	if (accountable_mapping(file, vm_flags)) {
+		charged = len >> PAGE_SHIFT;
+		if (security_vm_enough_memory(charged))
+			return -ENOMEM;
+		vm_flags |= VM_ACCOUNT;
+	}
+
+	/*
+	 * Can we just expand an old mapping?
+	 */
+	vma = vma_merge(mm, prev, addr, addr + len, vm_flags, NULL, file, pgoff, NULL);
+	if (vma)
+		goto out;
+
+	/*
+	 * Determine the object being mapped and call the appropriate
+	 * specific mapper. the address has already been validated, but
+	 * not unmapped, but the maps are removed from the list.
+	 */
+	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+	if (!vma) {
+		error = -ENOMEM;
+		goto unacct_error;
+	}
+
+	vma->vm_mm = mm;
+	vma->vm_start = addr;
+	vma->vm_end = addr + len;
+	vma->vm_flags = vm_flags;
+	vma->vm_page_prot = vm_get_page_prot(vm_flags);
+	vma->vm_pgoff = pgoff;
+	INIT_LIST_HEAD(&vma->anon_vma_chain);
+
+	if (file) {
+		error = -EINVAL;
+		if (vm_flags & (VM_GROWSDOWN|VM_GROWSUP))
+			goto free_vma;
+		if (vm_flags & VM_DENYWRITE) {
+			error = deny_write_access(file);
+			if (error)
+				goto free_vma;
+			correct_wcount = 1;
+		}
+		vma->vm_file = file;
+		get_file(file);
+		error = file->f_op->mmap(file, vma);
+		if (error)
+			goto unmap_and_free_vma;
+		if (vm_flags & VM_EXECUTABLE)
+			added_exe_file_vma(mm);
+
+		/* Can addr have changed??
+		 *
+		 * Answer: Yes, several device drivers can do it in their
+		 *         f_op->mmap method. -DaveM
+		 */
+		addr = vma->vm_start;
+		pgoff = vma->vm_pgoff;
+		vm_flags = vma->vm_flags;
+	} else if (vm_flags & VM_SHARED) {
+		error = shmem_zero_setup(vma);
+		if (error)
+			goto free_vma;
+	}
+
+	if (vma_wants_writenotify(vma)) {
+		pgprot_t pprot = vma->vm_page_prot;
+
+		/* Can vma->vm_page_prot have changed??
+		 *
+		 * Answer: Yes, drivers may have changed it in their
+		 *         f_op->mmap method.
+		 *
+		 * Ensures that vmas marked as uncached stay that way.
+		 */
+		vma->vm_page_prot = vm_get_page_prot(vm_flags & ~VM_SHARED);
+		if (pgprot_val(pprot) == pgprot_val(pgprot_noncached(pprot)))
+			vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+	}
+
+	vma_link(mm, vma, prev, rb_link, rb_parent);
+	file = vma->vm_file;
+
+	/* Once vma denies write, undo our temporary denial count */
+	if (correct_wcount)
+		atomic_inc(&inode->i_writecount);
+out:
+	perf_event_mmap(vma);
+
+	mm->total_vm += len >> PAGE_SHIFT;
+	vm_stat_account(mm, vm_flags, file, len >> PAGE_SHIFT);
+	if (vm_flags & VM_LOCKED) {
+		if (!mlock_vma_pages_range(vma, addr, addr + len))
+			mm->locked_vm += (len >> PAGE_SHIFT);
+	} else if ((flags & MAP_POPULATE) && !(flags & MAP_NONBLOCK))
+		make_pages_present_ex(addr, addr + len, tsk);
+	return addr;
+
+unmap_and_free_vma:
+	if (correct_wcount)
+		atomic_inc(&inode->i_writecount);
+	vma->vm_file = NULL;
+	fput(file);
+
+	/* Undo any partial mapping done by a device driver. */
+	unmap_region(mm, vma, prev, vma->vm_start, vma->vm_end);
+	charged = 0;
+free_vma:
+	kmem_cache_free(vm_area_cachep, vma);
+unacct_error:
+	if (charged)
+		vm_unacct_memory(charged);
+	return error;
+}
+
 unsigned long mmap_region(struct file *file, unsigned long addr,
 			  unsigned long len, unsigned long flags,
 			  unsigned int vm_flags, unsigned long pgoff)
@@ -1388,6 +1569,8 @@
 arch_get_unmapped_area(struct file *filp, unsigned long addr,
 		unsigned long len, unsigned long pgoff, unsigned long flags)
 {
+	panic("%s: shouldn't be used on this platform!", __FUNCTION__);
+
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
 	unsigned long start_addr;
@@ -1463,6 +1646,8 @@
 			  const unsigned long len, const unsigned long pgoff,
 			  const unsigned long flags)
 {
+	panic("%s: shouldn't be used on this platform!", __FUNCTION__);
+
 	struct vm_area_struct *vma;
 	struct mm_struct *mm = current->mm;
 	unsigned long addr = addr0;
